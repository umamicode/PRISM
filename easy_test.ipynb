{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28bf9e86-0994-4379-aa8e-0a1c25c89ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "#SimCLR\n",
    "from simclr import SimCLR\n",
    "from simclr.modules import LogisticRegression, get_resnet\n",
    "from simclr.modules.transformations import TransformsSimCLR\n",
    "\n",
    "#ReLIC\n",
    "#[TODO]\n",
    "from relic import ReLIC\n",
    "#from relic.modules import ReLIC_Loss, get_resnet\n",
    "from relic.modules.transformations import TransformsRelic\n",
    "\n",
    "# TensorBoard\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from model import load_optimizer, save_model\n",
    "from utils import yaml_config_hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b93c534e-b823-426a-8671-2f3d8820a995",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PACS Dataset\n",
    "NUM_CLASSES = 7      # 7 classes for each domain: 'dog', 'elephant', 'giraffe', 'guitar', 'horse', 'house', 'person'\n",
    "DATASETS_NAMES = ['photo', 'art', 'cartoon', 'sketch']\n",
    "CLASSES_NAMES = ['Dog', 'Elephant', 'Giraffe', 'Guitar', 'Horse', 'House', 'Person']\n",
    "DIR_PHOTO = './datasets/PACS/photo'\n",
    "DIR_ART = './datasets/PACS/art_painting'\n",
    "DIR_CARTOON = './datasets/PACS/cartoon'\n",
    "DIR_SKETCH = './datasets/PACS/sketch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7c787ab-8e34-45de-907e-9dc70c352898",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"SimCLR/ReLIC\")\n",
    "config = yaml_config_hook(\"./config/config.yaml\")\n",
    "for k, v in config.items():\n",
    "    parser.add_argument(f\"--{k}\", default=v, type=type(v))\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "\n",
    "# Master address for distributed data parallel\n",
    "os.environ[\"MASTER_ADDR\"] = \"127.0.0.1\"\n",
    "os.environ[\"MASTER_PORT\"] = \"8000\"\n",
    "\n",
    "if not os.path.exists(args.model_path):\n",
    "    os.makedirs(args.model_path)\n",
    "\n",
    "args.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "args.num_gpus = torch.cuda.device_count()\n",
    "args.world_size = args.gpus * args.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e883616-3055-4582-814a-9738207d446d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference(loader, ssl_model, device ,relic):\n",
    "    feature_vector = []\n",
    "    labels_vector = []\n",
    "    #SIMCLR\n",
    "    if relic == False:\n",
    "        for step, (x, y) in enumerate(loader):\n",
    "            x = x.to(device)\n",
    "\n",
    "            # get encoding\n",
    "            with torch.no_grad():\n",
    "                h, _, z, _ = ssl_model(x, x)\n",
    "\n",
    "            h = h.detach()\n",
    "\n",
    "            feature_vector.extend(h.cpu().detach().numpy())\n",
    "            labels_vector.extend(y.numpy())\n",
    "\n",
    "            if step % 20 == 0:\n",
    "                print(f\"Step [{step}/{len(loader)}]\\t Computing features...\")\n",
    "\n",
    "        feature_vector = np.array(feature_vector)\n",
    "        labels_vector = np.array(labels_vector)\n",
    "        print(\"Features shape {}\".format(feature_vector.shape))\n",
    "        return feature_vector, labels_vector\n",
    "    #ReLIC\n",
    "    elif relic == True:\n",
    "        for step, (x, y) in enumerate(loader):\n",
    "            x = x.to(device)\n",
    "\n",
    "            # get encoding\n",
    "            with torch.no_grad():\n",
    "                #[TODO] inference\n",
    "                \n",
    "                #dkcho\n",
    "                #h,_,_, _, _, _, _ = ssl_model(x, x, x)\n",
    "                \n",
    "                #new\n",
    "                h= ssl_model(x,x,x, test= True)\n",
    "                \n",
    "\n",
    "\n",
    "            \n",
    "            h = h.detach() #(256,512)\n",
    "\n",
    "            feature_vector.extend(h.cpu().detach().numpy())\n",
    "            labels_vector.extend(y.numpy())\n",
    "\n",
    "            \n",
    "\n",
    "            if step % 20 == 0:\n",
    "                print(f\"Step [{step}/{len(loader)}]\\t Computing features...\")\n",
    "\n",
    "        feature_vector = np.array(feature_vector)\n",
    "        labels_vector = np.array(labels_vector)\n",
    "        print(\"Features shape {}\".format(feature_vector.shape))\n",
    "        return feature_vector, labels_vector        \n",
    "\n",
    "def get_features(ssl_model, train_loader, test_loader, device, relic):\n",
    "    train_X, train_y = inference(train_loader, ssl_model, device, relic) #relic\n",
    "    test_X, test_y = inference(test_loader, ssl_model, device, relic) #relic\n",
    "    return train_X, train_y, test_X, test_y\n",
    "\n",
    "\n",
    "def create_data_loaders_from_arrays(X_train, y_train, X_test, y_test, batch_size):\n",
    "    train = torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(X_train), torch.from_numpy(y_train)\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "\n",
    "    test = torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(X_test), torch.from_numpy(y_test)\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "def train(args, loader, ssl_model, model, criterion, optimizer):\n",
    "    loss_epoch = 0\n",
    "    accuracy_epoch = 0\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x = x.to(args.device)\n",
    "        y = y.to(args.device)\n",
    "        \n",
    "\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        predicted = output.argmax(1)\n",
    "        acc = (predicted == y).sum().item() / y.size(0)\n",
    "        accuracy_epoch += acc\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_epoch += loss.item()\n",
    "        # if step % 100 == 0:\n",
    "        #     print(\n",
    "        #         f\"Step [{step}/{len(loader)}]\\t Loss: {loss.item()}\\t Accuracy: {acc}\"\n",
    "        #     )\n",
    "\n",
    "    return loss_epoch, accuracy_epoch\n",
    "\n",
    "\n",
    "def test(args, loader, ssl_model, model, criterion, optimizer):\n",
    "    loss_epoch = 0\n",
    "    accuracy_epoch = 0\n",
    "    model.eval()\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        model.zero_grad()\n",
    "\n",
    "        x = x.to(args.device)\n",
    "        y = y.to(args.device)\n",
    "\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        predicted = output.argmax(1)\n",
    "        acc = (predicted == y).sum().item() / y.size(0)\n",
    "        accuracy_epoch += acc\n",
    "\n",
    "        loss_epoch += loss.item()\n",
    "\n",
    "    return loss_epoch, accuracy_epoch\n",
    "\n",
    "def main(gpu,args):\n",
    "\n",
    "    print(\"ReLIC -- {c}\".format(c= args.relic))\n",
    "    print(\"Model From -- {m}, Epoch: {e}\".format(m= args.model_path, e= args.epoch_num))\n",
    "    print(\"All Evaluation args -- \", args)\n",
    "\n",
    "    \n",
    "    if args.relic == False:\n",
    "        if args.test_dataset == \"STL10\":\n",
    "            train_dataset = torchvision.datasets.STL10(\n",
    "                args.dataset_dir,\n",
    "                split=\"train\",\n",
    "                download=True,\n",
    "                transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "            )\n",
    "            test_dataset = torchvision.datasets.STL10(\n",
    "                args.dataset_dir,\n",
    "                split=\"test\",\n",
    "                download=True,\n",
    "                transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "            )\n",
    "        elif args.test_dataset == \"CIFAR10\":\n",
    "            train_dataset = torchvision.datasets.CIFAR10(\n",
    "                args.dataset_dir,\n",
    "                train=True,\n",
    "                download=True,\n",
    "                transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "            )\n",
    "            test_dataset = torchvision.datasets.CIFAR10(\n",
    "                args.dataset_dir,\n",
    "                train=False,\n",
    "                download=True,\n",
    "                transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "            )\n",
    "        elif args.test_dataset == \"PACS\":\n",
    "            pacs_convertor= {'default':DIR_PHOTO, 'photo':DIR_PHOTO, 'art':DIR_ART, 'cartoon':DIR_CARTOON, 'sketch':DIR_SKETCH}\n",
    "            train_dataset= torchvision.datasets.ImageFolder(pacs_convertor[args.test_pacs_style], transform=TransformsSimCLR(size=args.image_size).test_transform)\n",
    "            test_dataset = torchvision.datasets.ImageFolder(pacs_convertor[args.test_pacs_style], transform=TransformsSimCLR(size=args.image_size).test_transform)\n",
    "                \n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "    \n",
    "    #[TODO - Added] ReLIC\n",
    "    elif args.relic == True:\n",
    "        if args.test_dataset == \"STL10\":\n",
    "            train_dataset = torchvision.datasets.STL10(\n",
    "                args.dataset_dir,\n",
    "                split=\"train\",\n",
    "                download=True,\n",
    "                transform=TransformsRelic(size=args.image_size).test_transform,\n",
    "            )\n",
    "            test_dataset = torchvision.datasets.STL10(\n",
    "                args.dataset_dir,\n",
    "                split=\"test\",\n",
    "                download=True,\n",
    "                transform=TransformsRelic(size=args.image_size).test_transform,\n",
    "            )\n",
    "        elif args.test_dataset == \"CIFAR10\":\n",
    "            train_dataset = torchvision.datasets.CIFAR10(\n",
    "                args.dataset_dir,\n",
    "                train=True,\n",
    "                download=True,\n",
    "                transform=TransformsRelic(size=args.image_size).test_transform,\n",
    "            )\n",
    "            test_dataset = torchvision.datasets.CIFAR10(\n",
    "                args.dataset_dir,\n",
    "                train=False,\n",
    "                download=True,\n",
    "                transform=TransformsRelic(size=args.image_size).test_transform,\n",
    "            )\n",
    "        elif args.dataset == \"PACS\":\n",
    "                pacs_convertor= {'default':DIR_PHOTO, 'photo':DIR_PHOTO, 'art':DIR_ART, 'cartoon':DIR_CARTOON, 'sketch':DIR_SKETCH}\n",
    "                train_dataset= torchvision.datasets.ImageFolder(pacs_convertor[args.test_pacs_style], transform=TransformsRelic(size=args.image_size).test_transform)\n",
    "                test_dataset = torchvision.datasets.ImageFolder(pacs_convertor[args.test_pacs_style], transform=TransformsRelic(size=args.image_size).test_transform)\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError       \n",
    "\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=args.logistic_batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        num_workers=args.workers,\n",
    "    )\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=args.logistic_batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=True,\n",
    "        num_workers=args.workers,\n",
    "    )\n",
    "\n",
    "    encoder = get_resnet(args.resnet, pretrained=False)\n",
    "    n_features = encoder.fc.in_features  # get dimensions of fc layer\n",
    "\n",
    "    # load pre-trained model from checkpoint\n",
    "    if args.relic ==  False:\n",
    "        simclr_model = SimCLR(encoder, args.projection_dim, n_features)\n",
    "        model_fp = os.path.join(args.model_path, \"checkpoint_{}.tar\".format(args.epoch_num))\n",
    "        simclr_model.load_state_dict(torch.load(model_fp, map_location=args.device.type))\n",
    "        simclr_model = simclr_model.to(args.device)\n",
    "        simclr_model.eval()\n",
    "\n",
    "        ## Logistic Regression\n",
    "        n_classes = 10  # CIFAR-10 / STL-10\n",
    "        model = LogisticRegression(simclr_model.n_features, n_classes)\n",
    "        model = model.to(args.device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        print(\"### Creating features from pre-trained context model ###\")\n",
    "        (train_X, train_y, test_X, test_y) = get_features(\n",
    "            simclr_model, train_loader, test_loader, args.device, args.relic\n",
    "        )\n",
    "\n",
    "        arr_train_loader, arr_test_loader = create_data_loaders_from_arrays(\n",
    "            train_X, train_y, test_X, test_y, args.logistic_batch_size\n",
    "        )\n",
    "\n",
    "        for epoch in range(args.logistic_epochs):\n",
    "            loss_epoch, accuracy_epoch = train(\n",
    "                args, arr_train_loader, simclr_model, model, criterion, optimizer\n",
    "            )\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{args.logistic_epochs}]\\t Loss: {loss_epoch / len(arr_train_loader)}\\t Accuracy: {accuracy_epoch / len(arr_train_loader)}\"\n",
    "            )\n",
    "\n",
    "        # final testing\n",
    "        loss_epoch, accuracy_epoch = test(\n",
    "            args, arr_test_loader, simclr_model, model, criterion, optimizer\n",
    "        )\n",
    "        print(\n",
    "            f\"[FINAL]\\t Loss: {loss_epoch / len(arr_test_loader)}\\t Accuracy: {accuracy_epoch / len(arr_test_loader)}\"\n",
    "        )\n",
    "\n",
    "    #[TODO - ADDED] ReLIC\n",
    "    if args.relic == True:\n",
    "        relic_model = ReLIC(encoder, args.projection_dim, n_features)\n",
    "        model_fp = os.path.join(args.model_path, \"checkpoint_{}.tar\".format(args.epoch_num))\n",
    "        relic_model.load_state_dict(torch.load(model_fp, map_location=args.device.type))\n",
    "\n",
    "        #[TODO] JUST USE ENCODER PART ###CAUTION\n",
    "        #saved_n_features= relic_model.n_features\n",
    "        #relic_model= relic_model.encoder\n",
    "\n",
    "        relic_model = relic_model.to(args.device)\n",
    "        relic_model.eval()\n",
    "\n",
    "        \n",
    "\n",
    "        ## Logistic Regression\n",
    "        n_classes = 10  # CIFAR-10 / STL-10\n",
    "        #[TODO] JUST USE ENCODER PART ### CAUTION / OR USE Smaller Model (args.projection_dim)\n",
    "        #model = LogisticRegression(args.projection_dim, n_classes)\n",
    "        \n",
    "        model = LogisticRegression(relic_model.n_features, n_classes) #(relic_model.n_features, n_classes)= (512,10)\n",
    "        model = model.to(args.device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        print(\"### Creating features from pre-trained context model ###\")\n",
    "        (train_X, train_y, test_X, test_y) = get_features(\n",
    "            relic_model, train_loader, test_loader, args.device, args.relic\n",
    "        )\n",
    "\n",
    "        arr_train_loader, arr_test_loader = create_data_loaders_from_arrays(\n",
    "            train_X, train_y, test_X, test_y, args.logistic_batch_size\n",
    "        )\n",
    "\n",
    "        for epoch in range(args.logistic_epochs):\n",
    "            loss_epoch, accuracy_epoch = train(\n",
    "                args, arr_train_loader, relic_model, model, criterion, optimizer\n",
    "            )\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{args.logistic_epochs}]\\t Loss: {loss_epoch / len(arr_train_loader)}\\t Accuracy: {accuracy_epoch / len(arr_train_loader)}\"\n",
    "            )\n",
    "\n",
    "        # final testing\n",
    "        loss_epoch, accuracy_epoch = test(\n",
    "            args, arr_test_loader, relic_model, model, criterion, optimizer\n",
    "        )\n",
    "        print(\n",
    "            f\"[FINAL]\\t Loss: {loss_epoch / len(arr_test_loader)}\\t Accuracy: {accuracy_epoch / len(arr_test_loader)}\"\n",
    "        )\n",
    "    \n",
    "    \n",
    "    #NAIVE TRANSFER\n",
    "    #one more testing\n",
    "    pacs_convertor= {'default':DIR_PHOTO, 'photo':DIR_PHOTO, 'art':DIR_ART, 'cartoon':DIR_CARTOON, 'sketch':DIR_SKETCH}\n",
    "    train_dataset= torchvision.datasets.ImageFolder(pacs_convertor['sketch'], transform=TransformsSimCLR(size=args.image_size).test_transform)\n",
    "    test_dataset = torchvision.datasets.ImageFolder(pacs_convertor['sketch'], transform=TransformsSimCLR(size=args.image_size).test_transform)\n",
    "                \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=args.logistic_batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        num_workers=args.workers,\n",
    "    )\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=args.logistic_batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=True,\n",
    "        num_workers=args.workers,\n",
    "    )\n",
    "    \n",
    "    (train_X, train_y, test_X, test_y) = get_features(\n",
    "            simclr_model, train_loader, test_loader, args.device, args.relic\n",
    "        )\n",
    "    arr_train_loader, arr_test_loader = create_data_loaders_from_arrays(\n",
    "            train_X, train_y, test_X, test_y, args.logistic_batch_size\n",
    "        )\n",
    "    \n",
    "    if args.relic== False:\n",
    "        loss_epoch, accuracy_epoch = test(\n",
    "                args, arr_test_loader, simclr_model, model, criterion, optimizer\n",
    "            )\n",
    "        print(\n",
    "                f\"[Single DG]\\t Loss: {loss_epoch / len(arr_test_loader)}\\t Accuracy: {accuracy_epoch / len(arr_test_loader)}\"\n",
    "            )\n",
    "    \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c69b165e-05b8-4070-842a-6cae60bc00f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.test_dataset = 'CIFAR10'\n",
    "args.test_pacs_style= 'default'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e11a4c3-da63-4d87-9aab-f087fde518ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.prism= False\n",
    "args.relic= False\n",
    "args.projection_dim= 128\n",
    "args.model_path= 'save/monday/pacs_sdg'\n",
    "args.epoch_num= 500\n",
    "args.logistic_epochs= 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0126e51c-b3f7-47d2-becd-8ee0068570fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLIC -- False\n",
      "Model From -- save/monday/pacs_sdg, Epoch: 500\n",
      "All Evaluation args --  Namespace(nodes=1, gpus=1, nr=0, dataparallel=0, workers=8, dataset_dir='./datasets', seed=42, batch_size=128, image_size=224, start_epoch=0, epochs=500, dataset='PACS', pacs_style='default', test_dataset='CIFAR10', test_pacs_style='default', pretrain=False, relic=False, relic_normalize=True, relic_temp=1.0, relic_alpha=0.5, prism=False, resnet='resnet18', projection_dim=128, optimizer='LARS', weight_decay=1e-06, temperature=0.5, model_path='save/monday/pacs_sdg', epoch_num=500, reload=False, logistic_batch_size=256, logistic_epochs=500, device=device(type='cuda', index=0), num_gpus=4, world_size=1)\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "### Creating features from pre-trained context model ###\n",
      "Step [0/195]\t Computing features...\n",
      "Step [20/195]\t Computing features...\n",
      "Step [40/195]\t Computing features...\n",
      "Step [60/195]\t Computing features...\n",
      "Step [80/195]\t Computing features...\n",
      "Step [100/195]\t Computing features...\n",
      "Step [120/195]\t Computing features...\n",
      "Step [140/195]\t Computing features...\n",
      "Step [160/195]\t Computing features...\n",
      "Step [180/195]\t Computing features...\n",
      "Features shape (49920, 512)\n",
      "Step [0/39]\t Computing features...\n",
      "Step [20/39]\t Computing features...\n",
      "Features shape (9984, 512)\n",
      "Epoch [0/500]\t Loss: 1.8967825174331665\t Accuracy: 0.3489383012820513\n",
      "Epoch [1/500]\t Loss: 1.6494644599083141\t Accuracy: 0.42506009615384616\n",
      "Epoch [2/500]\t Loss: 1.5769067116272755\t Accuracy: 0.44479166666666664\n",
      "Epoch [3/500]\t Loss: 1.5347806704350007\t Accuracy: 0.45873397435897434\n",
      "Epoch [4/500]\t Loss: 1.504974714303628\t Accuracy: 0.46814903846153844\n",
      "Epoch [5/500]\t Loss: 1.4817579819605902\t Accuracy: 0.47620192307692305\n",
      "Epoch [6/500]\t Loss: 1.462639156366006\t Accuracy: 0.48219150641025643\n",
      "Epoch [7/500]\t Loss: 1.4463275878857345\t Accuracy: 0.48770032051282053\n",
      "Epoch [8/500]\t Loss: 1.4320708366540762\t Accuracy: 0.4930288461538462\n",
      "Epoch [9/500]\t Loss: 1.419390914379022\t Accuracy: 0.4980769230769231\n",
      "Epoch [10/500]\t Loss: 1.4079642460896418\t Accuracy: 0.5029847756410256\n",
      "Epoch [11/500]\t Loss: 1.3975606337571755\t Accuracy: 0.5064102564102564\n",
      "Epoch [12/500]\t Loss: 1.3880100488662719\t Accuracy: 0.5102964743589744\n",
      "Epoch [13/500]\t Loss: 1.3791829561575866\t Accuracy: 0.5138221153846154\n",
      "Epoch [14/500]\t Loss: 1.370978165895511\t Accuracy: 0.5176682692307693\n",
      "Epoch [15/500]\t Loss: 1.3633148939181596\t Accuracy: 0.5209735576923077\n",
      "Epoch [16/500]\t Loss: 1.3561276619250957\t Accuracy: 0.5238982371794871\n",
      "Epoch [17/500]\t Loss: 1.3493623855786445\t Accuracy: 0.5267427884615384\n",
      "Epoch [18/500]\t Loss: 1.3429739652535855\t Accuracy: 0.529286858974359\n",
      "Epoch [19/500]\t Loss: 1.3369243248915061\t Accuracy: 0.5315304487179487\n",
      "Epoch [20/500]\t Loss: 1.3311809784326798\t Accuracy: 0.5341145833333333\n",
      "Epoch [21/500]\t Loss: 1.3257160364053189\t Accuracy: 0.5357371794871795\n",
      "Epoch [22/500]\t Loss: 1.3205052100695096\t Accuracy: 0.5377403846153846\n",
      "Epoch [23/500]\t Loss: 1.3155273773731329\t Accuracy: 0.5396834935897435\n",
      "Epoch [24/500]\t Loss: 1.3107639673428657\t Accuracy: 0.541386217948718\n",
      "Epoch [25/500]\t Loss: 1.3061985621085535\t Accuracy: 0.5438301282051282\n",
      "Epoch [26/500]\t Loss: 1.3018165765664516\t Accuracy: 0.5456129807692308\n",
      "Epoch [27/500]\t Loss: 1.2976049985641087\t Accuracy: 0.5467147435897436\n",
      "Epoch [28/500]\t Loss: 1.2935521779916226\t Accuracy: 0.5480769230769231\n",
      "Epoch [29/500]\t Loss: 1.2896475785817856\t Accuracy: 0.5497395833333333\n",
      "Epoch [30/500]\t Loss: 1.285881726558392\t Accuracy: 0.5515625\n",
      "Epoch [31/500]\t Loss: 1.2822460351846157\t Accuracy: 0.5526442307692307\n",
      "Epoch [32/500]\t Loss: 1.278732651930589\t Accuracy: 0.553886217948718\n",
      "Epoch [33/500]\t Loss: 1.2753343948951135\t Accuracy: 0.5550480769230769\n",
      "Epoch [34/500]\t Loss: 1.2720448053800142\t Accuracy: 0.5565705128205128\n",
      "Epoch [35/500]\t Loss: 1.2688577902622713\t Accuracy: 0.5580729166666667\n",
      "Epoch [36/500]\t Loss: 1.2657678799751477\t Accuracy: 0.5591947115384616\n",
      "Epoch [37/500]\t Loss: 1.2627699815309965\t Accuracy: 0.559735576923077\n",
      "Epoch [38/500]\t Loss: 1.2598593485661043\t Accuracy: 0.560556891025641\n",
      "Epoch [39/500]\t Loss: 1.2570316565342439\t Accuracy: 0.5613982371794872\n",
      "Epoch [40/500]\t Loss: 1.2542828156397894\t Accuracy: 0.5624599358974359\n",
      "Epoch [41/500]\t Loss: 1.251609121224819\t Accuracy: 0.5635216346153846\n",
      "Epoch [42/500]\t Loss: 1.249007006180592\t Accuracy: 0.5645032051282052\n",
      "Epoch [43/500]\t Loss: 1.2464732053952339\t Accuracy: 0.5653645833333333\n",
      "Epoch [44/500]\t Loss: 1.2440047215192747\t Accuracy: 0.5662860576923077\n",
      "Epoch [45/500]\t Loss: 1.2415986501253569\t Accuracy: 0.5669270833333333\n",
      "Epoch [46/500]\t Loss: 1.239252296472207\t Accuracy: 0.5675280448717949\n",
      "Epoch [47/500]\t Loss: 1.2369631418815026\t Accuracy: 0.5684094551282052\n",
      "Epoch [48/500]\t Loss: 1.2347288315112774\t Accuracy: 0.569130608974359\n",
      "Epoch [49/500]\t Loss: 1.232547181691879\t Accuracy: 0.5698717948717948\n",
      "Epoch [50/500]\t Loss: 1.2304160179235997\t Accuracy: 0.5706530448717949\n",
      "Epoch [51/500]\t Loss: 1.2283334261331802\t Accuracy: 0.5711538461538461\n",
      "Epoch [52/500]\t Loss: 1.2262975173118786\t Accuracy: 0.5717548076923077\n",
      "Epoch [53/500]\t Loss: 1.224306514324286\t Accuracy: 0.5725160256410257\n",
      "Epoch [54/500]\t Loss: 1.2223587525196564\t Accuracy: 0.5730568910256411\n",
      "Epoch [55/500]\t Loss: 1.2204526448861146\t Accuracy: 0.5740384615384615\n",
      "Epoch [56/500]\t Loss: 1.2185867065038436\t Accuracy: 0.5748397435897435\n",
      "Epoch [57/500]\t Loss: 1.2167595129746658\t Accuracy: 0.5754206730769231\n",
      "Epoch [58/500]\t Loss: 1.214969713259966\t Accuracy: 0.5762019230769231\n",
      "Epoch [59/500]\t Loss: 1.2132160119521311\t Accuracy: 0.5765825320512821\n",
      "Epoch [60/500]\t Loss: 1.2114971906710894\t Accuracy: 0.5771434294871794\n",
      "Epoch [61/500]\t Loss: 1.2098121178455843\t Accuracy: 0.5776642628205129\n",
      "Epoch [62/500]\t Loss: 1.2081596215566\t Accuracy: 0.5783253205128205\n",
      "Epoch [63/500]\t Loss: 1.2065386949441372\t Accuracy: 0.5790264423076923\n",
      "Epoch [64/500]\t Loss: 1.204948342152131\t Accuracy: 0.5799078525641026\n",
      "Epoch [65/500]\t Loss: 1.2033875697698349\t Accuracy: 0.5804887820512821\n",
      "Epoch [66/500]\t Loss: 1.2018554644706922\t Accuracy: 0.5810296474358975\n",
      "Epoch [67/500]\t Loss: 1.2003511667251587\t Accuracy: 0.5814903846153846\n",
      "Epoch [68/500]\t Loss: 1.1988738047770964\t Accuracy: 0.5823116987179487\n",
      "Epoch [69/500]\t Loss: 1.1974225961245024\t Accuracy: 0.5826923076923077\n",
      "Epoch [70/500]\t Loss: 1.195996777827923\t Accuracy: 0.5834535256410256\n",
      "Epoch [71/500]\t Loss: 1.1945956010084886\t Accuracy: 0.5838741987179488\n",
      "Epoch [72/500]\t Loss: 1.1932183620257255\t Accuracy: 0.5841546474358974\n",
      "Epoch [73/500]\t Loss: 1.191864364575117\t Accuracy: 0.584755608974359\n",
      "Epoch [74/500]\t Loss: 1.190532985711709\t Accuracy: 0.5853365384615384\n",
      "Epoch [75/500]\t Loss: 1.1892235902639536\t Accuracy: 0.5859174679487179\n",
      "Epoch [76/500]\t Loss: 1.1879355852420515\t Accuracy: 0.5865384615384616\n",
      "Epoch [77/500]\t Loss: 1.1866683642069498\t Accuracy: 0.5867788461538461\n",
      "Epoch [78/500]\t Loss: 1.1854214228116549\t Accuracy: 0.5870392628205128\n",
      "Epoch [79/500]\t Loss: 1.1841941784589718\t Accuracy: 0.587459935897436\n",
      "Epoch [80/500]\t Loss: 1.1829861054053674\t Accuracy: 0.587900641025641\n",
      "Epoch [81/500]\t Loss: 1.1817967616594756\t Accuracy: 0.5883413461538461\n",
      "Epoch [82/500]\t Loss: 1.1806256599915332\t Accuracy: 0.5888822115384615\n",
      "Epoch [83/500]\t Loss: 1.17947228932992\t Accuracy: 0.5893830128205129\n",
      "Epoch [84/500]\t Loss: 1.1783362400837434\t Accuracy: 0.5898036858974359\n",
      "Epoch [85/500]\t Loss: 1.177217120390672\t Accuracy: 0.5900440705128205\n",
      "Epoch [86/500]\t Loss: 1.1761144595268445\t Accuracy: 0.5903245192307692\n",
      "Epoch [87/500]\t Loss: 1.1750278772451939\t Accuracy: 0.5907251602564103\n",
      "Epoch [88/500]\t Loss: 1.1739569786267403\t Accuracy: 0.5911057692307692\n",
      "Epoch [89/500]\t Loss: 1.172901410322923\t Accuracy: 0.591366185897436\n",
      "Epoch [90/500]\t Loss: 1.1718608195965106\t Accuracy: 0.5916666666666667\n",
      "Epoch [91/500]\t Loss: 1.1708348298684144\t Accuracy: 0.5921274038461538\n",
      "Epoch [92/500]\t Loss: 1.169823137919108\t Accuracy: 0.5925080128205128\n",
      "Epoch [93/500]\t Loss: 1.1688253775621071\t Accuracy: 0.5928084935897436\n",
      "Epoch [94/500]\t Loss: 1.1678412810350076\t Accuracy: 0.5930488782051282\n",
      "Epoch [95/500]\t Loss: 1.1668705072158423\t Accuracy: 0.5934094551282051\n",
      "Epoch [96/500]\t Loss: 1.1659127907875257\t Accuracy: 0.5935897435897436\n",
      "Epoch [97/500]\t Loss: 1.16496779246208\t Accuracy: 0.59375\n",
      "Epoch [98/500]\t Loss: 1.1640352707642776\t Accuracy: 0.5938501602564102\n",
      "Epoch [99/500]\t Loss: 1.1631149640450111\t Accuracy: 0.5940705128205128\n",
      "Epoch [100/500]\t Loss: 1.1622066228817671\t Accuracy: 0.5943910256410256\n",
      "Epoch [101/500]\t Loss: 1.1613099501683162\t Accuracy: 0.594511217948718\n",
      "Epoch [102/500]\t Loss: 1.16042472582597\t Accuracy: 0.5947916666666667\n",
      "Epoch [103/500]\t Loss: 1.1595507206060947\t Accuracy: 0.5950921474358974\n",
      "Epoch [104/500]\t Loss: 1.1586876942561224\t Accuracy: 0.5953525641025641\n",
      "Epoch [105/500]\t Loss: 1.1578353839042859\t Accuracy: 0.5957732371794872\n",
      "Epoch [106/500]\t Loss: 1.156993654446724\t Accuracy: 0.5959535256410257\n",
      "Epoch [107/500]\t Loss: 1.1561622326190655\t Accuracy: 0.5964142628205128\n",
      "Epoch [108/500]\t Loss: 1.1553409215731498\t Accuracy: 0.5966145833333333\n",
      "Epoch [109/500]\t Loss: 1.1545295195701795\t Accuracy: 0.5967147435897436\n",
      "Epoch [110/500]\t Loss: 1.1537278639964568\t Accuracy: 0.5970552884615384\n",
      "Epoch [111/500]\t Loss: 1.1529357237693592\t Accuracy: 0.5971554487179487\n",
      "Epoch [112/500]\t Loss: 1.152152928022238\t Accuracy: 0.5974759615384615\n",
      "Epoch [113/500]\t Loss: 1.151379317503709\t Accuracy: 0.5977564102564102\n",
      "Epoch [114/500]\t Loss: 1.1506146947542826\t Accuracy: 0.5979567307692307\n",
      "Epoch [115/500]\t Loss: 1.149858897160261\t Accuracy: 0.598036858974359\n",
      "Epoch [116/500]\t Loss: 1.1491117725005517\t Accuracy: 0.5983573717948718\n",
      "Epoch [117/500]\t Loss: 1.1483731334026044\t Accuracy: 0.5985777243589744\n",
      "Epoch [118/500]\t Loss: 1.1476428245886778\t Accuracy: 0.598838141025641\n",
      "Epoch [119/500]\t Loss: 1.1469207231815044\t Accuracy: 0.5989983974358974\n",
      "Epoch [120/500]\t Loss: 1.1462066827676236\t Accuracy: 0.5990584935897436\n",
      "Epoch [121/500]\t Loss: 1.1455005034422263\t Accuracy: 0.5993389423076924\n",
      "Epoch [122/500]\t Loss: 1.1448020919775352\t Accuracy: 0.5995392628205128\n",
      "Epoch [123/500]\t Loss: 1.1441113034884134\t Accuracy: 0.5998597756410257\n",
      "Epoch [124/500]\t Loss: 1.143427980557466\t Accuracy: 0.6001802884615385\n",
      "Epoch [125/500]\t Loss: 1.1427520437118335\t Accuracy: 0.6005809294871794\n",
      "Epoch [126/500]\t Loss: 1.1420833031336466\t Accuracy: 0.60078125\n",
      "Epoch [127/500]\t Loss: 1.14142167140276\t Accuracy: 0.6009615384615384\n",
      "Epoch [128/500]\t Loss: 1.1407670186116146\t Accuracy: 0.6011418269230769\n",
      "Epoch [129/500]\t Loss: 1.1401192075166946\t Accuracy: 0.6015224358974359\n",
      "Epoch [130/500]\t Loss: 1.139478168426416\t Accuracy: 0.6017427884615385\n",
      "Epoch [131/500]\t Loss: 1.138843753398993\t Accuracy: 0.6020633012820513\n",
      "Epoch [132/500]\t Loss: 1.1382158768482697\t Accuracy: 0.6021634615384616\n",
      "Epoch [133/500]\t Loss: 1.137594359348982\t Accuracy: 0.6024238782051282\n",
      "Epoch [134/500]\t Loss: 1.1369791947878325\t Accuracy: 0.6028044871794872\n",
      "Epoch [135/500]\t Loss: 1.1363702214681186\t Accuracy: 0.6029847756410256\n",
      "Epoch [136/500]\t Loss: 1.1357673495243756\t Accuracy: 0.6033854166666667\n",
      "Epoch [137/500]\t Loss: 1.1351704707512489\t Accuracy: 0.6036258012820512\n",
      "Epoch [138/500]\t Loss: 1.134579509955186\t Accuracy: 0.6039262820512821\n",
      "Epoch [139/500]\t Loss: 1.1339943519005409\t Accuracy: 0.6042668269230769\n",
      "Epoch [140/500]\t Loss: 1.13341492383908\t Accuracy: 0.6045472756410256\n",
      "Epoch [141/500]\t Loss: 1.132841122150421\t Accuracy: 0.604707532051282\n",
      "Epoch [142/500]\t Loss: 1.132272882033617\t Accuracy: 0.6049078525641025\n",
      "Epoch [143/500]\t Loss: 1.1317100922266643\t Accuracy: 0.6051883012820513\n",
      "Epoch [144/500]\t Loss: 1.1311526656150819\t Accuracy: 0.6055488782051283\n",
      "Epoch [145/500]\t Loss: 1.1306005438168845\t Accuracy: 0.6056690705128205\n",
      "Epoch [146/500]\t Loss: 1.1300536311589755\t Accuracy: 0.6059695512820513\n",
      "Epoch [147/500]\t Loss: 1.1295118466401712\t Accuracy: 0.60625\n",
      "Epoch [148/500]\t Loss: 1.1289751141499251\t Accuracy: 0.6064903846153846\n",
      "Epoch [149/500]\t Loss: 1.128443374694922\t Accuracy: 0.6066706730769231\n",
      "Epoch [150/500]\t Loss: 1.1279165215981313\t Accuracy: 0.6067508012820513\n",
      "Epoch [151/500]\t Loss: 1.1273945224590791\t Accuracy: 0.6069711538461539\n",
      "Epoch [152/500]\t Loss: 1.1268772681554158\t Accuracy: 0.6070713141025641\n",
      "Epoch [153/500]\t Loss: 1.1263646920522055\t Accuracy: 0.6071714743589743\n",
      "Epoch [154/500]\t Loss: 1.125856775809557\t Accuracy: 0.6073918269230769\n",
      "Epoch [155/500]\t Loss: 1.125353378515977\t Accuracy: 0.6075520833333333\n",
      "Epoch [156/500]\t Loss: 1.1248544992544711\t Accuracy: 0.6077323717948718\n",
      "Epoch [157/500]\t Loss: 1.1243600463255858\t Accuracy: 0.6078125\n",
      "Epoch [158/500]\t Loss: 1.1238699454527634\t Accuracy: 0.607792467948718\n",
      "Epoch [159/500]\t Loss: 1.123384159650558\t Accuracy: 0.6078725961538461\n",
      "Epoch [160/500]\t Loss: 1.1229026183103903\t Accuracy: 0.6080729166666666\n",
      "Epoch [161/500]\t Loss: 1.1224252560199834\t Accuracy: 0.6080929487179487\n",
      "Epoch [162/500]\t Loss: 1.1219520156200116\t Accuracy: 0.6083133012820513\n",
      "Epoch [163/500]\t Loss: 1.1214828650156656\t Accuracy: 0.6085136217948718\n",
      "Epoch [164/500]\t Loss: 1.12101770731119\t Accuracy: 0.6086538461538461\n",
      "Epoch [165/500]\t Loss: 1.1205565186647268\t Accuracy: 0.6088541666666667\n",
      "Epoch [166/500]\t Loss: 1.1200992171580975\t Accuracy: 0.6090544871794872\n",
      "Epoch [167/500]\t Loss: 1.1196457920930325\t Accuracy: 0.6093149038461538\n",
      "Epoch [168/500]\t Loss: 1.1191961566607158\t Accuracy: 0.6094150641025641\n",
      "Epoch [169/500]\t Loss: 1.1187502598151182\t Accuracy: 0.6094951923076923\n",
      "Epoch [170/500]\t Loss: 1.1183080969712673\t Accuracy: 0.6095352564102564\n",
      "Epoch [171/500]\t Loss: 1.1178695406669226\t Accuracy: 0.6096955128205128\n",
      "Epoch [172/500]\t Loss: 1.1174346071023207\t Accuracy: 0.6098758012820513\n",
      "Epoch [173/500]\t Loss: 1.1170032305595203\t Accuracy: 0.6099759615384616\n",
      "Epoch [174/500]\t Loss: 1.1165753602981567\t Accuracy: 0.610136217948718\n",
      "Epoch [175/500]\t Loss: 1.1161509755330208\t Accuracy: 0.6102564102564103\n",
      "Epoch [176/500]\t Loss: 1.1157299891496315\t Accuracy: 0.6104767628205128\n",
      "Epoch [177/500]\t Loss: 1.115312375777807\t Accuracy: 0.6106570512820513\n",
      "Epoch [178/500]\t Loss: 1.114898107907711\t Accuracy: 0.6108573717948718\n",
      "Epoch [179/500]\t Loss: 1.1144871149307642\t Accuracy: 0.6111778846153846\n",
      "Epoch [180/500]\t Loss: 1.1140793821750543\t Accuracy: 0.6114983974358974\n",
      "Epoch [181/500]\t Loss: 1.1136748530925848\t Accuracy: 0.611758814102564\n",
      "Epoch [182/500]\t Loss: 1.1132735090378003\t Accuracy: 0.6119391025641026\n",
      "Epoch [183/500]\t Loss: 1.1128752977420122\t Accuracy: 0.6121794871794872\n",
      "Epoch [184/500]\t Loss: 1.1124801519589547\t Accuracy: 0.6122996794871794\n",
      "Epoch [185/500]\t Loss: 1.1120880719942925\t Accuracy: 0.6123798076923077\n",
      "Epoch [186/500]\t Loss: 1.1116990064963317\t Accuracy: 0.612479967948718\n",
      "Epoch [187/500]\t Loss: 1.1113129215362745\t Accuracy: 0.6126402243589744\n",
      "Epoch [188/500]\t Loss: 1.1109297770720261\t Accuracy: 0.6127804487179487\n",
      "Epoch [189/500]\t Loss: 1.1105495596543336\t Accuracy: 0.6129607371794872\n",
      "Epoch [190/500]\t Loss: 1.1101721696364575\t Accuracy: 0.6130608974358974\n",
      "Epoch [191/500]\t Loss: 1.1097976385018764\t Accuracy: 0.6131810897435898\n",
      "Epoch [192/500]\t Loss: 1.1094259225405179\t Accuracy: 0.61328125\n",
      "Epoch [193/500]\t Loss: 1.10905697620832\t Accuracy: 0.6134214743589743\n",
      "Epoch [194/500]\t Loss: 1.1086907784144084\t Accuracy: 0.6135016025641026\n",
      "Epoch [195/500]\t Loss: 1.1083272487689286\t Accuracy: 0.6135216346153847\n",
      "Epoch [196/500]\t Loss: 1.1079664279253054\t Accuracy: 0.613661858974359\n",
      "Epoch [197/500]\t Loss: 1.1076082547505697\t Accuracy: 0.6139423076923077\n",
      "Epoch [198/500]\t Loss: 1.1072526714740656\t Accuracy: 0.6141426282051282\n",
      "Epoch [199/500]\t Loss: 1.106899683903425\t Accuracy: 0.6142628205128206\n",
      "Epoch [200/500]\t Loss: 1.1065492550532023\t Accuracy: 0.6145633012820513\n",
      "Epoch [201/500]\t Loss: 1.106201347326621\t Accuracy: 0.6146834935897436\n",
      "Epoch [202/500]\t Loss: 1.1058559243495647\t Accuracy: 0.6148237179487179\n",
      "Epoch [203/500]\t Loss: 1.105512984899374\t Accuracy: 0.6148237179487179\n",
      "Epoch [204/500]\t Loss: 1.1051724653977615\t Accuracy: 0.6149038461538462\n",
      "Epoch [205/500]\t Loss: 1.1048343899922493\t Accuracy: 0.6151241987179488\n",
      "Epoch [206/500]\t Loss: 1.1044986666777195\t Accuracy: 0.6152644230769231\n",
      "Epoch [207/500]\t Loss: 1.1041653241866674\t Accuracy: 0.6153846153846154\n",
      "Epoch [208/500]\t Loss: 1.10383429924647\t Accuracy: 0.6155649038461538\n",
      "Epoch [209/500]\t Loss: 1.1035056056120456\t Accuracy: 0.615625\n",
      "Epoch [210/500]\t Loss: 1.10317918245609\t Accuracy: 0.6157051282051282\n",
      "Epoch [211/500]\t Loss: 1.1028550251936302\t Accuracy: 0.6155849358974359\n",
      "Epoch [212/500]\t Loss: 1.1025330806389833\t Accuracy: 0.6158854166666666\n",
      "Epoch [213/500]\t Loss: 1.102213373245337\t Accuracy: 0.6159655448717949\n",
      "Epoch [214/500]\t Loss: 1.1018958296531285\t Accuracy: 0.6162059294871794\n",
      "Epoch [215/500]\t Loss: 1.1015804422207367\t Accuracy: 0.6162459935897436\n",
      "Epoch [216/500]\t Loss: 1.1012672295937171\t Accuracy: 0.616426282051282\n",
      "Epoch [217/500]\t Loss: 1.1009560976272974\t Accuracy: 0.6165064102564103\n",
      "Epoch [218/500]\t Loss: 1.100647085140913\t Accuracy: 0.616426282051282\n",
      "Epoch [219/500]\t Loss: 1.100340106854072\t Accuracy: 0.6165264423076923\n",
      "Epoch [220/500]\t Loss: 1.100035203114534\t Accuracy: 0.6167267628205129\n",
      "Epoch [221/500]\t Loss: 1.099732334797199\t Accuracy: 0.6167868589743589\n",
      "Epoch [222/500]\t Loss: 1.099431475920555\t Accuracy: 0.6167668269230769\n",
      "Epoch [223/500]\t Loss: 1.0991326075333816\t Accuracy: 0.6168669871794872\n",
      "Epoch [224/500]\t Loss: 1.0988356871482654\t Accuracy: 0.6169471153846153\n",
      "Epoch [225/500]\t Loss: 1.0985407242408165\t Accuracy: 0.6170072115384615\n",
      "Epoch [226/500]\t Loss: 1.0982476766292866\t Accuracy: 0.6171474358974359\n",
      "Epoch [227/500]\t Loss: 1.0979565421740214\t Accuracy: 0.6171875\n",
      "Epoch [228/500]\t Loss: 1.0976673037577898\t Accuracy: 0.6173878205128205\n",
      "Epoch [229/500]\t Loss: 1.0973799243951454\t Accuracy: 0.6175080128205128\n",
      "Epoch [230/500]\t Loss: 1.0970944077540667\t Accuracy: 0.6176081730769231\n",
      "Epoch [231/500]\t Loss: 1.0968107119584696\t Accuracy: 0.6176883012820513\n",
      "Epoch [232/500]\t Loss: 1.0965288223364413\t Accuracy: 0.6176682692307692\n",
      "Epoch [233/500]\t Loss: 1.0962487364426636\t Accuracy: 0.6178485576923077\n",
      "Epoch [234/500]\t Loss: 1.0959704267673003\t Accuracy: 0.6180288461538461\n",
      "Epoch [235/500]\t Loss: 1.095693882000752\t Accuracy: 0.6182291666666667\n",
      "Epoch [236/500]\t Loss: 1.0954190672972264\t Accuracy: 0.6182692307692308\n",
      "Epoch [237/500]\t Loss: 1.0951459964116415\t Accuracy: 0.6182491987179487\n",
      "Epoch [238/500]\t Loss: 1.0948746134073306\t Accuracy: 0.6182491987179487\n",
      "Epoch [239/500]\t Loss: 1.0946049286768986\t Accuracy: 0.618329326923077\n",
      "Epoch [240/500]\t Loss: 1.0943369147105095\t Accuracy: 0.618369391025641\n",
      "Epoch [241/500]\t Loss: 1.0940705782327897\t Accuracy: 0.6185096153846154\n",
      "Epoch [242/500]\t Loss: 1.0938058895942493\t Accuracy: 0.6184895833333334\n",
      "Epoch [243/500]\t Loss: 1.093542799888513\t Accuracy: 0.6185697115384615\n",
      "Epoch [244/500]\t Loss: 1.093281327149807\t Accuracy: 0.6186097756410256\n",
      "Epoch [245/500]\t Loss: 1.0930214628195152\t Accuracy: 0.6186097756410256\n",
      "Epoch [246/500]\t Loss: 1.0927631754141587\t Accuracy: 0.6186498397435898\n",
      "Epoch [247/500]\t Loss: 1.0925064707413699\t Accuracy: 0.6186899038461539\n",
      "Epoch [248/500]\t Loss: 1.0922513005061028\t Accuracy: 0.6187900641025641\n",
      "Epoch [249/500]\t Loss: 1.0919976763236217\t Accuracy: 0.6188501602564103\n",
      "Epoch [250/500]\t Loss: 1.0917455703784258\t Accuracy: 0.6189302884615384\n",
      "Epoch [251/500]\t Loss: 1.091494963107965\t Accuracy: 0.6189703525641026\n",
      "Epoch [252/500]\t Loss: 1.0912458609312008\t Accuracy: 0.6190104166666667\n",
      "Epoch [253/500]\t Loss: 1.0909982552895179\t Accuracy: 0.6190905448717948\n",
      "Epoch [254/500]\t Loss: 1.0907521119484536\t Accuracy: 0.619150641025641\n",
      "Epoch [255/500]\t Loss: 1.090507414096441\t Accuracy: 0.619150641025641\n",
      "Epoch [256/500]\t Loss: 1.0902641574541727\t Accuracy: 0.6192708333333333\n",
      "Epoch [257/500]\t Loss: 1.0900223392706652\t Accuracy: 0.6193309294871795\n",
      "Epoch [258/500]\t Loss: 1.0897819167528398\t Accuracy: 0.6194310897435897\n",
      "Epoch [259/500]\t Loss: 1.0895429180218623\t Accuracy: 0.6193509615384616\n",
      "Epoch [260/500]\t Loss: 1.0893053005903195\t Accuracy: 0.6194711538461538\n",
      "Epoch [261/500]\t Loss: 1.0890690742394864\t Accuracy: 0.61953125\n",
      "Epoch [262/500]\t Loss: 1.088834192813971\t Accuracy: 0.6194911858974359\n",
      "Epoch [263/500]\t Loss: 1.0886006700686919\t Accuracy: 0.619511217948718\n",
      "Epoch [264/500]\t Loss: 1.0883685041696598\t Accuracy: 0.619511217948718\n",
      "Epoch [265/500]\t Loss: 1.0881376303159274\t Accuracy: 0.619571314102564\n",
      "Epoch [266/500]\t Loss: 1.0879080992478591\t Accuracy: 0.6197115384615385\n",
      "Epoch [267/500]\t Loss: 1.087679881315965\t Accuracy: 0.6197115384615385\n",
      "Epoch [268/500]\t Loss: 1.0874529621539972\t Accuracy: 0.6197716346153846\n",
      "Epoch [269/500]\t Loss: 1.087227307833158\t Accuracy: 0.6198517628205128\n",
      "Epoch [270/500]\t Loss: 1.0870029299687116\t Accuracy: 0.619951923076923\n",
      "Epoch [271/500]\t Loss: 1.0867798196963774\t Accuracy: 0.6201522435897436\n",
      "Epoch [272/500]\t Loss: 1.0865579516459734\t Accuracy: 0.6202724358974359\n",
      "Epoch [273/500]\t Loss: 1.086337352104676\t Accuracy: 0.6202724358974359\n",
      "Epoch [274/500]\t Loss: 1.0861179455732688\t Accuracy: 0.6203725961538461\n",
      "Epoch [275/500]\t Loss: 1.0858997690371979\t Accuracy: 0.6204527243589744\n",
      "Epoch [276/500]\t Loss: 1.0856828179114903\t Accuracy: 0.6205128205128205\n",
      "Epoch [277/500]\t Loss: 1.08546703625948\t Accuracy: 0.6205128205128205\n",
      "Epoch [278/500]\t Loss: 1.085252452813662\t Accuracy: 0.6205929487179487\n",
      "Epoch [279/500]\t Loss: 1.0850390568757668\t Accuracy: 0.6206330128205129\n",
      "Epoch [280/500]\t Loss: 1.084826817573645\t Accuracy: 0.6206129807692308\n",
      "Epoch [281/500]\t Loss: 1.0846157511075338\t Accuracy: 0.620713141025641\n",
      "Epoch [282/500]\t Loss: 1.0844058281336075\t Accuracy: 0.6207532051282051\n",
      "Epoch [283/500]\t Loss: 1.0841970403989156\t Accuracy: 0.6208133012820513\n",
      "Epoch [284/500]\t Loss: 1.083989382095826\t Accuracy: 0.6208133012820513\n",
      "Epoch [285/500]\t Loss: 1.083782842220404\t Accuracy: 0.6208533653846153\n",
      "Epoch [286/500]\t Loss: 1.0835774299425958\t Accuracy: 0.6206931089743589\n",
      "Epoch [287/500]\t Loss: 1.0833731128619268\t Accuracy: 0.620713141025641\n",
      "Epoch [288/500]\t Loss: 1.0831698811971224\t Accuracy: 0.6207331730769231\n",
      "Epoch [289/500]\t Loss: 1.0829677444237928\t Accuracy: 0.6207932692307693\n",
      "Epoch [290/500]\t Loss: 1.0827666710584591\t Accuracy: 0.6208333333333333\n",
      "Epoch [291/500]\t Loss: 1.0825666641577696\t Accuracy: 0.6208533653846153\n",
      "Epoch [292/500]\t Loss: 1.0823677114951304\t Accuracy: 0.6208533653846153\n",
      "Epoch [293/500]\t Loss: 1.0821698476106694\t Accuracy: 0.6210336538461538\n",
      "Epoch [294/500]\t Loss: 1.0819729860012348\t Accuracy: 0.6211137820512821\n",
      "Epoch [295/500]\t Loss: 1.0817771853544773\t Accuracy: 0.6211738782051283\n",
      "Epoch [296/500]\t Loss: 1.0815823790354606\t Accuracy: 0.6211939102564102\n",
      "Epoch [297/500]\t Loss: 1.0813886043352958\t Accuracy: 0.6213741987179487\n",
      "Epoch [298/500]\t Loss: 1.081195825796861\t Accuracy: 0.6214342948717949\n",
      "Epoch [299/500]\t Loss: 1.0810040577864035\t Accuracy: 0.6215144230769231\n",
      "Epoch [300/500]\t Loss: 1.0808132935792971\t Accuracy: 0.6216145833333333\n",
      "Epoch [301/500]\t Loss: 1.0806234977184197\t Accuracy: 0.6215945512820513\n",
      "Epoch [302/500]\t Loss: 1.080434696185283\t Accuracy: 0.6216947115384616\n",
      "Epoch [303/500]\t Loss: 1.0802468510774466\t Accuracy: 0.621875\n",
      "Epoch [304/500]\t Loss: 1.0800599789008116\t Accuracy: 0.6219551282051282\n",
      "Epoch [305/500]\t Loss: 1.0798740674287846\t Accuracy: 0.6219751602564103\n",
      "Epoch [306/500]\t Loss: 1.07968907784193\t Accuracy: 0.6220552884615385\n",
      "Epoch [307/500]\t Loss: 1.079505049265348\t Accuracy: 0.6221554487179487\n",
      "Epoch [308/500]\t Loss: 1.079321951743884\t Accuracy: 0.6221153846153846\n",
      "Epoch [309/500]\t Loss: 1.079139755016718\t Accuracy: 0.6221554487179487\n",
      "Epoch [310/500]\t Loss: 1.0789585156318469\t Accuracy: 0.6223157051282051\n",
      "Epoch [311/500]\t Loss: 1.078778166954334\t Accuracy: 0.6225761217948718\n",
      "Epoch [312/500]\t Loss: 1.0785987316033778\t Accuracy: 0.6226963141025641\n",
      "Epoch [313/500]\t Loss: 1.0784201906277584\t Accuracy: 0.6227363782051282\n",
      "Epoch [314/500]\t Loss: 1.0782425354688596\t Accuracy: 0.6228165064102564\n",
      "Epoch [315/500]\t Loss: 1.0780657762136214\t Accuracy: 0.6227964743589743\n",
      "Epoch [316/500]\t Loss: 1.0778898725142845\t Accuracy: 0.6229366987179488\n",
      "Epoch [317/500]\t Loss: 1.0777148711375701\t Accuracy: 0.6229166666666667\n",
      "Epoch [318/500]\t Loss: 1.0775407124788334\t Accuracy: 0.6229967948717948\n",
      "Epoch [319/500]\t Loss: 1.077367412738311\t Accuracy: 0.623036858974359\n",
      "Epoch [320/500]\t Loss: 1.0771949743613218\t Accuracy: 0.6230168269230769\n",
      "Epoch [321/500]\t Loss: 1.0770233985705253\t Accuracy: 0.6231169871794872\n",
      "Epoch [322/500]\t Loss: 1.0768526279009305\t Accuracy: 0.6231570512820512\n",
      "Epoch [323/500]\t Loss: 1.076682710341918\t Accuracy: 0.6232171474358974\n",
      "Epoch [324/500]\t Loss: 1.0765136058513936\t Accuracy: 0.6232972756410257\n",
      "Epoch [325/500]\t Loss: 1.0763453477468246\t Accuracy: 0.6233974358974359\n",
      "Epoch [326/500]\t Loss: 1.0761778794802153\t Accuracy: 0.6234975961538461\n",
      "Epoch [327/500]\t Loss: 1.0760112285614014\t Accuracy: 0.6235576923076923\n",
      "Epoch [328/500]\t Loss: 1.0758454017150096\t Accuracy: 0.6236378205128205\n",
      "Epoch [329/500]\t Loss: 1.075680336279747\t Accuracy: 0.6236979166666666\n",
      "Epoch [330/500]\t Loss: 1.0755160998075437\t Accuracy: 0.623818108974359\n",
      "Epoch [331/500]\t Loss: 1.0753526268861233\t Accuracy: 0.6239583333333333\n",
      "Epoch [332/500]\t Loss: 1.0751899529726077\t Accuracy: 0.6240384615384615\n",
      "Epoch [333/500]\t Loss: 1.075028038636232\t Accuracy: 0.6240584935897436\n",
      "Epoch [334/500]\t Loss: 1.0748668857109853\t Accuracy: 0.6241586538461539\n",
      "Epoch [335/500]\t Loss: 1.0747065097857744\t Accuracy: 0.6241185897435897\n",
      "Epoch [336/500]\t Loss: 1.0745469019963192\t Accuracy: 0.6241386217948718\n",
      "Epoch [337/500]\t Loss: 1.0743880381950965\t Accuracy: 0.624238782051282\n",
      "Epoch [338/500]\t Loss: 1.0742299107404856\t Accuracy: 0.6241786858974359\n",
      "Epoch [339/500]\t Loss: 1.0740725395007011\t Accuracy: 0.62421875\n",
      "Epoch [340/500]\t Loss: 1.0739159018565447\t Accuracy: 0.6241786858974359\n",
      "Epoch [341/500]\t Loss: 1.0737599968910216\t Accuracy: 0.62421875\n",
      "Epoch [342/500]\t Loss: 1.0736048343854072\t Accuracy: 0.6243189102564103\n",
      "Epoch [343/500]\t Loss: 1.0734503571803753\t Accuracy: 0.6243589743589744\n",
      "Epoch [344/500]\t Loss: 1.0732966285485488\t Accuracy: 0.6245592948717948\n",
      "Epoch [345/500]\t Loss: 1.073143621897086\t Accuracy: 0.6245592948717948\n",
      "Epoch [346/500]\t Loss: 1.0729912867912879\t Accuracy: 0.6245993589743589\n",
      "Epoch [347/500]\t Loss: 1.0728396901717552\t Accuracy: 0.624619391025641\n",
      "Epoch [348/500]\t Loss: 1.0726887687658653\t Accuracy: 0.6247395833333333\n",
      "Epoch [349/500]\t Loss: 1.072538550083454\t Accuracy: 0.6247195512820513\n",
      "Epoch [350/500]\t Loss: 1.0723890197582735\t Accuracy: 0.6247596153846153\n",
      "Epoch [351/500]\t Loss: 1.0722401744280106\t Accuracy: 0.6247395833333333\n",
      "Epoch [352/500]\t Loss: 1.0720920015604067\t Accuracy: 0.6247796474358974\n",
      "Epoch [353/500]\t Loss: 1.0719444984044784\t Accuracy: 0.6247596153846153\n",
      "Epoch [354/500]\t Loss: 1.0717976753528302\t Accuracy: 0.6246995192307693\n",
      "Epoch [355/500]\t Loss: 1.0716515229298518\t Accuracy: 0.6245993589743589\n",
      "Epoch [356/500]\t Loss: 1.0715060142370372\t Accuracy: 0.624619391025641\n",
      "Epoch [357/500]\t Loss: 1.071361182591854\t Accuracy: 0.6246594551282051\n",
      "Epoch [358/500]\t Loss: 1.071216997427818\t Accuracy: 0.6246594551282051\n",
      "Epoch [359/500]\t Loss: 1.0710734294011042\t Accuracy: 0.6246594551282051\n",
      "Epoch [360/500]\t Loss: 1.070930560124226\t Accuracy: 0.6246594551282051\n",
      "Epoch [361/500]\t Loss: 1.0707882878107902\t Accuracy: 0.6247596153846153\n",
      "Epoch [362/500]\t Loss: 1.0706466723711063\t Accuracy: 0.6248998397435898\n",
      "Epoch [363/500]\t Loss: 1.070505698216267\t Accuracy: 0.6249399038461538\n",
      "Epoch [364/500]\t Loss: 1.070365325304178\t Accuracy: 0.625\n",
      "Epoch [365/500]\t Loss: 1.0702255728917245\t Accuracy: 0.6251001602564102\n",
      "Epoch [366/500]\t Loss: 1.070086455345154\t Accuracy: 0.6250600961538462\n",
      "Epoch [367/500]\t Loss: 1.0699479365960145\t Accuracy: 0.6250600961538462\n",
      "Epoch [368/500]\t Loss: 1.0698100521014287\t Accuracy: 0.6252003205128205\n",
      "Epoch [369/500]\t Loss: 1.0696727535663506\t Accuracy: 0.6252203525641026\n",
      "Epoch [370/500]\t Loss: 1.0695360526060447\t Accuracy: 0.6253405448717949\n",
      "Epoch [371/500]\t Loss: 1.0693999617527692\t Accuracy: 0.6254407051282052\n",
      "Epoch [372/500]\t Loss: 1.069264470308255\t Accuracy: 0.6255008012820513\n",
      "Epoch [373/500]\t Loss: 1.0691295632949243\t Accuracy: 0.6254407051282052\n",
      "Epoch [374/500]\t Loss: 1.0689952373504639\t Accuracy: 0.6255408653846154\n",
      "Epoch [375/500]\t Loss: 1.0688615202903748\t Accuracy: 0.6255008012820513\n",
      "Epoch [376/500]\t Loss: 1.0687283711555677\t Accuracy: 0.6255608974358975\n",
      "Epoch [377/500]\t Loss: 1.0685957896403777\t Accuracy: 0.6256009615384616\n",
      "Epoch [378/500]\t Loss: 1.0684637824694316\t Accuracy: 0.6256610576923077\n",
      "Epoch [379/500]\t Loss: 1.0683323343594868\t Accuracy: 0.6257011217948718\n",
      "Epoch [380/500]\t Loss: 1.0682014712920556\t Accuracy: 0.6256810897435897\n",
      "Epoch [381/500]\t Loss: 1.0680711602553343\t Accuracy: 0.6257011217948718\n",
      "Epoch [382/500]\t Loss: 1.0679414186722194\t Accuracy: 0.6257211538461539\n",
      "Epoch [383/500]\t Loss: 1.0678122086402697\t Accuracy: 0.6256410256410256\n",
      "Epoch [384/500]\t Loss: 1.0676835714242396\t Accuracy: 0.6257011217948718\n",
      "Epoch [385/500]\t Loss: 1.0675554648423806\t Accuracy: 0.625761217948718\n",
      "Epoch [386/500]\t Loss: 1.0674279240461497\t Accuracy: 0.6258413461538461\n",
      "Epoch [387/500]\t Loss: 1.0673009034914849\t Accuracy: 0.6258613782051282\n",
      "Epoch [388/500]\t Loss: 1.0671744343562004\t Accuracy: 0.6259014423076923\n",
      "Epoch [389/500]\t Loss: 1.0670484872964712\t Accuracy: 0.6259615384615385\n",
      "Epoch [390/500]\t Loss: 1.066923080652188\t Accuracy: 0.6259815705128206\n",
      "Epoch [391/500]\t Loss: 1.066798194249471\t Accuracy: 0.6260016025641025\n",
      "Epoch [392/500]\t Loss: 1.0666738528471726\t Accuracy: 0.6259815705128206\n",
      "Epoch [393/500]\t Loss: 1.0665500026482801\t Accuracy: 0.6260216346153846\n",
      "Epoch [394/500]\t Loss: 1.0664266800269102\t Accuracy: 0.6260216346153846\n",
      "Epoch [395/500]\t Loss: 1.0663038837604033\t Accuracy: 0.6261017628205128\n",
      "Epoch [396/500]\t Loss: 1.0661815942862094\t Accuracy: 0.6261217948717949\n",
      "Epoch [397/500]\t Loss: 1.0660598076306858\t Accuracy: 0.6260817307692308\n",
      "Epoch [398/500]\t Loss: 1.0659385283788045\t Accuracy: 0.6260416666666667\n",
      "Epoch [399/500]\t Loss: 1.0658177718138084\t Accuracy: 0.6260817307692308\n",
      "Epoch [400/500]\t Loss: 1.065697479248047\t Accuracy: 0.6260216346153846\n",
      "Epoch [401/500]\t Loss: 1.0655776971425766\t Accuracy: 0.6261217948717949\n",
      "Epoch [402/500]\t Loss: 1.0654584147991277\t Accuracy: 0.6261618589743589\n",
      "Epoch [403/500]\t Loss: 1.0653396340516896\t Accuracy: 0.6262019230769231\n",
      "Epoch [404/500]\t Loss: 1.0652213286130856\t Accuracy: 0.6262219551282051\n",
      "Epoch [405/500]\t Loss: 1.0651035049022772\t Accuracy: 0.6263221153846154\n",
      "Epoch [406/500]\t Loss: 1.0649861613909404\t Accuracy: 0.6263421474358974\n",
      "Epoch [407/500]\t Loss: 1.0648692993017344\t Accuracy: 0.6264222756410256\n",
      "Epoch [408/500]\t Loss: 1.0647529048797413\t Accuracy: 0.6264823717948718\n",
      "Epoch [409/500]\t Loss: 1.064637009302775\t Accuracy: 0.6264823717948718\n",
      "Epoch [410/500]\t Loss: 1.0645215572454991\t Accuracy: 0.6265024038461539\n",
      "Epoch [411/500]\t Loss: 1.0644065887500078\t Accuracy: 0.6266225961538462\n",
      "Epoch [412/500]\t Loss: 1.0642920763064654\t Accuracy: 0.6266426282051282\n",
      "Epoch [413/500]\t Loss: 1.0641780303074764\t Accuracy: 0.6266626602564103\n",
      "Epoch [414/500]\t Loss: 1.064064464202294\t Accuracy: 0.6267027243589743\n",
      "Epoch [415/500]\t Loss: 1.063951325416565\t Accuracy: 0.6267227564102564\n",
      "Epoch [416/500]\t Loss: 1.0638386414601253\t Accuracy: 0.6268028846153846\n",
      "Epoch [417/500]\t Loss: 1.0637264315898602\t Accuracy: 0.6268830128205128\n",
      "Epoch [418/500]\t Loss: 1.0636146630996313\t Accuracy: 0.6269831730769231\n",
      "Epoch [419/500]\t Loss: 1.0635033237628448\t Accuracy: 0.6271434294871795\n",
      "Epoch [420/500]\t Loss: 1.0633924438403204\t Accuracy: 0.6271634615384616\n",
      "Epoch [421/500]\t Loss: 1.0632819900145898\t Accuracy: 0.6271634615384616\n",
      "Epoch [422/500]\t Loss: 1.0631719949917915\t Accuracy: 0.6271834935897436\n",
      "Epoch [423/500]\t Loss: 1.0630624178128365\t Accuracy: 0.6271634615384616\n",
      "Epoch [424/500]\t Loss: 1.0629533006594731\t Accuracy: 0.6272235576923076\n",
      "Epoch [425/500]\t Loss: 1.0628445967649802\t Accuracy: 0.6272035256410257\n",
      "Epoch [426/500]\t Loss: 1.0627363269145673\t Accuracy: 0.6272235576923076\n",
      "Epoch [427/500]\t Loss: 1.0626284645153925\t Accuracy: 0.6272836538461538\n",
      "Epoch [428/500]\t Loss: 1.0625210505265457\t Accuracy: 0.6273637820512821\n",
      "Epoch [429/500]\t Loss: 1.062414055909866\t Accuracy: 0.6274639423076923\n",
      "Epoch [430/500]\t Loss: 1.06230746843876\t Accuracy: 0.6274238782051282\n",
      "Epoch [431/500]\t Loss: 1.0622013049247938\t Accuracy: 0.6274439102564102\n",
      "Epoch [432/500]\t Loss: 1.062095562922649\t Accuracy: 0.6274439102564102\n",
      "Epoch [433/500]\t Loss: 1.061990221341451\t Accuracy: 0.6274639423076923\n",
      "Epoch [434/500]\t Loss: 1.0618852820151892\t Accuracy: 0.6274238782051282\n",
      "Epoch [435/500]\t Loss: 1.0617807605327705\t Accuracy: 0.6274639423076923\n",
      "Epoch [436/500]\t Loss: 1.0616766498639034\t Accuracy: 0.6274839743589744\n",
      "Epoch [437/500]\t Loss: 1.0615729487859287\t Accuracy: 0.6275440705128205\n",
      "Epoch [438/500]\t Loss: 1.061469622147389\t Accuracy: 0.6276041666666666\n",
      "Epoch [439/500]\t Loss: 1.0613667115187033\t Accuracy: 0.6276241987179487\n",
      "Epoch [440/500]\t Loss: 1.0612641777747716\t Accuracy: 0.6276041666666666\n",
      "Epoch [441/500]\t Loss: 1.061162061874683\t Accuracy: 0.6276442307692308\n",
      "Epoch [442/500]\t Loss: 1.0610603408935741\t Accuracy: 0.627764423076923\n",
      "Epoch [443/500]\t Loss: 1.0609589821253067\t Accuracy: 0.6278245192307692\n",
      "Epoch [444/500]\t Loss: 1.0608580329479316\t Accuracy: 0.6278044871794872\n",
      "Epoch [445/500]\t Loss: 1.0607574594326508\t Accuracy: 0.6278645833333333\n",
      "Epoch [446/500]\t Loss: 1.0606572735003936\t Accuracy: 0.6278645833333333\n",
      "Epoch [447/500]\t Loss: 1.0605574812644567\t Accuracy: 0.6279246794871794\n",
      "Epoch [448/500]\t Loss: 1.0604580708039113\t Accuracy: 0.6280048076923077\n",
      "Epoch [449/500]\t Loss: 1.0603589981030195\t Accuracy: 0.628104967948718\n",
      "Epoch [450/500]\t Loss: 1.06026032551741\t Accuracy: 0.628104967948718\n",
      "Epoch [451/500]\t Loss: 1.0601620506017635\t Accuracy: 0.6281850961538461\n",
      "Epoch [452/500]\t Loss: 1.0600640990795234\t Accuracy: 0.6282451923076923\n",
      "Epoch [453/500]\t Loss: 1.0599665470612354\t Accuracy: 0.6282051282051282\n",
      "Epoch [454/500]\t Loss: 1.0598693597011077\t Accuracy: 0.6283253205128205\n",
      "Epoch [455/500]\t Loss: 1.059772525383876\t Accuracy: 0.6284054487179487\n",
      "Epoch [456/500]\t Loss: 1.0596760609211067\t Accuracy: 0.6283854166666667\n",
      "Epoch [457/500]\t Loss: 1.0595799473615792\t Accuracy: 0.6284455128205129\n",
      "Epoch [458/500]\t Loss: 1.0594842100754762\t Accuracy: 0.6284455128205129\n",
      "Epoch [459/500]\t Loss: 1.0593888291945823\t Accuracy: 0.6285056089743589\n",
      "Epoch [460/500]\t Loss: 1.0592937982999362\t Accuracy: 0.628525641025641\n",
      "Epoch [461/500]\t Loss: 1.059199138176747\t Accuracy: 0.6286057692307693\n",
      "Epoch [462/500]\t Loss: 1.059104816118876\t Accuracy: 0.6285857371794872\n",
      "Epoch [463/500]\t Loss: 1.0590108290696756\t Accuracy: 0.6286858974358974\n",
      "Epoch [464/500]\t Loss: 1.058917197203025\t Accuracy: 0.6286658653846153\n",
      "Epoch [465/500]\t Loss: 1.0588239293832045\t Accuracy: 0.6287459935897436\n",
      "Epoch [466/500]\t Loss: 1.058730981594477\t Accuracy: 0.6287860576923077\n",
      "Epoch [467/500]\t Loss: 1.0586383813466782\t Accuracy: 0.6288461538461538\n",
      "Epoch [468/500]\t Loss: 1.0585461454513745\t Accuracy: 0.6288461538461538\n",
      "Epoch [469/500]\t Loss: 1.058454230809823\t Accuracy: 0.6288862179487179\n",
      "Epoch [470/500]\t Loss: 1.0583626542335902\t Accuracy: 0.6289463141025641\n",
      "Epoch [471/500]\t Loss: 1.0582714141943517\t Accuracy: 0.6289863782051283\n",
      "Epoch [472/500]\t Loss: 1.0581805103864426\t Accuracy: 0.6290665064102564\n",
      "Epoch [473/500]\t Loss: 1.0580899278322855\t Accuracy: 0.6291065705128205\n",
      "Epoch [474/500]\t Loss: 1.0579996906794034\t Accuracy: 0.6291065705128205\n",
      "Epoch [475/500]\t Loss: 1.057909759802696\t Accuracy: 0.6290464743589743\n",
      "Epoch [476/500]\t Loss: 1.0578201856368628\t Accuracy: 0.6290464743589743\n",
      "Epoch [477/500]\t Loss: 1.0577309229435066\t Accuracy: 0.6291065705128205\n",
      "Epoch [478/500]\t Loss: 1.057641980281243\t Accuracy: 0.6291466346153847\n",
      "Epoch [479/500]\t Loss: 1.0575533655973581\t Accuracy: 0.6291266025641026\n",
      "Epoch [480/500]\t Loss: 1.0574650700275714\t Accuracy: 0.6290665064102564\n",
      "Epoch [481/500]\t Loss: 1.057377074009333\t Accuracy: 0.6290464743589743\n",
      "Epoch [482/500]\t Loss: 1.057289424003699\t Accuracy: 0.6291065705128205\n",
      "Epoch [483/500]\t Loss: 1.0572020759949317\t Accuracy: 0.6291666666666667\n",
      "Epoch [484/500]\t Loss: 1.057115028760372\t Accuracy: 0.629286858974359\n",
      "Epoch [485/500]\t Loss: 1.0570283058362129\t Accuracy: 0.6292467948717949\n",
      "Epoch [486/500]\t Loss: 1.05694190630546\t Accuracy: 0.6292467948717949\n",
      "Epoch [487/500]\t Loss: 1.0568558038809361\t Accuracy: 0.6292668269230769\n",
      "Epoch [488/500]\t Loss: 1.0567700052872682\t Accuracy: 0.6292467948717949\n",
      "Epoch [489/500]\t Loss: 1.0566845148037642\t Accuracy: 0.6293068910256411\n",
      "Epoch [490/500]\t Loss: 1.056599336404067\t Accuracy: 0.6294270833333333\n",
      "Epoch [491/500]\t Loss: 1.056514454499269\t Accuracy: 0.6294871794871795\n",
      "Epoch [492/500]\t Loss: 1.0564298681723765\t Accuracy: 0.6294871794871795\n",
      "Epoch [493/500]\t Loss: 1.056345593317961\t Accuracy: 0.6295272435897435\n",
      "Epoch [494/500]\t Loss: 1.0562616183207585\t Accuracy: 0.6294871794871795\n",
      "Epoch [495/500]\t Loss: 1.0561779208672353\t Accuracy: 0.6295673076923077\n",
      "Epoch [496/500]\t Loss: 1.0560945306068812\t Accuracy: 0.6296474358974359\n",
      "Epoch [497/500]\t Loss: 1.056011442343394\t Accuracy: 0.6297676282051282\n",
      "Epoch [498/500]\t Loss: 1.0559286337632399\t Accuracy: 0.6298277243589744\n",
      "Epoch [499/500]\t Loss: 1.0558461177043426\t Accuracy: 0.6298076923076923\n",
      "[FINAL]\t Loss: 1.1079922501857464\t Accuracy: 0.608573717948718\n",
      "Step [0/15]\t Computing features...\n",
      "Features shape (3840, 512)\n",
      "Step [0/15]\t Computing features...\n",
      "Features shape (3840, 512)\n",
      "[Single DG]\t Loss: 4.97141030728817\t Accuracy: 0.22864583333333333\n"
     ]
    }
   ],
   "source": [
    "main(0,args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4372f5c-0d93-4522-b893-40c22087f133",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd2b194-cc89-4895-a57e-89695e80f51b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9107f9ca-ab39-45f0-b25b-77c9d7c822b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#epoch 100\n",
    "#photo ->art 0.23828125\n",
    "#photo ->cartoon 0.11848958333333333\n",
    "#photo ->sketch 0.16354166666666667"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a584932b-73fb-417c-b70a-b849cb5371a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1734375"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.23828125 + 0.11848958333333333 + 0.16354166666666667) /3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cec801-15fb-445a-9fa3-4f3338280898",
   "metadata": {},
   "outputs": [],
   "source": [
    "#epoch 10\n",
    "#photo ->art 0.2158203125\n",
    "#photo ->cartoon 0.1228298611111111\n",
    "#photo ->sketch 0.16302083333333334"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
