{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28bf9e86-0994-4379-aa8e-0a1c25c89ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "#SimCLR\n",
    "from simclr import SimCLR\n",
    "from simclr.modules import LogisticRegression, get_resnet\n",
    "from simclr.modules.transformations import TransformsSimCLR\n",
    "\n",
    "#ReLIC\n",
    "#[TODO]\n",
    "from relic import ReLIC\n",
    "#from relic.modules import ReLIC_Loss, get_resnet\n",
    "from relic.modules.transformations import TransformsRelic\n",
    "\n",
    "# TensorBoard\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "from utils import yaml_config_hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7c787ab-8e34-45de-907e-9dc70c352898",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"SimCLR/ReLIC\")\n",
    "config = yaml_config_hook(\"./config/config.yaml\")\n",
    "for k, v in config.items():\n",
    "    parser.add_argument(f\"--{k}\", default=v, type=type(v))\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "\n",
    "# Master address for distributed data parallel\n",
    "os.environ[\"MASTER_ADDR\"] = \"127.0.0.1\"\n",
    "os.environ[\"MASTER_PORT\"] = \"8000\"\n",
    "\n",
    "if not os.path.exists(args.model_path):\n",
    "    os.makedirs(args.model_path)\n",
    "\n",
    "args.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "args.num_gpus = torch.cuda.device_count()\n",
    "args.world_size = args.gpus * args.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e883616-3055-4582-814a-9738207d446d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(loader, ssl_model, device ,relic):\n",
    "    feature_vector = []\n",
    "    labels_vector = []\n",
    "    #SIMCLR\n",
    "    if relic == False:\n",
    "        for step, (x, y) in enumerate(loader):\n",
    "            x = x.to(device)\n",
    "\n",
    "            # get encoding\n",
    "            with torch.no_grad():\n",
    "                h, _, z, _ = ssl_model(x, x)\n",
    "\n",
    "            h = h.detach()\n",
    "\n",
    "            feature_vector.extend(h.cpu().detach().numpy())\n",
    "            labels_vector.extend(y.numpy())\n",
    "\n",
    "            if step % 20 == 0:\n",
    "                print(f\"Step [{step}/{len(loader)}]\\t Computing features...\")\n",
    "\n",
    "        feature_vector = np.array(feature_vector)\n",
    "        labels_vector = np.array(labels_vector)\n",
    "        print(\"Features shape {}\".format(feature_vector.shape))\n",
    "        return feature_vector, labels_vector\n",
    "    #ReLIC\n",
    "    elif relic == True:\n",
    "        for step, (x, y) in enumerate(loader):\n",
    "            x = x.to(device)\n",
    "\n",
    "            # get encoding\n",
    "            with torch.no_grad():\n",
    "                #[TODO] inference\n",
    "                \n",
    "                #dkcho\n",
    "                #h,_,_, _, _, _, _ = ssl_model(x, x, x)\n",
    "                \n",
    "                #new\n",
    "                h= ssl_model(x,x,x, test= True)\n",
    "                \n",
    "\n",
    "\n",
    "            \n",
    "            h = h.detach() #(256,512)\n",
    "\n",
    "            feature_vector.extend(h.cpu().detach().numpy())\n",
    "            labels_vector.extend(y.numpy())\n",
    "\n",
    "            \n",
    "\n",
    "            if step % 20 == 0:\n",
    "                print(f\"Step [{step}/{len(loader)}]\\t Computing features...\")\n",
    "\n",
    "        feature_vector = np.array(feature_vector)\n",
    "        labels_vector = np.array(labels_vector)\n",
    "        print(\"Features shape {}\".format(feature_vector.shape))\n",
    "        return feature_vector, labels_vector        \n",
    "\n",
    "def get_features(ssl_model, train_loader, test_loader, device, relic):\n",
    "    train_X, train_y = inference(train_loader, ssl_model, device, relic) #relic\n",
    "    test_X, test_y = inference(test_loader, ssl_model, device, relic) #relic\n",
    "    return train_X, train_y, test_X, test_y\n",
    "\n",
    "\n",
    "def create_data_loaders_from_arrays(X_train, y_train, X_test, y_test, batch_size):\n",
    "    train = torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(X_train), torch.from_numpy(y_train)\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "\n",
    "    test = torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(X_test), torch.from_numpy(y_test)\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "def train(args, loader, ssl_model, model, criterion, optimizer):\n",
    "    loss_epoch = 0\n",
    "    accuracy_epoch = 0\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x = x.to(args.device)\n",
    "        y = y.to(args.device)\n",
    "        \n",
    "\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        predicted = output.argmax(1)\n",
    "        acc = (predicted == y).sum().item() / y.size(0)\n",
    "        accuracy_epoch += acc\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_epoch += loss.item()\n",
    "        # if step % 100 == 0:\n",
    "        #     print(\n",
    "        #         f\"Step [{step}/{len(loader)}]\\t Loss: {loss.item()}\\t Accuracy: {acc}\"\n",
    "        #     )\n",
    "\n",
    "    return loss_epoch, accuracy_epoch\n",
    "\n",
    "\n",
    "def test(args, loader, ssl_model, model, criterion, optimizer):\n",
    "    loss_epoch = 0\n",
    "    accuracy_epoch = 0\n",
    "    model.eval()\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        model.zero_grad()\n",
    "\n",
    "        x = x.to(args.device)\n",
    "        y = y.to(args.device)\n",
    "\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        predicted = output.argmax(1)\n",
    "        acc = (predicted == y).sum().item() / y.size(0)\n",
    "        accuracy_epoch += acc\n",
    "\n",
    "        loss_epoch += loss.item()\n",
    "\n",
    "    return loss_epoch, accuracy_epoch\n",
    "\n",
    "def main(gpu,args):\n",
    "\n",
    "    print(\"ReLIC -- {c}\".format(c= args.relic))\n",
    "    print(\"Model From -- {m}, Epoch: {e}\".format(m= args.model_path, e= args.epoch_num))\n",
    "    print(\"All Evaluation args -- \", args)\n",
    "\n",
    "    \n",
    "    if args.relic == False:\n",
    "        if args.test_dataset == \"STL10\":\n",
    "            train_dataset = torchvision.datasets.STL10(\n",
    "                args.dataset_dir,\n",
    "                split=\"train\",\n",
    "                download=True,\n",
    "                transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "            )\n",
    "            test_dataset = torchvision.datasets.STL10(\n",
    "                args.dataset_dir,\n",
    "                split=\"test\",\n",
    "                download=True,\n",
    "                transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "            )\n",
    "        elif args.test_dataset == \"CIFAR10\":\n",
    "            train_dataset = torchvision.datasets.CIFAR10(\n",
    "                args.dataset_dir,\n",
    "                train=True,\n",
    "                download=True,\n",
    "                transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "            )\n",
    "            test_dataset = torchvision.datasets.CIFAR10(\n",
    "                args.dataset_dir,\n",
    "                train=False,\n",
    "                download=True,\n",
    "                transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "            )\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "    \n",
    "    #[TODO - Added] ReLIC\n",
    "    elif args.relic == True:\n",
    "        if args.test_dataset == \"STL10\":\n",
    "            train_dataset = torchvision.datasets.STL10(\n",
    "                args.dataset_dir,\n",
    "                split=\"train\",\n",
    "                download=True,\n",
    "                transform=TransformsRelic(size=args.image_size).test_transform,\n",
    "            )\n",
    "            test_dataset = torchvision.datasets.STL10(\n",
    "                args.dataset_dir,\n",
    "                split=\"test\",\n",
    "                download=True,\n",
    "                transform=TransformsRelic(size=args.image_size).test_transform,\n",
    "            )\n",
    "        elif args.test_dataset == \"CIFAR10\":\n",
    "            train_dataset = torchvision.datasets.CIFAR10(\n",
    "                args.dataset_dir,\n",
    "                train=True,\n",
    "                download=True,\n",
    "                transform=TransformsRelic(size=args.image_size).test_transform,\n",
    "            )\n",
    "            test_dataset = torchvision.datasets.CIFAR10(\n",
    "                args.dataset_dir,\n",
    "                train=False,\n",
    "                download=True,\n",
    "                transform=TransformsRelic(size=args.image_size).test_transform,\n",
    "            )\n",
    "        else:\n",
    "            raise NotImplementedError       \n",
    "\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=args.logistic_batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        num_workers=args.workers,\n",
    "    )\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=args.logistic_batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=True,\n",
    "        num_workers=args.workers,\n",
    "    )\n",
    "\n",
    "    encoder = get_resnet(args.resnet, pretrained=False)\n",
    "    n_features = encoder.fc.in_features  # get dimensions of fc layer\n",
    "\n",
    "    # load pre-trained model from checkpoint\n",
    "    if args.relic ==  False:\n",
    "        simclr_model = SimCLR(encoder, args.projection_dim, n_features)\n",
    "        model_fp = os.path.join(args.model_path, \"checkpoint_{}.tar\".format(args.epoch_num))\n",
    "        simclr_model.load_state_dict(torch.load(model_fp, map_location=args.device.type))\n",
    "        simclr_model = simclr_model.to(args.device)\n",
    "        simclr_model.eval()\n",
    "\n",
    "        ## Logistic Regression\n",
    "        n_classes = 10  # CIFAR-10 / STL-10\n",
    "        model = LogisticRegression(simclr_model.n_features, n_classes)\n",
    "        model = model.to(args.device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        print(\"### Creating features from pre-trained context model ###\")\n",
    "        (train_X, train_y, test_X, test_y) = get_features(\n",
    "            simclr_model, train_loader, test_loader, args.device, args.relic\n",
    "        )\n",
    "\n",
    "        arr_train_loader, arr_test_loader = create_data_loaders_from_arrays(\n",
    "            train_X, train_y, test_X, test_y, args.logistic_batch_size\n",
    "        )\n",
    "\n",
    "        for epoch in range(args.logistic_epochs):\n",
    "            loss_epoch, accuracy_epoch = train(\n",
    "                args, arr_train_loader, simclr_model, model, criterion, optimizer\n",
    "            )\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{args.logistic_epochs}]\\t Loss: {loss_epoch / len(arr_train_loader)}\\t Accuracy: {accuracy_epoch / len(arr_train_loader)}\"\n",
    "            )\n",
    "\n",
    "        # final testing\n",
    "        loss_epoch, accuracy_epoch = test(\n",
    "            args, arr_test_loader, simclr_model, model, criterion, optimizer\n",
    "        )\n",
    "        print(\n",
    "            f\"[FINAL]\\t Loss: {loss_epoch / len(arr_test_loader)}\\t Accuracy: {accuracy_epoch / len(arr_test_loader)}\"\n",
    "        )\n",
    "\n",
    "    #[TODO - ADDED] ReLIC\n",
    "    if args.relic == True:\n",
    "        relic_model = ReLIC(encoder, args.projection_dim, n_features)\n",
    "        model_fp = os.path.join(args.model_path, \"checkpoint_{}.tar\".format(args.epoch_num))\n",
    "        relic_model.load_state_dict(torch.load(model_fp, map_location=args.device.type))\n",
    "\n",
    "        #[TODO] JUST USE ENCODER PART ###CAUTION\n",
    "        #saved_n_features= relic_model.n_features\n",
    "        #relic_model= relic_model.encoder\n",
    "\n",
    "        relic_model = relic_model.to(args.device)\n",
    "        relic_model.eval()\n",
    "\n",
    "        \n",
    "\n",
    "        ## Logistic Regression\n",
    "        n_classes = 10  # CIFAR-10 / STL-10\n",
    "        #[TODO] JUST USE ENCODER PART ### CAUTION / OR USE Smaller Model (args.projection_dim)\n",
    "        #model = LogisticRegression(args.projection_dim, n_classes)\n",
    "        \n",
    "        model = LogisticRegression(relic_model.n_features, n_classes) #(relic_model.n_features, n_classes)= (512,10)\n",
    "        model = model.to(args.device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        print(\"### Creating features from pre-trained context model ###\")\n",
    "        (train_X, train_y, test_X, test_y) = get_features(\n",
    "            relic_model, train_loader, test_loader, args.device, args.relic\n",
    "        )\n",
    "\n",
    "        arr_train_loader, arr_test_loader = create_data_loaders_from_arrays(\n",
    "            train_X, train_y, test_X, test_y, args.logistic_batch_size\n",
    "        )\n",
    "\n",
    "        for epoch in range(args.logistic_epochs):\n",
    "            loss_epoch, accuracy_epoch = train(\n",
    "                args, arr_train_loader, relic_model, model, criterion, optimizer\n",
    "            )\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{args.logistic_epochs}]\\t Loss: {loss_epoch / len(arr_train_loader)}\\t Accuracy: {accuracy_epoch / len(arr_train_loader)}\"\n",
    "            )\n",
    "\n",
    "        # final testing\n",
    "        loss_epoch, accuracy_epoch = test(\n",
    "            args, arr_test_loader, relic_model, model, criterion, optimizer\n",
    "        )\n",
    "        print(\n",
    "            f\"[FINAL]\\t Loss: {loss_epoch / len(arr_test_loader)}\\t Accuracy: {accuracy_epoch / len(arr_test_loader)}\"\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e11a4c3-da63-4d87-9aab-f087fde518ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.model_path= 'save/relic/100'\n",
    "args.epoch_num= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0126e51c-b3f7-47d2-becd-8ee0068570fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLIC -- True\n",
      "Model From -- save/relic/100, Epoch: 10\n",
      "All Evaluation args --  Namespace(nodes=1, gpus=1, nr=0, dataparallel=0, workers=8, dataset_dir='./datasets', seed=42, batch_size=128, image_size=224, start_epoch=0, epochs=100, dataset='CIFAR10', test_dataset='STL10', pacs_style='default', pretrain=False, relic=True, relic_normalize=True, relic_temp=1.0, relic_alpha=0.5, resnet='resnet18', projection_dim=64, optimizer='LARS', weight_decay=1e-06, temperature=0.5, model_path='save/relic/100', epoch_num=10, reload=False, logistic_batch_size=256, logistic_epochs=500, device=device(type='cuda', index=0), num_gpus=4, world_size=1)\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "### Creating features from pre-trained context model ###\n",
      "Step [0/19]\t Computing features...\n",
      "Features shape (4864, 512)\n",
      "Step [0/31]\t Computing features...\n",
      "Step [20/31]\t Computing features...\n",
      "Features shape (7936, 512)\n",
      "Epoch [0/500]\t Loss: 2.2433698051854183\t Accuracy: 0.14370888157894737\n",
      "Epoch [1/500]\t Loss: 1.865556277726826\t Accuracy: 0.29009046052631576\n",
      "Epoch [2/500]\t Loss: 1.7013173981716758\t Accuracy: 0.3626644736842105\n",
      "Epoch [3/500]\t Loss: 1.6163841987911023\t Accuracy: 0.39946546052631576\n",
      "Epoch [4/500]\t Loss: 1.5646884064925344\t Accuracy: 0.41776315789473684\n",
      "Epoch [5/500]\t Loss: 1.5293589516689903\t Accuracy: 0.4315378289473684\n",
      "Epoch [6/500]\t Loss: 1.5032250379261218\t Accuracy: 0.4362664473684211\n",
      "Epoch [7/500]\t Loss: 1.4827124633287128\t Accuracy: 0.4409950657894737\n",
      "Epoch [8/500]\t Loss: 1.465997394762541\t Accuracy: 0.44695723684210525\n",
      "Epoch [9/500]\t Loss: 1.4519631674415188\t Accuracy: 0.4504523026315789\n",
      "Epoch [10/500]\t Loss: 1.4398723903455233\t Accuracy: 0.4551809210526316\n",
      "Epoch [11/500]\t Loss: 1.42924638170945\t Accuracy: 0.4603207236842105\n",
      "Epoch [12/500]\t Loss: 1.4197553772675364\t Accuracy: 0.46196546052631576\n",
      "Epoch [13/500]\t Loss: 1.4111641519948055\t Accuracy: 0.46504934210526316\n",
      "Epoch [14/500]\t Loss: 1.4033021111237376\t Accuracy: 0.46566611842105265\n",
      "Epoch [15/500]\t Loss: 1.3960420897132473\t Accuracy: 0.4683388157894737\n",
      "Epoch [16/500]\t Loss: 1.3892874466745477\t Accuracy: 0.4712171052631579\n",
      "Epoch [17/500]\t Loss: 1.382963644830804\t Accuracy: 0.4745065789473684\n",
      "Epoch [18/500]\t Loss: 1.377012052034077\t Accuracy: 0.47635690789473684\n",
      "Epoch [19/500]\t Loss: 1.3713859256945158\t Accuracy: 0.4798519736842105\n",
      "Epoch [20/500]\t Loss: 1.3660474513706409\t Accuracy: 0.48149671052631576\n",
      "Epoch [21/500]\t Loss: 1.3609654526961477\t Accuracy: 0.48458059210526316\n",
      "Epoch [22/500]\t Loss: 1.356114243206225\t Accuracy: 0.4876644736842105\n",
      "Epoch [23/500]\t Loss: 1.3514720326975773\t Accuracy: 0.48930921052631576\n",
      "Epoch [24/500]\t Loss: 1.3470204503912675\t Accuracy: 0.49239309210526316\n",
      "Epoch [25/500]\t Loss: 1.3427435159683228\t Accuracy: 0.4934210526315789\n",
      "Epoch [26/500]\t Loss: 1.3386274513445402\t Accuracy: 0.49609375\n",
      "Epoch [27/500]\t Loss: 1.334660291671753\t Accuracy: 0.49773848684210525\n",
      "Epoch [28/500]\t Loss: 1.3308313332105939\t Accuracy: 0.5002055921052632\n",
      "Epoch [29/500]\t Loss: 1.3271312650881315\t Accuracy: 0.5014391447368421\n",
      "Epoch [30/500]\t Loss: 1.3235514477679604\t Accuracy: 0.5028782894736842\n",
      "Epoch [31/500]\t Loss: 1.3200843145972805\t Accuracy: 0.5047286184210527\n",
      "Epoch [32/500]\t Loss: 1.3167230831949335\t Accuracy: 0.5061677631578947\n",
      "Epoch [33/500]\t Loss: 1.3134615295811702\t Accuracy: 0.5074013157894737\n",
      "Epoch [34/500]\t Loss: 1.3102937434848987\t Accuracy: 0.5100740131578947\n",
      "Epoch [35/500]\t Loss: 1.3072146804709184\t Accuracy: 0.510485197368421\n",
      "Epoch [36/500]\t Loss: 1.3042195533451282\t Accuracy: 0.5119243421052632\n",
      "Epoch [37/500]\t Loss: 1.3013038447028713\t Accuracy: 0.512952302631579\n",
      "Epoch [38/500]\t Loss: 1.298463589266727\t Accuracy: 0.5141858552631579\n",
      "Epoch [39/500]\t Loss: 1.2956949472427368\t Accuracy: 0.514391447368421\n",
      "Epoch [40/500]\t Loss: 1.292994367448907\t Accuracy: 0.515625\n",
      "Epoch [41/500]\t Loss: 1.2903587880887484\t Accuracy: 0.5170641447368421\n",
      "Epoch [42/500]\t Loss: 1.2877849716889231\t Accuracy: 0.5180921052631579\n",
      "Epoch [43/500]\t Loss: 1.2852701827099449\t Accuracy: 0.5193256578947368\n",
      "Epoch [44/500]\t Loss: 1.2828118048216168\t Accuracy: 0.5209703947368421\n",
      "Epoch [45/500]\t Loss: 1.2804072216937417\t Accuracy: 0.5219983552631579\n",
      "Epoch [46/500]\t Loss: 1.2780541997206838\t Accuracy: 0.5232319078947368\n",
      "Epoch [47/500]\t Loss: 1.2757506496027897\t Accuracy: 0.5244654605263158\n",
      "Epoch [48/500]\t Loss: 1.2734943628311157\t Accuracy: 0.5254934210526315\n",
      "Epoch [49/500]\t Loss: 1.271283557540492\t Accuracy: 0.5265213815789473\n",
      "Epoch [50/500]\t Loss: 1.2691163703014976\t Accuracy: 0.5275493421052632\n",
      "Epoch [51/500]\t Loss: 1.266991138458252\t Accuracy: 0.5287828947368421\n",
      "Epoch [52/500]\t Loss: 1.2649060675972386\t Accuracy: 0.5291940789473685\n",
      "Epoch [53/500]\t Loss: 1.2628598903354846\t Accuracy: 0.5287828947368421\n",
      "Epoch [54/500]\t Loss: 1.2608509942104942\t Accuracy: 0.530016447368421\n",
      "Epoch [55/500]\t Loss: 1.2588780428233899\t Accuracy: 0.5310444078947368\n",
      "Epoch [56/500]\t Loss: 1.2569398629037958\t Accuracy: 0.5320723684210527\n",
      "Epoch [57/500]\t Loss: 1.2550350553111027\t Accuracy: 0.5341282894736842\n",
      "Epoch [58/500]\t Loss: 1.2531626224517822\t Accuracy: 0.53515625\n",
      "Epoch [59/500]\t Loss: 1.2513213094912077\t Accuracy: 0.5359786184210527\n",
      "Epoch [60/500]\t Loss: 1.2495101690292358\t Accuracy: 0.5376233552631579\n",
      "Epoch [61/500]\t Loss: 1.2477282222948576\t Accuracy: 0.5384457236842105\n",
      "Epoch [62/500]\t Loss: 1.2459744654203717\t Accuracy: 0.5382401315789473\n",
      "Epoch [63/500]\t Loss: 1.2442479886506732\t Accuracy: 0.5380345394736842\n",
      "Epoch [64/500]\t Loss: 1.2425479951657747\t Accuracy: 0.5390625\n",
      "Epoch [65/500]\t Loss: 1.2408735940330906\t Accuracy: 0.5400904605263158\n",
      "Epoch [66/500]\t Loss: 1.2392240762710571\t Accuracy: 0.540296052631579\n",
      "Epoch [67/500]\t Loss: 1.237598550947089\t Accuracy: 0.5415296052631579\n",
      "Epoch [68/500]\t Loss: 1.235996491030643\t Accuracy: 0.541735197368421\n",
      "Epoch [69/500]\t Loss: 1.2344170808792114\t Accuracy: 0.5421463815789473\n",
      "Epoch [70/500]\t Loss: 1.2328597118980007\t Accuracy: 0.54296875\n",
      "Epoch [71/500]\t Loss: 1.2313237441213507\t Accuracy: 0.5435855263157895\n",
      "Epoch [72/500]\t Loss: 1.2298086316961991\t Accuracy: 0.5450246710526315\n",
      "Epoch [73/500]\t Loss: 1.2283136468184621\t Accuracy: 0.5454358552631579\n",
      "Epoch [74/500]\t Loss: 1.2268384130377519\t Accuracy: 0.5462582236842105\n",
      "Epoch [75/500]\t Loss: 1.225382271565889\t Accuracy: 0.5464638157894737\n",
      "Epoch [76/500]\t Loss: 1.2239448208557933\t Accuracy: 0.5472861842105263\n",
      "Epoch [77/500]\t Loss: 1.2225255276027478\t Accuracy: 0.5479029605263158\n",
      "Epoch [78/500]\t Loss: 1.2211238208569979\t Accuracy: 0.5483141447368421\n",
      "Epoch [79/500]\t Loss: 1.2197394308290983\t Accuracy: 0.549547697368421\n",
      "Epoch [80/500]\t Loss: 1.2183717238275629\t Accuracy: 0.5503700657894737\n",
      "Epoch [81/500]\t Loss: 1.217020411240427\t Accuracy: 0.5509868421052632\n",
      "Epoch [82/500]\t Loss: 1.2156851228914762\t Accuracy: 0.552014802631579\n",
      "Epoch [83/500]\t Loss: 1.2143653568468595\t Accuracy: 0.552014802631579\n",
      "Epoch [84/500]\t Loss: 1.213060786849574\t Accuracy: 0.5526315789473685\n",
      "Epoch [85/500]\t Loss: 1.2117709988041927\t Accuracy: 0.5536595394736842\n",
      "Epoch [86/500]\t Loss: 1.2104957354696173\t Accuracy: 0.5555098684210527\n",
      "Epoch [87/500]\t Loss: 1.2092346203954596\t Accuracy: 0.555921052631579\n",
      "Epoch [88/500]\t Loss: 1.207987295953851\t Accuracy: 0.5565378289473685\n",
      "Epoch [89/500]\t Loss: 1.2067534860811735\t Accuracy: 0.5571546052631579\n",
      "Epoch [90/500]\t Loss: 1.2055329272621556\t Accuracy: 0.5581825657894737\n",
      "Epoch [91/500]\t Loss: 1.2043252054013704\t Accuracy: 0.5583881578947368\n",
      "Epoch [92/500]\t Loss: 1.203130094628585\t Accuracy: 0.5583881578947368\n",
      "Epoch [93/500]\t Loss: 1.2019473188801815\t Accuracy: 0.5592105263157895\n",
      "Epoch [94/500]\t Loss: 1.2007767275760048\t Accuracy: 0.559827302631579\n",
      "Epoch [95/500]\t Loss: 1.199617862701416\t Accuracy: 0.5604440789473685\n",
      "Epoch [96/500]\t Loss: 1.1984705674020868\t Accuracy: 0.5606496710526315\n",
      "Epoch [97/500]\t Loss: 1.197334596985265\t Accuracy: 0.5610608552631579\n",
      "Epoch [98/500]\t Loss: 1.196209706758198\t Accuracy: 0.5616776315789473\n",
      "Epoch [99/500]\t Loss: 1.1950956833989996\t Accuracy: 0.5631167763157895\n",
      "Epoch [100/500]\t Loss: 1.1939923575049953\t Accuracy: 0.5631167763157895\n",
      "Epoch [101/500]\t Loss: 1.1928993902708356\t Accuracy: 0.5639391447368421\n",
      "Epoch [102/500]\t Loss: 1.1918166875839233\t Accuracy: 0.5647615131578947\n",
      "Epoch [103/500]\t Loss: 1.190743967106468\t Accuracy: 0.5647615131578947\n",
      "Epoch [104/500]\t Loss: 1.1896811221775256\t Accuracy: 0.5647615131578947\n",
      "Epoch [105/500]\t Loss: 1.18862783908844\t Accuracy: 0.5647615131578947\n",
      "Epoch [106/500]\t Loss: 1.1875839735332288\t Accuracy: 0.5657894736842105\n",
      "Epoch [107/500]\t Loss: 1.1865494313992953\t Accuracy: 0.5662006578947368\n",
      "Epoch [108/500]\t Loss: 1.1855239993647526\t Accuracy: 0.5666118421052632\n",
      "Epoch [109/500]\t Loss: 1.1845074013659829\t Accuracy: 0.5666118421052632\n",
      "Epoch [110/500]\t Loss: 1.1834996060321206\t Accuracy: 0.5670230263157895\n",
      "Epoch [111/500]\t Loss: 1.1825004376863177\t Accuracy: 0.5670230263157895\n",
      "Epoch [112/500]\t Loss: 1.1815096077166105\t Accuracy: 0.567639802631579\n",
      "Epoch [113/500]\t Loss: 1.1805271349455182\t Accuracy: 0.5678453947368421\n",
      "Epoch [114/500]\t Loss: 1.1795527809544613\t Accuracy: 0.5682565789473685\n",
      "Epoch [115/500]\t Loss: 1.1785864641791897\t Accuracy: 0.5682565789473685\n",
      "Epoch [116/500]\t Loss: 1.1776279901203357\t Accuracy: 0.5678453947368421\n",
      "Epoch [117/500]\t Loss: 1.1766771329076666\t Accuracy: 0.5684621710526315\n",
      "Epoch [118/500]\t Loss: 1.1757339239120483\t Accuracy: 0.569078947368421\n",
      "Epoch [119/500]\t Loss: 1.1747982062791522\t Accuracy: 0.5699013157894737\n",
      "Epoch [120/500]\t Loss: 1.173869766687092\t Accuracy: 0.5707236842105263\n",
      "Epoch [121/500]\t Loss: 1.1729485110232705\t Accuracy: 0.5713404605263158\n",
      "Epoch [122/500]\t Loss: 1.1720343075300519\t Accuracy: 0.5717516447368421\n",
      "Epoch [123/500]\t Loss: 1.1711271185623973\t Accuracy: 0.5725740131578947\n",
      "Epoch [124/500]\t Loss: 1.1702267496209395\t Accuracy: 0.572985197368421\n",
      "Epoch [125/500]\t Loss: 1.169333112867255\t Accuracy: 0.5736019736842105\n",
      "Epoch [126/500]\t Loss: 1.1684461392854388\t Accuracy: 0.5748355263157895\n",
      "Epoch [127/500]\t Loss: 1.1675656531986438\t Accuracy: 0.5752467105263158\n",
      "Epoch [128/500]\t Loss: 1.1666916420585232\t Accuracy: 0.575452302631579\n",
      "Epoch [129/500]\t Loss: 1.1658238548981517\t Accuracy: 0.5758634868421053\n",
      "Epoch [130/500]\t Loss: 1.164962279169183\t Accuracy: 0.5770970394736842\n",
      "Epoch [131/500]\t Loss: 1.1641069148716174\t Accuracy: 0.5773026315789473\n",
      "Epoch [132/500]\t Loss: 1.1632575361352218\t Accuracy: 0.5773026315789473\n",
      "Epoch [133/500]\t Loss: 1.162413992379841\t Accuracy: 0.5779194078947368\n",
      "Epoch [134/500]\t Loss: 1.1615764341856305\t Accuracy: 0.5785361842105263\n",
      "Epoch [135/500]\t Loss: 1.1607445227472406\t Accuracy: 0.5791529605263158\n",
      "Epoch [136/500]\t Loss: 1.1599183082580566\t Accuracy: 0.5787417763157895\n",
      "Epoch [137/500]\t Loss: 1.1590976652346159\t Accuracy: 0.5787417763157895\n",
      "Epoch [138/500]\t Loss: 1.1582825497577065\t Accuracy: 0.5787417763157895\n",
      "Epoch [139/500]\t Loss: 1.1574728802630776\t Accuracy: 0.5787417763157895\n",
      "Epoch [140/500]\t Loss: 1.156668455977189\t Accuracy: 0.5789473684210527\n",
      "Epoch [141/500]\t Loss: 1.1558693333675987\t Accuracy: 0.579358552631579\n",
      "Epoch [142/500]\t Loss: 1.1550753681283248\t Accuracy: 0.5797697368421053\n",
      "Epoch [143/500]\t Loss: 1.154286591630233\t Accuracy: 0.5805921052631579\n",
      "Epoch [144/500]\t Loss: 1.1535027529063977\t Accuracy: 0.5810032894736842\n",
      "Epoch [145/500]\t Loss: 1.1527239209727238\t Accuracy: 0.5814144736842105\n",
      "Epoch [146/500]\t Loss: 1.1519499954424406\t Accuracy: 0.5812088815789473\n",
      "Epoch [147/500]\t Loss: 1.1511809198479903\t Accuracy: 0.5814144736842105\n",
      "Epoch [148/500]\t Loss: 1.150416606350949\t Accuracy: 0.58203125\n",
      "Epoch [149/500]\t Loss: 1.1496569733870656\t Accuracy: 0.5818256578947368\n",
      "Epoch [150/500]\t Loss: 1.1489019582146092\t Accuracy: 0.5828536184210527\n",
      "Epoch [151/500]\t Loss: 1.1481515922044452\t Accuracy: 0.5830592105263158\n",
      "Epoch [152/500]\t Loss: 1.1474056055671291\t Accuracy: 0.5838815789473685\n",
      "Epoch [153/500]\t Loss: 1.1466641802536814\t Accuracy: 0.5836759868421053\n",
      "Epoch [154/500]\t Loss: 1.1459270966680426\t Accuracy: 0.5836759868421053\n",
      "Epoch [155/500]\t Loss: 1.1451943422618664\t Accuracy: 0.5836759868421053\n",
      "Epoch [156/500]\t Loss: 1.144465866841768\t Accuracy: 0.5844983552631579\n",
      "Epoch [157/500]\t Loss: 1.1437416641335738\t Accuracy: 0.5849095394736842\n",
      "Epoch [158/500]\t Loss: 1.143021589831302\t Accuracy: 0.5855263157894737\n",
      "Epoch [159/500]\t Loss: 1.14230561883826\t Accuracy: 0.5865542763157895\n",
      "Epoch [160/500]\t Loss: 1.141593713509409\t Accuracy: 0.5867598684210527\n",
      "Epoch [161/500]\t Loss: 1.1408858550222296\t Accuracy: 0.587171052631579\n",
      "Epoch [162/500]\t Loss: 1.140181917893259\t Accuracy: 0.587171052631579\n",
      "Epoch [163/500]\t Loss: 1.139481877025805\t Accuracy: 0.5881990131578947\n",
      "Epoch [164/500]\t Loss: 1.1387857449682135\t Accuracy: 0.5888157894736842\n",
      "Epoch [165/500]\t Loss: 1.1380933585919832\t Accuracy: 0.5894325657894737\n",
      "Epoch [166/500]\t Loss: 1.137404818283884\t Accuracy: 0.58984375\n",
      "Epoch [167/500]\t Loss: 1.1367199295445491\t Accuracy: 0.58984375\n",
      "Epoch [168/500]\t Loss: 1.1360387927607487\t Accuracy: 0.5906661184210527\n",
      "Epoch [169/500]\t Loss: 1.1353612510781539\t Accuracy: 0.5906661184210527\n",
      "Epoch [170/500]\t Loss: 1.1346872856742458\t Accuracy: 0.5908717105263158\n",
      "Epoch [171/500]\t Loss: 1.134016846355639\t Accuracy: 0.5908717105263158\n",
      "Epoch [172/500]\t Loss: 1.1333499644931995\t Accuracy: 0.5912828947368421\n",
      "Epoch [173/500]\t Loss: 1.1326865208776373\t Accuracy: 0.5921052631578947\n",
      "Epoch [174/500]\t Loss: 1.1320265092347797\t Accuracy: 0.5933388157894737\n",
      "Epoch [175/500]\t Loss: 1.1313698856454146\t Accuracy: 0.5935444078947368\n",
      "Epoch [176/500]\t Loss: 1.1307166124645032\t Accuracy: 0.59375\n",
      "Epoch [177/500]\t Loss: 1.1300666520470066\t Accuracy: 0.59375\n",
      "Epoch [178/500]\t Loss: 1.1294199479253668\t Accuracy: 0.5939555921052632\n",
      "Epoch [179/500]\t Loss: 1.1287764499061985\t Accuracy: 0.5945723684210527\n",
      "Epoch [180/500]\t Loss: 1.128136157989502\t Accuracy: 0.594983552631579\n",
      "Epoch [181/500]\t Loss: 1.127499028256065\t Accuracy: 0.5951891447368421\n",
      "Epoch [182/500]\t Loss: 1.1268650230608488\t Accuracy: 0.5956003289473685\n",
      "Epoch [183/500]\t Loss: 1.1262341612263729\t Accuracy: 0.5956003289473685\n",
      "Epoch [184/500]\t Loss: 1.1256063109950016\t Accuracy: 0.5958059210526315\n",
      "Epoch [185/500]\t Loss: 1.1249815225601196\t Accuracy: 0.5960115131578947\n",
      "Epoch [186/500]\t Loss: 1.1243596641640914\t Accuracy: 0.5960115131578947\n",
      "Epoch [187/500]\t Loss: 1.123740786000302\t Accuracy: 0.5958059210526315\n",
      "Epoch [188/500]\t Loss: 1.1231248943429244\t Accuracy: 0.5960115131578947\n",
      "Epoch [189/500]\t Loss: 1.1225117633217259\t Accuracy: 0.5958059210526315\n",
      "Epoch [190/500]\t Loss: 1.1219015937102468\t Accuracy: 0.5958059210526315\n",
      "Epoch [191/500]\t Loss: 1.1212942976700633\t Accuracy: 0.5958059210526315\n",
      "Epoch [192/500]\t Loss: 1.12068972462102\t Accuracy: 0.5958059210526315\n",
      "Epoch [193/500]\t Loss: 1.1200880063207526\t Accuracy: 0.5962171052631579\n",
      "Epoch [194/500]\t Loss: 1.119488941995721\t Accuracy: 0.5960115131578947\n",
      "Epoch [195/500]\t Loss: 1.1188926759519076\t Accuracy: 0.5962171052631579\n",
      "Epoch [196/500]\t Loss: 1.1182990450608103\t Accuracy: 0.5966282894736842\n",
      "Epoch [197/500]\t Loss: 1.1177080932416414\t Accuracy: 0.59765625\n",
      "Epoch [198/500]\t Loss: 1.1171198204944008\t Accuracy: 0.5984786184210527\n",
      "Epoch [199/500]\t Loss: 1.116534107609799\t Accuracy: 0.5984786184210527\n",
      "Epoch [200/500]\t Loss: 1.1159509859587018\t Accuracy: 0.5986842105263158\n",
      "Epoch [201/500]\t Loss: 1.1153704806378013\t Accuracy: 0.5990953947368421\n",
      "Epoch [202/500]\t Loss: 1.1147924410669428\t Accuracy: 0.5990953947368421\n",
      "Epoch [203/500]\t Loss: 1.114216917439511\t Accuracy: 0.5997121710526315\n",
      "Epoch [204/500]\t Loss: 1.1136438783846403\t Accuracy: 0.6001233552631579\n",
      "Epoch [205/500]\t Loss: 1.1130733176281578\t Accuracy: 0.6007401315789473\n",
      "Epoch [206/500]\t Loss: 1.112505184976678\t Accuracy: 0.6009457236842105\n",
      "Epoch [207/500]\t Loss: 1.111939505526894\t Accuracy: 0.6013569078947368\n",
      "Epoch [208/500]\t Loss: 1.1113761036019576\t Accuracy: 0.6013569078947368\n",
      "Epoch [209/500]\t Loss: 1.1108151611528898\t Accuracy: 0.6011513157894737\n",
      "Epoch [210/500]\t Loss: 1.1102565338737087\t Accuracy: 0.6013569078947368\n",
      "Epoch [211/500]\t Loss: 1.1097002405869334\t Accuracy: 0.6015625\n",
      "Epoch [212/500]\t Loss: 1.1091462624700446\t Accuracy: 0.6021792763157895\n",
      "Epoch [213/500]\t Loss: 1.108594486587926\t Accuracy: 0.6019736842105263\n",
      "Epoch [214/500]\t Loss: 1.1080450384240401\t Accuracy: 0.6023848684210527\n",
      "Epoch [215/500]\t Loss: 1.1074977924949245\t Accuracy: 0.6025904605263158\n",
      "Epoch [216/500]\t Loss: 1.1069527738972713\t Accuracy: 0.6030016447368421\n",
      "Epoch [217/500]\t Loss: 1.1064099575343884\t Accuracy: 0.6034128289473685\n",
      "Epoch [218/500]\t Loss: 1.1058692869387174\t Accuracy: 0.6034128289473685\n",
      "Epoch [219/500]\t Loss: 1.1053308248519897\t Accuracy: 0.6034128289473685\n",
      "Epoch [220/500]\t Loss: 1.1047944834357815\t Accuracy: 0.6038240131578947\n",
      "Epoch [221/500]\t Loss: 1.1042601811258417\t Accuracy: 0.6044407894736842\n",
      "Epoch [222/500]\t Loss: 1.1037280622281527\t Accuracy: 0.6044407894736842\n",
      "Epoch [223/500]\t Loss: 1.103198064000983\t Accuracy: 0.6050575657894737\n",
      "Epoch [224/500]\t Loss: 1.1026700421383506\t Accuracy: 0.6052631578947368\n",
      "Epoch [225/500]\t Loss: 1.10214406565616\t Accuracy: 0.6050575657894737\n",
      "Epoch [226/500]\t Loss: 1.101620078086853\t Accuracy: 0.6048519736842105\n",
      "Epoch [227/500]\t Loss: 1.1010981735430265\t Accuracy: 0.6050575657894737\n",
      "Epoch [228/500]\t Loss: 1.1005782453637374\t Accuracy: 0.60546875\n",
      "Epoch [229/500]\t Loss: 1.1000602182589079\t Accuracy: 0.60546875\n",
      "Epoch [230/500]\t Loss: 1.0995442553570396\t Accuracy: 0.6060855263157895\n",
      "Epoch [231/500]\t Loss: 1.0990301684329384\t Accuracy: 0.6060855263157895\n",
      "Epoch [232/500]\t Loss: 1.098518039050855\t Accuracy: 0.6062911184210527\n",
      "Epoch [233/500]\t Loss: 1.0980077542756732\t Accuracy: 0.606702302631579\n",
      "Epoch [234/500]\t Loss: 1.09749940821999\t Accuracy: 0.606702302631579\n",
      "Epoch [235/500]\t Loss: 1.096992906771208\t Accuracy: 0.6071134868421053\n",
      "Epoch [236/500]\t Loss: 1.0964882687518471\t Accuracy: 0.6073190789473685\n",
      "Epoch [237/500]\t Loss: 1.0959854816135608\t Accuracy: 0.6075246710526315\n",
      "Epoch [238/500]\t Loss: 1.0954845767272146\t Accuracy: 0.6079358552631579\n",
      "Epoch [239/500]\t Loss: 1.0949854035126536\t Accuracy: 0.608141447368421\n",
      "Epoch [240/500]\t Loss: 1.0944880247116089\t Accuracy: 0.6085526315789473\n",
      "Epoch [241/500]\t Loss: 1.093992452872427\t Accuracy: 0.6087582236842105\n",
      "Epoch [242/500]\t Loss: 1.0934987005434538\t Accuracy: 0.6085526315789473\n",
      "Epoch [243/500]\t Loss: 1.0930066736120927\t Accuracy: 0.6085526315789473\n",
      "Epoch [244/500]\t Loss: 1.0925163595299971\t Accuracy: 0.6087582236842105\n",
      "Epoch [245/500]\t Loss: 1.0920278461355912\t Accuracy: 0.6089638157894737\n",
      "Epoch [246/500]\t Loss: 1.091540920106988\t Accuracy: 0.6089638157894737\n",
      "Epoch [247/500]\t Loss: 1.0910557508468628\t Accuracy: 0.6089638157894737\n",
      "Epoch [248/500]\t Loss: 1.0905722693393105\t Accuracy: 0.6089638157894737\n",
      "Epoch [249/500]\t Loss: 1.0900904755843313\t Accuracy: 0.6091694078947368\n",
      "Epoch [250/500]\t Loss: 1.0896102754693282\t Accuracy: 0.6091694078947368\n",
      "Epoch [251/500]\t Loss: 1.0891318258486296\t Accuracy: 0.6087582236842105\n",
      "Epoch [252/500]\t Loss: 1.0886549322228682\t Accuracy: 0.6087582236842105\n",
      "Epoch [253/500]\t Loss: 1.0881796636079486\t Accuracy: 0.609375\n",
      "Epoch [254/500]\t Loss: 1.087706026278044\t Accuracy: 0.609375\n",
      "Epoch [255/500]\t Loss: 1.0872339543543363\t Accuracy: 0.6095805921052632\n",
      "Epoch [256/500]\t Loss: 1.0867634948931242\t Accuracy: 0.6097861842105263\n",
      "Epoch [257/500]\t Loss: 1.0862946353460614\t Accuracy: 0.6099917763157895\n",
      "Epoch [258/500]\t Loss: 1.0858272910118103\t Accuracy: 0.6101973684210527\n",
      "Epoch [259/500]\t Loss: 1.085361477575804\t Accuracy: 0.6101973684210527\n",
      "Epoch [260/500]\t Loss: 1.0848972609168606\t Accuracy: 0.610608552631579\n",
      "Epoch [261/500]\t Loss: 1.0844344653581317\t Accuracy: 0.6101973684210527\n",
      "Epoch [262/500]\t Loss: 1.0839732634393793\t Accuracy: 0.6108141447368421\n",
      "Epoch [263/500]\t Loss: 1.083513573596352\t Accuracy: 0.6112253289473685\n",
      "Epoch [264/500]\t Loss: 1.0830553550469249\t Accuracy: 0.6114309210526315\n",
      "Epoch [265/500]\t Loss: 1.0825986297507035\t Accuracy: 0.6118421052631579\n",
      "Epoch [266/500]\t Loss: 1.08214334124013\t Accuracy: 0.612047697368421\n",
      "Epoch [267/500]\t Loss: 1.08168952088607\t Accuracy: 0.6116365131578947\n",
      "Epoch [268/500]\t Loss: 1.0812371561401768\t Accuracy: 0.6122532894736842\n",
      "Epoch [269/500]\t Loss: 1.0807861999461525\t Accuracy: 0.6128700657894737\n",
      "Epoch [270/500]\t Loss: 1.0803366679894297\t Accuracy: 0.6128700657894737\n",
      "Epoch [271/500]\t Loss: 1.0798885947779606\t Accuracy: 0.6134868421052632\n",
      "Epoch [272/500]\t Loss: 1.0794419614892257\t Accuracy: 0.6136924342105263\n",
      "Epoch [273/500]\t Loss: 1.0789966583251953\t Accuracy: 0.6136924342105263\n",
      "Epoch [274/500]\t Loss: 1.0785527041083889\t Accuracy: 0.6138980263157895\n",
      "Epoch [275/500]\t Loss: 1.07811018667723\t Accuracy: 0.6141036184210527\n",
      "Epoch [276/500]\t Loss: 1.0776690464270742\t Accuracy: 0.6143092105263158\n",
      "Epoch [277/500]\t Loss: 1.0772292582612288\t Accuracy: 0.614514802631579\n",
      "Epoch [278/500]\t Loss: 1.0767908378651267\t Accuracy: 0.614514802631579\n",
      "Epoch [279/500]\t Loss: 1.0763536911261709\t Accuracy: 0.6141036184210527\n",
      "Epoch [280/500]\t Loss: 1.0759179341165643\t Accuracy: 0.6143092105263158\n",
      "Epoch [281/500]\t Loss: 1.0754834444899308\t Accuracy: 0.6143092105263158\n",
      "Epoch [282/500]\t Loss: 1.075050247342963\t Accuracy: 0.6147203947368421\n",
      "Epoch [283/500]\t Loss: 1.0746184524736906\t Accuracy: 0.6151315789473685\n",
      "Epoch [284/500]\t Loss: 1.0741878810681795\t Accuracy: 0.6151315789473685\n",
      "Epoch [285/500]\t Loss: 1.0737586115535938\t Accuracy: 0.6155427631578947\n",
      "Epoch [286/500]\t Loss: 1.0733305905994617\t Accuracy: 0.615953947368421\n",
      "Epoch [287/500]\t Loss: 1.0729039029071206\t Accuracy: 0.6163651315789473\n",
      "Epoch [288/500]\t Loss: 1.0724784261301945\t Accuracy: 0.6165707236842105\n",
      "Epoch [289/500]\t Loss: 1.0720541728170294\t Accuracy: 0.6165707236842105\n",
      "Epoch [290/500]\t Loss: 1.0716312339431362\t Accuracy: 0.6165707236842105\n",
      "Epoch [291/500]\t Loss: 1.071209468339619\t Accuracy: 0.6165707236842105\n",
      "Epoch [292/500]\t Loss: 1.0707889481594688\t Accuracy: 0.6167763157894737\n",
      "Epoch [293/500]\t Loss: 1.0703696451689069\t Accuracy: 0.6167763157894737\n",
      "Epoch [294/500]\t Loss: 1.0699515311341536\t Accuracy: 0.6165707236842105\n",
      "Epoch [295/500]\t Loss: 1.0695346907565468\t Accuracy: 0.6165707236842105\n",
      "Epoch [296/500]\t Loss: 1.0691189420850653\t Accuracy: 0.6165707236842105\n",
      "Epoch [297/500]\t Loss: 1.0687044545223838\t Accuracy: 0.6163651315789473\n",
      "Epoch [298/500]\t Loss: 1.0682911308188188\t Accuracy: 0.6163651315789473\n",
      "Epoch [299/500]\t Loss: 1.0678789709743701\t Accuracy: 0.6167763157894737\n",
      "Epoch [300/500]\t Loss: 1.0674679404810856\t Accuracy: 0.6169819078947368\n",
      "Epoch [301/500]\t Loss: 1.0670581240403025\t Accuracy: 0.6175986842105263\n",
      "Epoch [302/500]\t Loss: 1.0666494087169045\t Accuracy: 0.6175986842105263\n",
      "Epoch [303/500]\t Loss: 1.0662418509784497\t Accuracy: 0.6178042763157895\n",
      "Epoch [304/500]\t Loss: 1.0658354633732845\t Accuracy: 0.6178042763157895\n",
      "Epoch [305/500]\t Loss: 1.0654301674742448\t Accuracy: 0.6173930921052632\n",
      "Epoch [306/500]\t Loss: 1.065025950732984\t Accuracy: 0.6178042763157895\n",
      "Epoch [307/500]\t Loss: 1.0646229292217053\t Accuracy: 0.6178042763157895\n",
      "Epoch [308/500]\t Loss: 1.0642209335377342\t Accuracy: 0.6180098684210527\n",
      "Epoch [309/500]\t Loss: 1.06382008289036\t Accuracy: 0.6182154605263158\n",
      "Epoch [310/500]\t Loss: 1.063420295715332\t Accuracy: 0.618421052631579\n",
      "Epoch [311/500]\t Loss: 1.063021653576901\t Accuracy: 0.618421052631579\n",
      "Epoch [312/500]\t Loss: 1.0626239902094792\t Accuracy: 0.6186266447368421\n",
      "Epoch [313/500]\t Loss: 1.0622275032495196\t Accuracy: 0.6188322368421053\n",
      "Epoch [314/500]\t Loss: 1.0618320421168679\t Accuracy: 0.6190378289473685\n",
      "Epoch [315/500]\t Loss: 1.0614376413194757\t Accuracy: 0.6188322368421053\n",
      "Epoch [316/500]\t Loss: 1.0610443071315163\t Accuracy: 0.6190378289473685\n",
      "Epoch [317/500]\t Loss: 1.0606519956337779\t Accuracy: 0.6190378289473685\n",
      "Epoch [318/500]\t Loss: 1.0602607570196454\t Accuracy: 0.6192434210526315\n",
      "Epoch [319/500]\t Loss: 1.0598704814910889\t Accuracy: 0.6192434210526315\n",
      "Epoch [320/500]\t Loss: 1.0594812662977922\t Accuracy: 0.6194490131578947\n",
      "Epoch [321/500]\t Loss: 1.0590930863430625\t Accuracy: 0.6196546052631579\n",
      "Epoch [322/500]\t Loss: 1.0587059635865061\t Accuracy: 0.619860197368421\n",
      "Epoch [323/500]\t Loss: 1.0583197568592273\t Accuracy: 0.6200657894736842\n",
      "Epoch [324/500]\t Loss: 1.0579346136042946\t Accuracy: 0.6204769736842105\n",
      "Epoch [325/500]\t Loss: 1.0575504302978516\t Accuracy: 0.62109375\n",
      "Epoch [326/500]\t Loss: 1.0571672979154085\t Accuracy: 0.62109375\n",
      "Epoch [327/500]\t Loss: 1.0567851066589355\t Accuracy: 0.6212993421052632\n",
      "Epoch [328/500]\t Loss: 1.0564038910363849\t Accuracy: 0.6212993421052632\n",
      "Epoch [329/500]\t Loss: 1.0560236886927956\t Accuracy: 0.6215049342105263\n",
      "Epoch [330/500]\t Loss: 1.0556444462976957\t Accuracy: 0.62109375\n",
      "Epoch [331/500]\t Loss: 1.0552661073835272\t Accuracy: 0.6208881578947368\n",
      "Epoch [332/500]\t Loss: 1.0548887691999738\t Accuracy: 0.62109375\n",
      "Epoch [333/500]\t Loss: 1.0545123784165633\t Accuracy: 0.6215049342105263\n",
      "Epoch [334/500]\t Loss: 1.054136944444556\t Accuracy: 0.6215049342105263\n",
      "Epoch [335/500]\t Loss: 1.053762385719701\t Accuracy: 0.6215049342105263\n",
      "Epoch [336/500]\t Loss: 1.053388868507586\t Accuracy: 0.6217105263157895\n",
      "Epoch [337/500]\t Loss: 1.0530162579134892\t Accuracy: 0.6219161184210527\n",
      "Epoch [338/500]\t Loss: 1.0526445413890637\t Accuracy: 0.6219161184210527\n",
      "Epoch [339/500]\t Loss: 1.0522737471680892\t Accuracy: 0.6219161184210527\n",
      "Epoch [340/500]\t Loss: 1.0519038940730847\t Accuracy: 0.6219161184210527\n",
      "Epoch [341/500]\t Loss: 1.051534941321925\t Accuracy: 0.6221217105263158\n",
      "Epoch [342/500]\t Loss: 1.051166876366264\t Accuracy: 0.6221217105263158\n",
      "Epoch [343/500]\t Loss: 1.0507997368511401\t Accuracy: 0.622327302631579\n",
      "Epoch [344/500]\t Loss: 1.0504334882686013\t Accuracy: 0.6221217105263158\n",
      "Epoch [345/500]\t Loss: 1.0500680992477818\t Accuracy: 0.6221217105263158\n",
      "Epoch [346/500]\t Loss: 1.04970362625624\t Accuracy: 0.6221217105263158\n",
      "Epoch [347/500]\t Loss: 1.049340053608543\t Accuracy: 0.6221217105263158\n",
      "Epoch [348/500]\t Loss: 1.0489772903291803\t Accuracy: 0.6221217105263158\n",
      "Epoch [349/500]\t Loss: 1.0486154211194891\t Accuracy: 0.622327302631579\n",
      "Epoch [350/500]\t Loss: 1.0482544397052966\t Accuracy: 0.622327302631579\n",
      "Epoch [351/500]\t Loss: 1.0478943021673905\t Accuracy: 0.622327302631579\n",
      "Epoch [352/500]\t Loss: 1.0475350053686845\t Accuracy: 0.6225328947368421\n",
      "Epoch [353/500]\t Loss: 1.0471766183250828\t Accuracy: 0.6225328947368421\n",
      "Epoch [354/500]\t Loss: 1.0468190782948543\t Accuracy: 0.6225328947368421\n",
      "Epoch [355/500]\t Loss: 1.0464622786170559\t Accuracy: 0.6225328947368421\n",
      "Epoch [356/500]\t Loss: 1.0461064043797945\t Accuracy: 0.6225328947368421\n",
      "Epoch [357/500]\t Loss: 1.0457513300996077\t Accuracy: 0.6225328947368421\n",
      "Epoch [358/500]\t Loss: 1.0453971530261792\t Accuracy: 0.6227384868421053\n",
      "Epoch [359/500]\t Loss: 1.0450437288535268\t Accuracy: 0.6227384868421053\n",
      "Epoch [360/500]\t Loss: 1.0446911767909401\t Accuracy: 0.6227384868421053\n",
      "Epoch [361/500]\t Loss: 1.0443393556695235\t Accuracy: 0.6227384868421053\n",
      "Epoch [362/500]\t Loss: 1.0439884411661249\t Accuracy: 0.6227384868421053\n",
      "Epoch [363/500]\t Loss: 1.0436382827005888\t Accuracy: 0.6227384868421053\n",
      "Epoch [364/500]\t Loss: 1.0432889461517334\t Accuracy: 0.6227384868421053\n",
      "Epoch [365/500]\t Loss: 1.042940406422866\t Accuracy: 0.6227384868421053\n",
      "Epoch [366/500]\t Loss: 1.0425926823365061\t Accuracy: 0.6235608552631579\n",
      "Epoch [367/500]\t Loss: 1.042245742521788\t Accuracy: 0.6235608552631579\n",
      "Epoch [368/500]\t Loss: 1.0418995242369802\t Accuracy: 0.6235608552631579\n",
      "Epoch [369/500]\t Loss: 1.0415541623768054\t Accuracy: 0.6235608552631579\n",
      "Epoch [370/500]\t Loss: 1.0412095659657528\t Accuracy: 0.6235608552631579\n",
      "Epoch [371/500]\t Loss: 1.0408657444150824\t Accuracy: 0.6235608552631579\n",
      "Epoch [372/500]\t Loss: 1.0405226789022748\t Accuracy: 0.6235608552631579\n",
      "Epoch [373/500]\t Loss: 1.0401803788385893\t Accuracy: 0.623766447368421\n",
      "Epoch [374/500]\t Loss: 1.039838903828671\t Accuracy: 0.6239720394736842\n",
      "Epoch [375/500]\t Loss: 1.0394981440744901\t Accuracy: 0.6243832236842105\n",
      "Epoch [376/500]\t Loss: 1.039158112124393\t Accuracy: 0.6243832236842105\n",
      "Epoch [377/500]\t Loss: 1.0388188550346775\t Accuracy: 0.625\n",
      "Epoch [378/500]\t Loss: 1.038480347708652\t Accuracy: 0.6252055921052632\n",
      "Epoch [379/500]\t Loss: 1.0381425932834023\t Accuracy: 0.6254111842105263\n",
      "Epoch [380/500]\t Loss: 1.0378055509768034\t Accuracy: 0.6254111842105263\n",
      "Epoch [381/500]\t Loss: 1.0374692333372015\t Accuracy: 0.6256167763157895\n",
      "Epoch [382/500]\t Loss: 1.0371337156546743\t Accuracy: 0.6256167763157895\n",
      "Epoch [383/500]\t Loss: 1.0367989351874904\t Accuracy: 0.6256167763157895\n",
      "Epoch [384/500]\t Loss: 1.0364648197826587\t Accuracy: 0.6258223684210527\n",
      "Epoch [385/500]\t Loss: 1.03613145100443\t Accuracy: 0.6258223684210527\n",
      "Epoch [386/500]\t Loss: 1.0357987692481594\t Accuracy: 0.6258223684210527\n",
      "Epoch [387/500]\t Loss: 1.035466874900617\t Accuracy: 0.6260279605263158\n",
      "Epoch [388/500]\t Loss: 1.035135639341254\t Accuracy: 0.6260279605263158\n",
      "Epoch [389/500]\t Loss: 1.0348051221747148\t Accuracy: 0.6266447368421053\n",
      "Epoch [390/500]\t Loss: 1.034475326538086\t Accuracy: 0.6264391447368421\n",
      "Epoch [391/500]\t Loss: 1.0341462430201078\t Accuracy: 0.6264391447368421\n",
      "Epoch [392/500]\t Loss: 1.0338178716207806\t Accuracy: 0.6266447368421053\n",
      "Epoch [393/500]\t Loss: 1.0334900931308144\t Accuracy: 0.6268503289473685\n",
      "Epoch [394/500]\t Loss: 1.0331631114608364\t Accuracy: 0.6268503289473685\n",
      "Epoch [395/500]\t Loss: 1.0328367917161239\t Accuracy: 0.6270559210526315\n",
      "Epoch [396/500]\t Loss: 1.0325111746788025\t Accuracy: 0.6270559210526315\n",
      "Epoch [397/500]\t Loss: 1.0321861944700543\t Accuracy: 0.6270559210526315\n",
      "Epoch [398/500]\t Loss: 1.0318619357912164\t Accuracy: 0.6270559210526315\n",
      "Epoch [399/500]\t Loss: 1.0315383578601636\t Accuracy: 0.6268503289473685\n",
      "Epoch [400/500]\t Loss: 1.0312154293060303\t Accuracy: 0.6268503289473685\n",
      "Epoch [401/500]\t Loss: 1.0308931124837775\t Accuracy: 0.6272615131578947\n",
      "Epoch [402/500]\t Loss: 1.0305715516993874\t Accuracy: 0.6274671052631579\n",
      "Epoch [403/500]\t Loss: 1.0302506120581376\t Accuracy: 0.627672697368421\n",
      "Epoch [404/500]\t Loss: 1.0299303719871922\t Accuracy: 0.6278782894736842\n",
      "Epoch [405/500]\t Loss: 1.0296107875673395\t Accuracy: 0.627672697368421\n",
      "Epoch [406/500]\t Loss: 1.0292917897826748\t Accuracy: 0.6280838815789473\n",
      "Epoch [407/500]\t Loss: 1.028973494705401\t Accuracy: 0.6280838815789473\n",
      "Epoch [408/500]\t Loss: 1.0286558270454407\t Accuracy: 0.6282894736842105\n",
      "Epoch [409/500]\t Loss: 1.028338821310746\t Accuracy: 0.6282894736842105\n",
      "Epoch [410/500]\t Loss: 1.028022499460923\t Accuracy: 0.6282894736842105\n",
      "Epoch [411/500]\t Loss: 1.0277067548350285\t Accuracy: 0.6282894736842105\n",
      "Epoch [412/500]\t Loss: 1.0273916878198321\t Accuracy: 0.6284950657894737\n",
      "Epoch [413/500]\t Loss: 1.0270772199881704\t Accuracy: 0.62890625\n",
      "Epoch [414/500]\t Loss: 1.0267633921221684\t Accuracy: 0.6293174342105263\n",
      "Epoch [415/500]\t Loss: 1.0264501791251333\t Accuracy: 0.6293174342105263\n",
      "Epoch [416/500]\t Loss: 1.0261376249162775\t Accuracy: 0.6293174342105263\n",
      "Epoch [417/500]\t Loss: 1.025825654205523\t Accuracy: 0.6293174342105263\n",
      "Epoch [418/500]\t Loss: 1.025514354831294\t Accuracy: 0.6293174342105263\n",
      "Epoch [419/500]\t Loss: 1.0252036358180798\t Accuracy: 0.6295230263157895\n",
      "Epoch [420/500]\t Loss: 1.024893537948006\t Accuracy: 0.6297286184210527\n",
      "Epoch [421/500]\t Loss: 1.0245840706323321\t Accuracy: 0.6297286184210527\n",
      "Epoch [422/500]\t Loss: 1.0242751899518465\t Accuracy: 0.6297286184210527\n",
      "Epoch [423/500]\t Loss: 1.0239669053178084\t Accuracy: 0.6297286184210527\n",
      "Epoch [424/500]\t Loss: 1.0236592794719495\t Accuracy: 0.6299342105263158\n",
      "Epoch [425/500]\t Loss: 1.02335219320498\t Accuracy: 0.6299342105263158\n",
      "Epoch [426/500]\t Loss: 1.0230457123957182\t Accuracy: 0.6299342105263158\n",
      "Epoch [427/500]\t Loss: 1.022739871552116\t Accuracy: 0.6299342105263158\n",
      "Epoch [428/500]\t Loss: 1.0224345671503168\t Accuracy: 0.6299342105263158\n",
      "Epoch [429/500]\t Loss: 1.0221299121254368\t Accuracy: 0.6299342105263158\n",
      "Epoch [430/500]\t Loss: 1.0218258029536198\t Accuracy: 0.6303453947368421\n",
      "Epoch [431/500]\t Loss: 1.021522277279904\t Accuracy: 0.630139802631579\n",
      "Epoch [432/500]\t Loss: 1.0212193256930302\t Accuracy: 0.630139802631579\n",
      "Epoch [433/500]\t Loss: 1.0209169795638637\t Accuracy: 0.6299342105263158\n",
      "Epoch [434/500]\t Loss: 1.020615235755318\t Accuracy: 0.6299342105263158\n",
      "Epoch [435/500]\t Loss: 1.0203140691707009\t Accuracy: 0.6303453947368421\n",
      "Epoch [436/500]\t Loss: 1.0200134076570209\t Accuracy: 0.6305509868421053\n",
      "Epoch [437/500]\t Loss: 1.0197133453268754\t Accuracy: 0.6305509868421053\n",
      "Epoch [438/500]\t Loss: 1.019413875906091\t Accuracy: 0.6305509868421053\n",
      "Epoch [439/500]\t Loss: 1.0191149523383694\t Accuracy: 0.6305509868421053\n",
      "Epoch [440/500]\t Loss: 1.0188165714866237\t Accuracy: 0.6305509868421053\n",
      "Epoch [441/500]\t Loss: 1.018518786681326\t Accuracy: 0.6305509868421053\n",
      "Epoch [442/500]\t Loss: 1.018221588511216\t Accuracy: 0.6305509868421053\n",
      "Epoch [443/500]\t Loss: 1.0179249016862166\t Accuracy: 0.6305509868421053\n",
      "Epoch [444/500]\t Loss: 1.0176287481659336\t Accuracy: 0.6309621710526315\n",
      "Epoch [445/500]\t Loss: 1.017333215788791\t Accuracy: 0.6309621710526315\n",
      "Epoch [446/500]\t Loss: 1.0170381288779409\t Accuracy: 0.6309621710526315\n",
      "Epoch [447/500]\t Loss: 1.0167436913440102\t Accuracy: 0.6311677631578947\n",
      "Epoch [448/500]\t Loss: 1.016449749469757\t Accuracy: 0.6311677631578947\n",
      "Epoch [449/500]\t Loss: 1.016156372271086\t Accuracy: 0.631578947368421\n",
      "Epoch [450/500]\t Loss: 1.0158635471996509\t Accuracy: 0.6317845394736842\n",
      "Epoch [451/500]\t Loss: 1.0155712303362394\t Accuracy: 0.6319901315789473\n",
      "Epoch [452/500]\t Loss: 1.0152794405033714\t Accuracy: 0.6321957236842105\n",
      "Epoch [453/500]\t Loss: 1.0149882122089988\t Accuracy: 0.6321957236842105\n",
      "Epoch [454/500]\t Loss: 1.0146975109451695\t Accuracy: 0.6321957236842105\n",
      "Epoch [455/500]\t Loss: 1.0144073304377104\t Accuracy: 0.6328125\n",
      "Epoch [456/500]\t Loss: 1.0141176706866215\t Accuracy: 0.6330180921052632\n",
      "Epoch [457/500]\t Loss: 1.01382850659521\t Accuracy: 0.6332236842105263\n",
      "Epoch [458/500]\t Loss: 1.013539941687333\t Accuracy: 0.6336348684210527\n",
      "Epoch [459/500]\t Loss: 1.013251825382835\t Accuracy: 0.6338404605263158\n",
      "Epoch [460/500]\t Loss: 1.0129642172863609\t Accuracy: 0.6338404605263158\n",
      "Epoch [461/500]\t Loss: 1.012677224058854\t Accuracy: 0.6338404605263158\n",
      "Epoch [462/500]\t Loss: 1.0123906668863798\t Accuracy: 0.6338404605263158\n",
      "Epoch [463/500]\t Loss: 1.0121046336073625\t Accuracy: 0.6346628289473685\n",
      "Epoch [464/500]\t Loss: 1.0118191336330615\t Accuracy: 0.6344572368421053\n",
      "Epoch [465/500]\t Loss: 1.0115341199071783\t Accuracy: 0.6346628289473685\n",
      "Epoch [466/500]\t Loss: 1.0112496143893193\t Accuracy: 0.6348684210526315\n",
      "Epoch [467/500]\t Loss: 1.0109656641357823\t Accuracy: 0.6350740131578947\n",
      "Epoch [468/500]\t Loss: 1.010682159348538\t Accuracy: 0.6350740131578947\n",
      "Epoch [469/500]\t Loss: 1.0103991690434908\t Accuracy: 0.6350740131578947\n",
      "Epoch [470/500]\t Loss: 1.0101166743981211\t Accuracy: 0.6350740131578947\n",
      "Epoch [471/500]\t Loss: 1.009834703646208\t Accuracy: 0.6352796052631579\n",
      "Epoch [472/500]\t Loss: 1.0095531877718473\t Accuracy: 0.635485197368421\n",
      "Epoch [473/500]\t Loss: 1.0092721644200777\t Accuracy: 0.6358963815789473\n",
      "Epoch [474/500]\t Loss: 1.008991683784284\t Accuracy: 0.6363075657894737\n",
      "Epoch [475/500]\t Loss: 1.0087116329293502\t Accuracy: 0.6363075657894737\n",
      "Epoch [476/500]\t Loss: 1.0084320996937\t Accuracy: 0.6365131578947368\n",
      "Epoch [477/500]\t Loss: 1.0081530464322943\t Accuracy: 0.6369243421052632\n",
      "Epoch [478/500]\t Loss: 1.0078744731451337\t Accuracy: 0.6371299342105263\n",
      "Epoch [479/500]\t Loss: 1.0075963296388324\t Accuracy: 0.6371299342105263\n",
      "Epoch [480/500]\t Loss: 1.0073187382597673\t Accuracy: 0.6371299342105263\n",
      "Epoch [481/500]\t Loss: 1.0070416331291199\t Accuracy: 0.6371299342105263\n",
      "Epoch [482/500]\t Loss: 1.0067649671905918\t Accuracy: 0.6371299342105263\n",
      "Epoch [483/500]\t Loss: 1.0064888031859147\t Accuracy: 0.6371299342105263\n",
      "Epoch [484/500]\t Loss: 1.00621308464753\t Accuracy: 0.6371299342105263\n",
      "Epoch [485/500]\t Loss: 1.0059377770674856\t Accuracy: 0.6373355263157895\n",
      "Epoch [486/500]\t Loss: 1.0056630498484562\t Accuracy: 0.6375411184210527\n",
      "Epoch [487/500]\t Loss: 1.0053887179023342\t Accuracy: 0.6375411184210527\n",
      "Epoch [488/500]\t Loss: 1.0051149192609286\t Accuracy: 0.6377467105263158\n",
      "Epoch [489/500]\t Loss: 1.004841475110305\t Accuracy: 0.6377467105263158\n",
      "Epoch [490/500]\t Loss: 1.0045686050465232\t Accuracy: 0.637952302631579\n",
      "Epoch [491/500]\t Loss: 1.0042961741748608\t Accuracy: 0.6381578947368421\n",
      "Epoch [492/500]\t Loss: 1.0040241291648464\t Accuracy: 0.6381578947368421\n",
      "Epoch [493/500]\t Loss: 1.003752639419154\t Accuracy: 0.6381578947368421\n",
      "Epoch [494/500]\t Loss: 1.0034815449463694\t Accuracy: 0.6383634868421053\n",
      "Epoch [495/500]\t Loss: 1.0032109053511369\t Accuracy: 0.6383634868421053\n",
      "Epoch [496/500]\t Loss: 1.002940667302985\t Accuracy: 0.6385690789473685\n",
      "Epoch [497/500]\t Loss: 1.0026709688337225\t Accuracy: 0.6391858552631579\n",
      "Epoch [498/500]\t Loss: 1.0024017032824064\t Accuracy: 0.6391858552631579\n",
      "Epoch [499/500]\t Loss: 1.002132839278171\t Accuracy: 0.6391858552631579\n",
      "[FINAL]\t Loss: 1.142785403036302\t Accuracy: 0.5865675403225806\n"
     ]
    }
   ],
   "source": [
    "main(0,args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cec801-15fb-445a-9fa3-4f3338280898",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
