{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28bf9e86-0994-4379-aa8e-0a1c25c89ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "#SimCLR\n",
    "from simclr import SimCLR\n",
    "from simclr.modules import LogisticRegression, get_resnet\n",
    "from simclr.modules.transformations import TransformsSimCLR\n",
    "\n",
    "#ReLIC\n",
    "#[TODO]\n",
    "from relic import ReLIC\n",
    "#from relic.modules import ReLIC_Loss, get_resnet\n",
    "from relic.modules.transformations import TransformsRelic\n",
    "\n",
    "# TensorBoard\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "from utils import yaml_config_hook\n",
    "\n",
    "#PACS Dataset\n",
    "NUM_CLASSES = 7      # 7 classes for each domain: 'dog', 'elephant', 'giraffe', 'guitar', 'horse', 'house', 'person'\n",
    "DATASETS_NAMES = ['photo', 'art', 'cartoon', 'sketch']\n",
    "CLASSES_NAMES = ['Dog', 'Elephant', 'Giraffe', 'Guitar', 'Horse', 'House', 'Person']\n",
    "DIR_PHOTO = './datasets/PACS/photo'\n",
    "DIR_ART = './datasets/PACS/art_painting'\n",
    "DIR_CARTOON = './datasets/PACS/cartoon'\n",
    "DIR_SKETCH = './datasets/PACS/sketch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7c787ab-8e34-45de-907e-9dc70c352898",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"SimCLR/ReLIC\")\n",
    "config = yaml_config_hook(\"./config/config.yaml\")\n",
    "for k, v in config.items():\n",
    "    parser.add_argument(f\"--{k}\", default=v, type=type(v))\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "\n",
    "# Master address for distributed data parallel\n",
    "os.environ[\"MASTER_ADDR\"] = \"127.0.0.1\"\n",
    "os.environ[\"MASTER_PORT\"] = \"8000\"\n",
    "\n",
    "if not os.path.exists(args.model_path):\n",
    "    os.makedirs(args.model_path)\n",
    "\n",
    "args.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "args.num_gpus = torch.cuda.device_count()\n",
    "args.world_size = args.gpus * args.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e883616-3055-4582-814a-9738207d446d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(loader, ssl_model, device ,relic):\n",
    "    feature_vector = []\n",
    "    labels_vector = []\n",
    "    #SIMCLR\n",
    "    if relic == False:\n",
    "        for step, (x, y) in enumerate(loader):\n",
    "            x = x.to(device)\n",
    "\n",
    "            # get encoding\n",
    "            with torch.no_grad():\n",
    "                h, _, z, _ = ssl_model(x, x)\n",
    "\n",
    "            h = h.detach()\n",
    "\n",
    "            feature_vector.extend(h.cpu().detach().numpy())\n",
    "            labels_vector.extend(y.numpy())\n",
    "\n",
    "            if step % 20 == 0:\n",
    "                print(f\"Step [{step}/{len(loader)}]\\t Computing features...\")\n",
    "\n",
    "        feature_vector = np.array(feature_vector)\n",
    "        labels_vector = np.array(labels_vector)\n",
    "        print(\"Features shape {}\".format(feature_vector.shape))\n",
    "        return feature_vector, labels_vector\n",
    "    #ReLIC\n",
    "    elif relic == True:\n",
    "        for step, (x, y) in enumerate(loader):\n",
    "            x = x.to(device)\n",
    "\n",
    "            # get encoding\n",
    "            with torch.no_grad():\n",
    "                h,_,_, _, _, _, _ = ssl_model(x, x, x)\n",
    "                #online_1,online_2,target_1,target_2, original_features = ssl_model(x, x, x)\n",
    "                #print(\"online1 -- \", online_1.shape)\n",
    "                #print(\"online2 -- \", online_2.shape)\n",
    "                #print(\"target1 -- \", target_1.shape)\n",
    "                #print(\"target2 -- \", target_2.shape)\n",
    "                #print(\"original -- \", original_features.shape)\n",
    "                #print(\"AAAAAAAAAAAA\")\n",
    "                \n",
    "\n",
    "\n",
    "            \n",
    "            h = h.detach() #(256,512)\n",
    "\n",
    "            feature_vector.extend(h.cpu().detach().numpy())\n",
    "            labels_vector.extend(y.numpy())\n",
    "\n",
    "            \n",
    "\n",
    "            if step % 20 == 0:\n",
    "                print(f\"Step [{step}/{len(loader)}]\\t Computing features...\")\n",
    "\n",
    "        feature_vector = np.array(feature_vector)\n",
    "        labels_vector = np.array(labels_vector)\n",
    "        print(\"Features shape {}\".format(feature_vector.shape))\n",
    "        return feature_vector, labels_vector        \n",
    "\n",
    "def get_features(ssl_model, train_loader, test_loader, device, relic):\n",
    "    train_X, train_y = inference(train_loader, ssl_model, device, relic) #relic\n",
    "    test_X, test_y = inference(test_loader, ssl_model, device, relic) #relic\n",
    "    return train_X, train_y, test_X, test_y\n",
    "\n",
    "\n",
    "def create_data_loaders_from_arrays(X_train, y_train, X_test, y_test, batch_size):\n",
    "    train = torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(X_train), torch.from_numpy(y_train)\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "\n",
    "    test = torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(X_test), torch.from_numpy(y_test)\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "def train(args, loader, ssl_model, model, criterion, optimizer):\n",
    "    loss_epoch = 0\n",
    "    accuracy_epoch = 0\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x = x.to(args.device)\n",
    "        y = y.to(args.device)\n",
    "        \n",
    "\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        predicted = output.argmax(1)\n",
    "        acc = (predicted == y).sum().item() / y.size(0)\n",
    "        accuracy_epoch += acc\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_epoch += loss.item()\n",
    "        # if step % 100 == 0:\n",
    "        #     print(\n",
    "        #         f\"Step [{step}/{len(loader)}]\\t Loss: {loss.item()}\\t Accuracy: {acc}\"\n",
    "        #     )\n",
    "\n",
    "    return loss_epoch, accuracy_epoch\n",
    "\n",
    "\n",
    "def test(args, loader, ssl_model, model, criterion, optimizer):\n",
    "    loss_epoch = 0\n",
    "    accuracy_epoch = 0\n",
    "    model.eval()\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        model.zero_grad()\n",
    "\n",
    "        x = x.to(args.device)\n",
    "        y = y.to(args.device)\n",
    "\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        predicted = output.argmax(1)\n",
    "        acc = (predicted == y).sum().item() / y.size(0)\n",
    "        accuracy_epoch += acc\n",
    "\n",
    "        loss_epoch += loss.item()\n",
    "\n",
    "    return loss_epoch, accuracy_epoch\n",
    "\n",
    "def main(gpu,args):\n",
    "\n",
    "    print(\"ReLIC -- {c}\".format(c= args.relic))\n",
    "    print(\"Model From -- {m}, Epoch: {e}\".format(m= args.model_path, e= args.epoch_num))\n",
    "    print(\"All Evaluation args -- \", args)\n",
    "\n",
    "    \n",
    "    if args.relic == False:\n",
    "        if args.test_dataset == \"STL10\":\n",
    "            train_dataset = torchvision.datasets.STL10(\n",
    "                args.dataset_dir,\n",
    "                split=\"train\",\n",
    "                download=True,\n",
    "                transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "            )\n",
    "            test_dataset = torchvision.datasets.STL10(\n",
    "                args.dataset_dir,\n",
    "                split=\"test\",\n",
    "                download=True,\n",
    "                transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "            )\n",
    "        elif args.test_dataset == \"CIFAR10\":\n",
    "            train_dataset = torchvision.datasets.CIFAR10(\n",
    "                args.dataset_dir,\n",
    "                train=True,\n",
    "                download=True,\n",
    "                transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "            )\n",
    "            test_dataset = torchvision.datasets.CIFAR10(\n",
    "                args.dataset_dir,\n",
    "                train=False,\n",
    "                download=True,\n",
    "                transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "            )\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "    \n",
    "    #[TODO - Added] ReLIC\n",
    "    elif args.relic == True:\n",
    "        if args.test_dataset == \"STL10\":\n",
    "            train_dataset = torchvision.datasets.STL10(\n",
    "                args.dataset_dir,\n",
    "                split=\"train\",\n",
    "                download=True,\n",
    "                transform=TransformsRelic(size=args.image_size).test_transform,\n",
    "            )\n",
    "            test_dataset = torchvision.datasets.STL10(\n",
    "                args.dataset_dir,\n",
    "                split=\"test\",\n",
    "                download=True,\n",
    "                transform=TransformsRelic(size=args.image_size).test_transform,\n",
    "            )\n",
    "        elif args.test_dataset == \"CIFAR10\":\n",
    "            train_dataset = torchvision.datasets.CIFAR10(\n",
    "                args.dataset_dir,\n",
    "                train=True,\n",
    "                download=True,\n",
    "                transform=TransformsRelic(size=args.image_size).test_transform,\n",
    "            )\n",
    "            test_dataset = torchvision.datasets.CIFAR10(\n",
    "                args.dataset_dir,\n",
    "                train=False,\n",
    "                download=True,\n",
    "                transform=TransformsRelic(size=args.image_size).test_transform,\n",
    "            )\n",
    "        else:\n",
    "            raise NotImplementedError       \n",
    "\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=args.logistic_batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        num_workers=args.workers,\n",
    "    )\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=args.logistic_batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=True,\n",
    "        num_workers=args.workers,\n",
    "    )\n",
    "\n",
    "    encoder = get_resnet(args.resnet, pretrained=False)\n",
    "    n_features = encoder.fc.in_features  # get dimensions of fc layer\n",
    "\n",
    "    # load pre-trained model from checkpoint\n",
    "    if args.relic ==  False:\n",
    "        simclr_model = SimCLR(encoder, args.projection_dim, n_features)\n",
    "        model_fp = os.path.join(args.model_path, \"checkpoint_{}.tar\".format(args.epoch_num))\n",
    "        simclr_model.load_state_dict(torch.load(model_fp, map_location=args.device.type))\n",
    "        simclr_model = simclr_model.to(args.device)\n",
    "        simclr_model.eval()\n",
    "\n",
    "        ## Logistic Regression\n",
    "        n_classes = 10  # CIFAR-10 / STL-10\n",
    "        model = LogisticRegression(simclr_model.n_features, n_classes)\n",
    "        model = model.to(args.device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        print(\"### Creating features from pre-trained context model ###\")\n",
    "        (train_X, train_y, test_X, test_y) = get_features(\n",
    "            simclr_model, train_loader, test_loader, args.device, args.relic\n",
    "        )\n",
    "\n",
    "        arr_train_loader, arr_test_loader = create_data_loaders_from_arrays(\n",
    "            train_X, train_y, test_X, test_y, args.logistic_batch_size\n",
    "        )\n",
    "\n",
    "        for epoch in range(args.logistic_epochs):\n",
    "            loss_epoch, accuracy_epoch = train(\n",
    "                args, arr_train_loader, simclr_model, model, criterion, optimizer\n",
    "            )\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{args.logistic_epochs}]\\t Loss: {loss_epoch / len(arr_train_loader)}\\t Accuracy: {accuracy_epoch / len(arr_train_loader)}\"\n",
    "            )\n",
    "\n",
    "        # final testing\n",
    "        loss_epoch, accuracy_epoch = test(\n",
    "            args, arr_test_loader, simclr_model, model, criterion, optimizer\n",
    "        )\n",
    "        print(\n",
    "            f\"[FINAL]\\t Loss: {loss_epoch / len(arr_test_loader)}\\t Accuracy: {accuracy_epoch / len(arr_test_loader)}\"\n",
    "        )\n",
    "\n",
    "    #[TODO - ADDED] ReLIC\n",
    "    if args.relic == True:\n",
    "        relic_model = ReLIC(encoder, args.projection_dim, n_features)\n",
    "        model_fp = os.path.join(args.model_path, \"checkpoint_{}.tar\".format(args.epoch_num))\n",
    "        relic_model.load_state_dict(torch.load(model_fp, map_location=args.device.type))\n",
    "\n",
    "        #[TODO] JUST USE ENCODER PART ###CAUTION\n",
    "        #saved_n_features= relic_model.n_features\n",
    "        #relic_model= relic_model.encoder\n",
    "\n",
    "        relic_model = relic_model.to(args.device)\n",
    "        relic_model.eval()\n",
    "\n",
    "        \n",
    "\n",
    "        ## Logistic Regression\n",
    "        n_classes = 10  # CIFAR-10 / STL-10\n",
    "        #[TODO] JUST USE ENCODER PART ### CAUTION / OR USE Smaller Model (args.projection_dim)\n",
    "        #model = LogisticRegression(args.projection_dim, n_classes)\n",
    "        \n",
    "        model = LogisticRegression(relic_model.n_features, n_classes) #(relic_model.n_features, n_classes)= (512,10)\n",
    "        model = model.to(args.device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        print(\"### Creating features from pre-trained context model ###\")\n",
    "        (train_X, train_y, test_X, test_y) = get_features(\n",
    "            relic_model, train_loader, test_loader, args.device, args.relic\n",
    "        )\n",
    "\n",
    "        arr_train_loader, arr_test_loader = create_data_loaders_from_arrays(\n",
    "            train_X, train_y, test_X, test_y, args.logistic_batch_size\n",
    "        )\n",
    "\n",
    "        for epoch in range(args.logistic_epochs):\n",
    "            loss_epoch, accuracy_epoch = train(\n",
    "                args, arr_train_loader, relic_model, model, criterion, optimizer\n",
    "            )\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{args.logistic_epochs}]\\t Loss: {loss_epoch / len(arr_train_loader)}\\t Accuracy: {accuracy_epoch / len(arr_train_loader)}\"\n",
    "            )\n",
    "\n",
    "        # final testing\n",
    "        loss_epoch, accuracy_epoch = test(\n",
    "            args, arr_test_loader, relic_model, model, criterion, optimizer\n",
    "        )\n",
    "        print(\n",
    "            f\"[FINAL]\\t Loss: {loss_epoch / len(arr_test_loader)}\\t Accuracy: {accuracy_epoch / len(arr_test_loader)}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e11a4c3-da63-4d87-9aab-f087fde518ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.model_path= 'save/newrelic'\n",
    "args.epoch_num= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0126e51c-b3f7-47d2-becd-8ee0068570fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLIC -- True\n",
      "Model From -- save/newrelic, Epoch: 10\n",
      "All Evaluation args --  Namespace(nodes=1, gpus=1, nr=0, dataparallel=0, workers=8, dataset_dir='./datasets', seed=42, batch_size=128, image_size=224, start_epoch=0, epochs=100, dataset='CIFAR10', test_dataset='STL10', pacs_style='default', pretrain=False, relic=True, relic_normalize=True, relic_temp=1.0, relic_alpha=0.5, resnet='resnet18', projection_dim=64, optimizer='LARS', weight_decay=1e-06, temperature=0.5, model_path='save/newrelic', epoch_num=10, reload=False, logistic_batch_size=256, logistic_epochs=500, device=device(type='cuda', index=0), num_gpus=4, world_size=1)\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "### Creating features from pre-trained context model ###\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 7, got 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [20], line 288\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(gpu, args)\u001b[0m\n\u001b[1;32m    285\u001b[0m criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Creating features from pre-trained context model ###\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 288\u001b[0m (train_X, train_y, test_X, test_y) \u001b[38;5;241m=\u001b[39m \u001b[43mget_features\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrelic_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelic\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m arr_train_loader, arr_test_loader \u001b[38;5;241m=\u001b[39m create_data_loaders_from_arrays(\n\u001b[1;32m    293\u001b[0m     train_X, train_y, test_X, test_y, args\u001b[38;5;241m.\u001b[39mlogistic_batch_size\n\u001b[1;32m    294\u001b[0m )\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(args\u001b[38;5;241m.\u001b[39mlogistic_epochs):\n",
      "Cell \u001b[0;32mIn [20], line 60\u001b[0m, in \u001b[0;36mget_features\u001b[0;34m(ssl_model, train_loader, test_loader, device, relic)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_features\u001b[39m(ssl_model, train_loader, test_loader, device, relic):\n\u001b[0;32m---> 60\u001b[0m     train_X, train_y \u001b[38;5;241m=\u001b[39m \u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mssl_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelic\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#relic\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     test_X, test_y \u001b[38;5;241m=\u001b[39m inference(test_loader, ssl_model, device, relic) \u001b[38;5;66;03m#relic\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m train_X, train_y, test_X, test_y\n",
      "Cell \u001b[0;32mIn [20], line 32\u001b[0m, in \u001b[0;36minference\u001b[0;34m(loader, ssl_model, device, relic)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# get encoding\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 32\u001b[0m     h,_,_, _, _, _, _ \u001b[38;5;241m=\u001b[39m ssl_model(x, x, x)\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m#online_1,online_2,target_1,target_2, original_features = ssl_model(x, x, x)\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m#print(\"online1 -- \", online_1.shape)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m#print(\"online2 -- \", online_2.shape)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m#print(\"original -- \", original_features.shape)\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m#print(\"AAAAAAAAAAAA\")\u001b[39;00m\n\u001b[1;32m     44\u001b[0m h \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;66;03m#(256,512)\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 7, got 5)"
     ]
    }
   ],
   "source": [
    "main(0,args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cec801-15fb-445a-9fa3-4f3338280898",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
