{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28bf9e86-0994-4379-aa8e-0a1c25c89ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "#SimCLR\n",
    "from simclr import SimCLR\n",
    "from simclr.modules import LogisticRegression, get_resnet\n",
    "from simclr.modules.transformations import TransformsSimCLR\n",
    "\n",
    "#ReLIC\n",
    "#[TODO]\n",
    "from relic import ReLIC\n",
    "#from relic.modules import ReLIC_Loss, get_resnet\n",
    "from relic.modules.transformations import TransformsRelic\n",
    "\n",
    "# TensorBoard\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "from utils import yaml_config_hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7c787ab-8e34-45de-907e-9dc70c352898",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"SimCLR/ReLIC\")\n",
    "config = yaml_config_hook(\"./config/config.yaml\")\n",
    "for k, v in config.items():\n",
    "    parser.add_argument(f\"--{k}\", default=v, type=type(v))\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "\n",
    "# Master address for distributed data parallel\n",
    "os.environ[\"MASTER_ADDR\"] = \"127.0.0.1\"\n",
    "os.environ[\"MASTER_PORT\"] = \"8000\"\n",
    "\n",
    "if not os.path.exists(args.model_path):\n",
    "    os.makedirs(args.model_path)\n",
    "\n",
    "args.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "args.num_gpus = torch.cuda.device_count()\n",
    "args.world_size = args.gpus * args.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e883616-3055-4582-814a-9738207d446d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(loader, ssl_model, device ,relic):\n",
    "    feature_vector = []\n",
    "    labels_vector = []\n",
    "    #SIMCLR\n",
    "    if relic == False:\n",
    "        for step, (x, y) in enumerate(loader):\n",
    "            x = x.to(device)\n",
    "\n",
    "            # get encoding\n",
    "            with torch.no_grad():\n",
    "                h, _, z, _ = ssl_model(x, x)\n",
    "\n",
    "            h = h.detach()\n",
    "\n",
    "            feature_vector.extend(h.cpu().detach().numpy())\n",
    "            labels_vector.extend(y.numpy())\n",
    "\n",
    "            if step % 20 == 0:\n",
    "                print(f\"Step [{step}/{len(loader)}]\\t Computing features...\")\n",
    "\n",
    "        feature_vector = np.array(feature_vector)\n",
    "        labels_vector = np.array(labels_vector)\n",
    "        print(\"Features shape {}\".format(feature_vector.shape))\n",
    "        return feature_vector, labels_vector\n",
    "    #ReLIC\n",
    "    elif relic == True:\n",
    "        for step, (x, y) in enumerate(loader):\n",
    "            x = x.to(device)\n",
    "\n",
    "            # get encoding\n",
    "            with torch.no_grad():\n",
    "                #[TODO] inference\n",
    "                \n",
    "                #dkcho\n",
    "                #h,_,_, _, _, _, _ = ssl_model(x, x, x)\n",
    "                \n",
    "                #new\n",
    "                h= ssl_model(x,x,x, test= True)\n",
    "                \n",
    "\n",
    "\n",
    "            \n",
    "            h = h.detach() #(256,512)\n",
    "\n",
    "            feature_vector.extend(h.cpu().detach().numpy())\n",
    "            labels_vector.extend(y.numpy())\n",
    "\n",
    "            \n",
    "\n",
    "            if step % 20 == 0:\n",
    "                print(f\"Step [{step}/{len(loader)}]\\t Computing features...\")\n",
    "\n",
    "        feature_vector = np.array(feature_vector)\n",
    "        labels_vector = np.array(labels_vector)\n",
    "        print(\"Features shape {}\".format(feature_vector.shape))\n",
    "        return feature_vector, labels_vector        \n",
    "\n",
    "def get_features(ssl_model, train_loader, test_loader, device, relic):\n",
    "    train_X, train_y = inference(train_loader, ssl_model, device, relic) #relic\n",
    "    test_X, test_y = inference(test_loader, ssl_model, device, relic) #relic\n",
    "    return train_X, train_y, test_X, test_y\n",
    "\n",
    "\n",
    "def create_data_loaders_from_arrays(X_train, y_train, X_test, y_test, batch_size):\n",
    "    train = torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(X_train), torch.from_numpy(y_train)\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "\n",
    "    test = torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(X_test), torch.from_numpy(y_test)\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "def train(args, loader, ssl_model, model, criterion, optimizer):\n",
    "    loss_epoch = 0\n",
    "    accuracy_epoch = 0\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x = x.to(args.device)\n",
    "        y = y.to(args.device)\n",
    "        \n",
    "\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        predicted = output.argmax(1)\n",
    "        acc = (predicted == y).sum().item() / y.size(0)\n",
    "        accuracy_epoch += acc\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_epoch += loss.item()\n",
    "        # if step % 100 == 0:\n",
    "        #     print(\n",
    "        #         f\"Step [{step}/{len(loader)}]\\t Loss: {loss.item()}\\t Accuracy: {acc}\"\n",
    "        #     )\n",
    "\n",
    "    return loss_epoch, accuracy_epoch\n",
    "\n",
    "\n",
    "def test(args, loader, ssl_model, model, criterion, optimizer):\n",
    "    loss_epoch = 0\n",
    "    accuracy_epoch = 0\n",
    "    model.eval()\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        model.zero_grad()\n",
    "\n",
    "        x = x.to(args.device)\n",
    "        y = y.to(args.device)\n",
    "\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        predicted = output.argmax(1)\n",
    "        acc = (predicted == y).sum().item() / y.size(0)\n",
    "        accuracy_epoch += acc\n",
    "\n",
    "        loss_epoch += loss.item()\n",
    "\n",
    "    return loss_epoch, accuracy_epoch\n",
    "\n",
    "def main(gpu,args):\n",
    "\n",
    "    print(\"ReLIC -- {c}\".format(c= args.relic))\n",
    "    print(\"Model From -- {m}, Epoch: {e}\".format(m= args.model_path, e= args.epoch_num))\n",
    "    print(\"All Evaluation args -- \", args)\n",
    "\n",
    "    \n",
    "    if args.relic == False:\n",
    "        if args.test_dataset == \"STL10\":\n",
    "            train_dataset = torchvision.datasets.STL10(\n",
    "                args.dataset_dir,\n",
    "                split=\"train\",\n",
    "                download=True,\n",
    "                transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "            )\n",
    "            test_dataset = torchvision.datasets.STL10(\n",
    "                args.dataset_dir,\n",
    "                split=\"test\",\n",
    "                download=True,\n",
    "                transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "            )\n",
    "        elif args.test_dataset == \"CIFAR10\":\n",
    "            train_dataset = torchvision.datasets.CIFAR10(\n",
    "                args.dataset_dir,\n",
    "                train=True,\n",
    "                download=True,\n",
    "                transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "            )\n",
    "            test_dataset = torchvision.datasets.CIFAR10(\n",
    "                args.dataset_dir,\n",
    "                train=False,\n",
    "                download=True,\n",
    "                transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "            )\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "    \n",
    "    #[TODO - Added] ReLIC\n",
    "    elif args.relic == True:\n",
    "        if args.test_dataset == \"STL10\":\n",
    "            train_dataset = torchvision.datasets.STL10(\n",
    "                args.dataset_dir,\n",
    "                split=\"train\",\n",
    "                download=True,\n",
    "                transform=TransformsRelic(size=args.image_size).test_transform,\n",
    "            )\n",
    "            test_dataset = torchvision.datasets.STL10(\n",
    "                args.dataset_dir,\n",
    "                split=\"test\",\n",
    "                download=True,\n",
    "                transform=TransformsRelic(size=args.image_size).test_transform,\n",
    "            )\n",
    "        elif args.test_dataset == \"CIFAR10\":\n",
    "            train_dataset = torchvision.datasets.CIFAR10(\n",
    "                args.dataset_dir,\n",
    "                train=True,\n",
    "                download=True,\n",
    "                transform=TransformsRelic(size=args.image_size).test_transform,\n",
    "            )\n",
    "            test_dataset = torchvision.datasets.CIFAR10(\n",
    "                args.dataset_dir,\n",
    "                train=False,\n",
    "                download=True,\n",
    "                transform=TransformsRelic(size=args.image_size).test_transform,\n",
    "            )\n",
    "        else:\n",
    "            raise NotImplementedError       \n",
    "\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=args.logistic_batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        num_workers=args.workers,\n",
    "    )\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=args.logistic_batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=True,\n",
    "        num_workers=args.workers,\n",
    "    )\n",
    "\n",
    "    encoder = get_resnet(args.resnet, pretrained=False)\n",
    "    n_features = encoder.fc.in_features  # get dimensions of fc layer\n",
    "\n",
    "    # load pre-trained model from checkpoint\n",
    "    if args.relic ==  False:\n",
    "        simclr_model = SimCLR(encoder, args.projection_dim, n_features)\n",
    "        model_fp = os.path.join(args.model_path, \"checkpoint_{}.tar\".format(args.epoch_num))\n",
    "        simclr_model.load_state_dict(torch.load(model_fp, map_location=args.device.type))\n",
    "        simclr_model = simclr_model.to(args.device)\n",
    "        simclr_model.eval()\n",
    "\n",
    "        ## Logistic Regression\n",
    "        n_classes = 10  # CIFAR-10 / STL-10\n",
    "        model = LogisticRegression(simclr_model.n_features, n_classes)\n",
    "        model = model.to(args.device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        print(\"### Creating features from pre-trained context model ###\")\n",
    "        (train_X, train_y, test_X, test_y) = get_features(\n",
    "            simclr_model, train_loader, test_loader, args.device, args.relic\n",
    "        )\n",
    "\n",
    "        arr_train_loader, arr_test_loader = create_data_loaders_from_arrays(\n",
    "            train_X, train_y, test_X, test_y, args.logistic_batch_size\n",
    "        )\n",
    "\n",
    "        for epoch in range(args.logistic_epochs):\n",
    "            loss_epoch, accuracy_epoch = train(\n",
    "                args, arr_train_loader, simclr_model, model, criterion, optimizer\n",
    "            )\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{args.logistic_epochs}]\\t Loss: {loss_epoch / len(arr_train_loader)}\\t Accuracy: {accuracy_epoch / len(arr_train_loader)}\"\n",
    "            )\n",
    "\n",
    "        # final testing\n",
    "        loss_epoch, accuracy_epoch = test(\n",
    "            args, arr_test_loader, simclr_model, model, criterion, optimizer\n",
    "        )\n",
    "        print(\n",
    "            f\"[FINAL]\\t Loss: {loss_epoch / len(arr_test_loader)}\\t Accuracy: {accuracy_epoch / len(arr_test_loader)}\"\n",
    "        )\n",
    "\n",
    "    #[TODO - ADDED] ReLIC\n",
    "    if args.relic == True:\n",
    "        relic_model = ReLIC(encoder, args.projection_dim, n_features)\n",
    "        model_fp = os.path.join(args.model_path, \"checkpoint_{}.tar\".format(args.epoch_num))\n",
    "        relic_model.load_state_dict(torch.load(model_fp, map_location=args.device.type))\n",
    "\n",
    "        #[TODO] JUST USE ENCODER PART ###CAUTION\n",
    "        #saved_n_features= relic_model.n_features\n",
    "        #relic_model= relic_model.encoder\n",
    "\n",
    "        relic_model = relic_model.to(args.device)\n",
    "        relic_model.eval()\n",
    "\n",
    "        \n",
    "\n",
    "        ## Logistic Regression\n",
    "        n_classes = 10  # CIFAR-10 / STL-10\n",
    "        #[TODO] JUST USE ENCODER PART ### CAUTION / OR USE Smaller Model (args.projection_dim)\n",
    "        #model = LogisticRegression(args.projection_dim, n_classes)\n",
    "        \n",
    "        model = LogisticRegression(relic_model.n_features, n_classes) #(relic_model.n_features, n_classes)= (512,10)\n",
    "        model = model.to(args.device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        print(\"### Creating features from pre-trained context model ###\")\n",
    "        (train_X, train_y, test_X, test_y) = get_features(\n",
    "            relic_model, train_loader, test_loader, args.device, args.relic\n",
    "        )\n",
    "\n",
    "        arr_train_loader, arr_test_loader = create_data_loaders_from_arrays(\n",
    "            train_X, train_y, test_X, test_y, args.logistic_batch_size\n",
    "        )\n",
    "\n",
    "        for epoch in range(args.logistic_epochs):\n",
    "            loss_epoch, accuracy_epoch = train(\n",
    "                args, arr_train_loader, relic_model, model, criterion, optimizer\n",
    "            )\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{args.logistic_epochs}]\\t Loss: {loss_epoch / len(arr_train_loader)}\\t Accuracy: {accuracy_epoch / len(arr_train_loader)}\"\n",
    "            )\n",
    "\n",
    "        # final testing\n",
    "        loss_epoch, accuracy_epoch = test(\n",
    "            args, arr_test_loader, relic_model, model, criterion, optimizer\n",
    "        )\n",
    "        print(\n",
    "            f\"[FINAL]\\t Loss: {loss_epoch / len(arr_test_loader)}\\t Accuracy: {accuracy_epoch / len(arr_test_loader)}\"\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c69b165e-05b8-4070-842a-6cae60bc00f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.test_dataset = 'STL10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e11a4c3-da63-4d87-9aab-f087fde518ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.prism= True\n",
    "args.relic= True\n",
    "args.projection_dim= 128\n",
    "args.model_path= 'save/test/prism2'\n",
    "args.epoch_num= 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0126e51c-b3f7-47d2-becd-8ee0068570fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLIC -- True\n",
      "Model From -- save/test/prism2, Epoch: 40\n",
      "All Evaluation args --  Namespace(nodes=1, gpus=1, nr=0, dataparallel=0, workers=8, dataset_dir='./datasets', seed=42, batch_size=128, image_size=224, start_epoch=0, epochs=200, dataset='CIFAR10', test_dataset='STL10', pacs_style='default', pretrain=False, relic=True, relic_normalize=True, relic_temp=1.0, relic_alpha=0.5, prism=True, resnet='resnet18', projection_dim=128, optimizer='LARS', weight_decay=1e-06, temperature=0.5, model_path='save/test/prism2', epoch_num=40, reload=False, logistic_batch_size=256, logistic_epochs=500, device=device(type='cuda', index=0), num_gpus=4, world_size=1)\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "### Creating features from pre-trained context model ###\n",
      "Step [0/19]\t Computing features...\n",
      "Features shape (4864, 512)\n",
      "Step [0/31]\t Computing features...\n",
      "Step [20/31]\t Computing features...\n",
      "Features shape (7936, 512)\n",
      "Epoch [0/500]\t Loss: 2.2447886216013053\t Accuracy: 0.18482730263157895\n",
      "Epoch [1/500]\t Loss: 1.864076714766653\t Accuracy: 0.3519736842105263\n",
      "Epoch [2/500]\t Loss: 1.6700110310002376\t Accuracy: 0.43050986842105265\n",
      "Epoch [3/500]\t Loss: 1.5590434388110512\t Accuracy: 0.47245065789473684\n",
      "Epoch [4/500]\t Loss: 1.487932518908852\t Accuracy: 0.4886924342105263\n",
      "Epoch [5/500]\t Loss: 1.4382546575445878\t Accuracy: 0.4995888157894737\n",
      "Epoch [6/500]\t Loss: 1.4006994209791486\t Accuracy: 0.5074013157894737\n",
      "Epoch [7/500]\t Loss: 1.3711177863572772\t Accuracy: 0.5178865131578947\n",
      "Epoch [8/500]\t Loss: 1.3469373740647967\t Accuracy: 0.5240542763157895\n",
      "Epoch [9/500]\t Loss: 1.3266015241020603\t Accuracy: 0.5304276315789473\n",
      "Epoch [10/500]\t Loss: 1.3091340127744173\t Accuracy: 0.5337171052631579\n",
      "Epoch [11/500]\t Loss: 1.2938651975832487\t Accuracy: 0.5374177631578947\n",
      "Epoch [12/500]\t Loss: 1.2803230285644531\t Accuracy: 0.5427631578947368\n",
      "Epoch [13/500]\t Loss: 1.26816767767856\t Accuracy: 0.5462582236842105\n",
      "Epoch [14/500]\t Loss: 1.2571465404410112\t Accuracy: 0.5501644736842105\n",
      "Epoch [15/500]\t Loss: 1.2470678216532658\t Accuracy: 0.5526315789473685\n",
      "Epoch [16/500]\t Loss: 1.2377833065233732\t Accuracy: 0.5532483552631579\n",
      "Epoch [17/500]\t Loss: 1.2291766028655202\t Accuracy: 0.5571546052631579\n",
      "Epoch [18/500]\t Loss: 1.221154915659051\t Accuracy: 0.5649671052631579\n",
      "Epoch [19/500]\t Loss: 1.2136432622608386\t Accuracy: 0.5672286184210527\n",
      "Epoch [20/500]\t Loss: 1.2065801934192055\t Accuracy: 0.5696957236842105\n",
      "Epoch [21/500]\t Loss: 1.1999150828311318\t Accuracy: 0.5701069078947368\n",
      "Epoch [22/500]\t Loss: 1.193605335135209\t Accuracy: 0.5717516447368421\n",
      "Epoch [23/500]\t Loss: 1.1876152753829956\t Accuracy: 0.5733963815789473\n",
      "Epoch [24/500]\t Loss: 1.181914354625501\t Accuracy: 0.5748355263157895\n",
      "Epoch [25/500]\t Loss: 1.1764764597541408\t Accuracy: 0.576891447368421\n",
      "Epoch [26/500]\t Loss: 1.1712788719879954\t Accuracy: 0.578125\n",
      "Epoch [27/500]\t Loss: 1.1663018966975964\t Accuracy: 0.5789473684210527\n",
      "Epoch [28/500]\t Loss: 1.161528192068401\t Accuracy: 0.580797697368421\n",
      "Epoch [29/500]\t Loss: 1.1569425181338662\t Accuracy: 0.5822368421052632\n",
      "Epoch [30/500]\t Loss: 1.152531247389944\t Accuracy: 0.5830592105263158\n",
      "Epoch [31/500]\t Loss: 1.1482824024401213\t Accuracy: 0.5838815789473685\n",
      "Epoch [32/500]\t Loss: 1.1441849721105475\t Accuracy: 0.5853207236842105\n",
      "Epoch [33/500]\t Loss: 1.1402292314328646\t Accuracy: 0.5875822368421053\n",
      "Epoch [34/500]\t Loss: 1.136406465580589\t Accuracy: 0.5879934210526315\n",
      "Epoch [35/500]\t Loss: 1.1327083926451833\t Accuracy: 0.5890213815789473\n",
      "Epoch [36/500]\t Loss: 1.1291278977143138\t Accuracy: 0.5900493421052632\n",
      "Epoch [37/500]\t Loss: 1.1256582172293412\t Accuracy: 0.5906661184210527\n",
      "Epoch [38/500]\t Loss: 1.122293189952248\t Accuracy: 0.592516447368421\n",
      "Epoch [39/500]\t Loss: 1.119027250691464\t Accuracy: 0.5947779605263158\n",
      "Epoch [40/500]\t Loss: 1.1158551103190373\t Accuracy: 0.596422697368421\n",
      "Epoch [41/500]\t Loss: 1.1127719628183466\t Accuracy: 0.5966282894736842\n",
      "Epoch [42/500]\t Loss: 1.1097733786231594\t Accuracy: 0.5986842105263158\n",
      "Epoch [43/500]\t Loss: 1.106855179134168\t Accuracy: 0.5999177631578947\n",
      "Epoch [44/500]\t Loss: 1.1040135496541073\t Accuracy: 0.5999177631578947\n",
      "Epoch [45/500]\t Loss: 1.1012448511625592\t Accuracy: 0.6005345394736842\n",
      "Epoch [46/500]\t Loss: 1.0985457332510697\t Accuracy: 0.6021792763157895\n",
      "Epoch [47/500]\t Loss: 1.0959130462847257\t Accuracy: 0.6023848684210527\n",
      "Epoch [48/500]\t Loss: 1.0933438351279812\t Accuracy: 0.6030016447368421\n",
      "Epoch [49/500]\t Loss: 1.0908354269830804\t Accuracy: 0.6030016447368421\n",
      "Epoch [50/500]\t Loss: 1.088385117681403\t Accuracy: 0.6040296052631579\n",
      "Epoch [51/500]\t Loss: 1.085990491666292\t Accuracy: 0.6038240131578947\n",
      "Epoch [52/500]\t Loss: 1.0836492212195146\t Accuracy: 0.6052631578947368\n",
      "Epoch [53/500]\t Loss: 1.0813592170414172\t Accuracy: 0.6060855263157895\n",
      "Epoch [54/500]\t Loss: 1.0791183584614803\t Accuracy: 0.6064967105263158\n",
      "Epoch [55/500]\t Loss: 1.0769247569535907\t Accuracy: 0.6071134868421053\n",
      "Epoch [56/500]\t Loss: 1.074776530265808\t Accuracy: 0.6083470394736842\n",
      "Epoch [57/500]\t Loss: 1.072671934178001\t Accuracy: 0.6097861842105263\n",
      "Epoch [58/500]\t Loss: 1.0706093875985396\t Accuracy: 0.6104029605263158\n",
      "Epoch [59/500]\t Loss: 1.068587296887448\t Accuracy: 0.6112253289473685\n",
      "Epoch [60/500]\t Loss: 1.0666042095736454\t Accuracy: 0.6122532894736842\n",
      "Epoch [61/500]\t Loss: 1.0646586512264453\t Accuracy: 0.6128700657894737\n",
      "Epoch [62/500]\t Loss: 1.062749395245\t Accuracy: 0.6124588815789473\n",
      "Epoch [63/500]\t Loss: 1.0608750707224797\t Accuracy: 0.6136924342105263\n",
      "Epoch [64/500]\t Loss: 1.05903444792095\t Accuracy: 0.614514802631579\n",
      "Epoch [65/500]\t Loss: 1.0572265166985362\t Accuracy: 0.6151315789473685\n",
      "Epoch [66/500]\t Loss: 1.0554500284947848\t Accuracy: 0.6163651315789473\n",
      "Epoch [67/500]\t Loss: 1.0537039857161672\t Accuracy: 0.6165707236842105\n",
      "Epoch [68/500]\t Loss: 1.0519873844949823\t Accuracy: 0.6182154605263158\n",
      "Epoch [69/500]\t Loss: 1.0502993338986446\t Accuracy: 0.6186266447368421\n",
      "Epoch [70/500]\t Loss: 1.0486388049627606\t Accuracy: 0.6190378289473685\n",
      "Epoch [71/500]\t Loss: 1.0470049632223029\t Accuracy: 0.619860197368421\n",
      "Epoch [72/500]\t Loss: 1.045397074599015\t Accuracy: 0.6202713815789473\n",
      "Epoch [73/500]\t Loss: 1.0438141634589748\t Accuracy: 0.6202713815789473\n",
      "Epoch [74/500]\t Loss: 1.0422555898365222\t Accuracy: 0.6202713815789473\n",
      "Epoch [75/500]\t Loss: 1.0407205945567082\t Accuracy: 0.6206825657894737\n",
      "Epoch [76/500]\t Loss: 1.039208449815449\t Accuracy: 0.6217105263157895\n",
      "Epoch [77/500]\t Loss: 1.0377184842762195\t Accuracy: 0.6229440789473685\n",
      "Epoch [78/500]\t Loss: 1.0362500956183986\t Accuracy: 0.6245888157894737\n",
      "Epoch [79/500]\t Loss: 1.034802634465067\t Accuracy: 0.6256167763157895\n",
      "Epoch [80/500]\t Loss: 1.0333754671247382\t Accuracy: 0.6264391447368421\n",
      "Epoch [81/500]\t Loss: 1.0319680351960032\t Accuracy: 0.6272615131578947\n",
      "Epoch [82/500]\t Loss: 1.0305798430191844\t Accuracy: 0.6284950657894737\n",
      "Epoch [83/500]\t Loss: 1.029210322781613\t Accuracy: 0.6287006578947368\n",
      "Epoch [84/500]\t Loss: 1.027858975686525\t Accuracy: 0.62890625\n",
      "Epoch [85/500]\t Loss: 1.0265252370583384\t Accuracy: 0.6293174342105263\n",
      "Epoch [86/500]\t Loss: 1.0252087837771366\t Accuracy: 0.6299342105263158\n",
      "Epoch [87/500]\t Loss: 1.0239090323448181\t Accuracy: 0.630139802631579\n",
      "Epoch [88/500]\t Loss: 1.0226255874884755\t Accuracy: 0.6305509868421053\n",
      "Epoch [89/500]\t Loss: 1.0213580853060673\t Accuracy: 0.6313733552631579\n",
      "Epoch [90/500]\t Loss: 1.020106011315396\t Accuracy: 0.6313733552631579\n",
      "Epoch [91/500]\t Loss: 1.0188690518078052\t Accuracy: 0.6313733552631579\n",
      "Epoch [92/500]\t Loss: 1.0176468020991276\t Accuracy: 0.631578947368421\n",
      "Epoch [93/500]\t Loss: 1.016438901424408\t Accuracy: 0.6317845394736842\n",
      "Epoch [94/500]\t Loss: 1.0152449796074314\t Accuracy: 0.6317845394736842\n",
      "Epoch [95/500]\t Loss: 1.0140647888183594\t Accuracy: 0.6321957236842105\n",
      "Epoch [96/500]\t Loss: 1.0128978804538125\t Accuracy: 0.6321957236842105\n",
      "Epoch [97/500]\t Loss: 1.0117439659018266\t Accuracy: 0.6326069078947368\n",
      "Epoch [98/500]\t Loss: 1.0106027785100435\t Accuracy: 0.6336348684210527\n",
      "Epoch [99/500]\t Loss: 1.0094739731989408\t Accuracy: 0.6338404605263158\n",
      "Epoch [100/500]\t Loss: 1.0083573554691516\t Accuracy: 0.6338404605263158\n",
      "Epoch [101/500]\t Loss: 1.0072525018139888\t Accuracy: 0.6338404605263158\n",
      "Epoch [102/500]\t Loss: 1.0061593024354232\t Accuracy: 0.634046052631579\n",
      "Epoch [103/500]\t Loss: 1.0050773965684991\t Accuracy: 0.6344572368421053\n",
      "Epoch [104/500]\t Loss: 1.0040065771655033\t Accuracy: 0.6346628289473685\n",
      "Epoch [105/500]\t Loss: 1.0029465462032117\t Accuracy: 0.6346628289473685\n",
      "Epoch [106/500]\t Loss: 1.00189713427895\t Accuracy: 0.6352796052631579\n",
      "Epoch [107/500]\t Loss: 1.0008580998370522\t Accuracy: 0.6356907894736842\n",
      "Epoch [108/500]\t Loss: 0.9998291323059484\t Accuracy: 0.6356907894736842\n",
      "Epoch [109/500]\t Loss: 0.9988101375730414\t Accuracy: 0.6363075657894737\n",
      "Epoch [110/500]\t Loss: 0.9978008960422716\t Accuracy: 0.6363075657894737\n",
      "Epoch [111/500]\t Loss: 0.9968011096904152\t Accuracy: 0.6365131578947368\n",
      "Epoch [112/500]\t Loss: 0.9958106624452692\t Accuracy: 0.6373355263157895\n",
      "Epoch [113/500]\t Loss: 0.9948293723558125\t Accuracy: 0.6381578947368421\n",
      "Epoch [114/500]\t Loss: 0.993856994729293\t Accuracy: 0.6385690789473685\n",
      "Epoch [115/500]\t Loss: 0.9928933883968153\t Accuracy: 0.6387746710526315\n",
      "Epoch [116/500]\t Loss: 0.991938380818618\t Accuracy: 0.6389802631578947\n",
      "Epoch [117/500]\t Loss: 0.9909918057291132\t Accuracy: 0.639391447368421\n",
      "Epoch [118/500]\t Loss: 0.9900535313706649\t Accuracy: 0.6402138157894737\n",
      "Epoch [119/500]\t Loss: 0.9891232848167419\t Accuracy: 0.6398026315789473\n",
      "Epoch [120/500]\t Loss: 0.9882010033256129\t Accuracy: 0.6404194078947368\n",
      "Epoch [121/500]\t Loss: 0.9872865269058629\t Accuracy: 0.640625\n",
      "Epoch [122/500]\t Loss: 0.9863796924289904\t Accuracy: 0.6408305921052632\n",
      "Epoch [123/500]\t Loss: 0.9854803963711387\t Accuracy: 0.6412417763157895\n",
      "Epoch [124/500]\t Loss: 0.9845884222733347\t Accuracy: 0.6416529605263158\n",
      "Epoch [125/500]\t Loss: 0.9837037387647127\t Accuracy: 0.6422697368421053\n",
      "Epoch [126/500]\t Loss: 0.9828261199750399\t Accuracy: 0.6428865131578947\n",
      "Epoch [127/500]\t Loss: 0.9819555031625848\t Accuracy: 0.6430921052631579\n",
      "Epoch [128/500]\t Loss: 0.9810917157875864\t Accuracy: 0.6449424342105263\n",
      "Epoch [129/500]\t Loss: 0.980234610406976\t Accuracy: 0.6453536184210527\n",
      "Epoch [130/500]\t Loss: 0.9793841995690998\t Accuracy: 0.6461759868421053\n",
      "Epoch [131/500]\t Loss: 0.9785402542666385\t Accuracy: 0.6463815789473685\n",
      "Epoch [132/500]\t Loss: 0.9777026897982547\t Accuracy: 0.6467927631578947\n",
      "Epoch [133/500]\t Loss: 0.976871415188438\t Accuracy: 0.6469983552631579\n",
      "Epoch [134/500]\t Loss: 0.9760463080908123\t Accuracy: 0.6482319078947368\n",
      "Epoch [135/500]\t Loss: 0.9752272524331745\t Accuracy: 0.6492598684210527\n",
      "Epoch [136/500]\t Loss: 0.9744141917479666\t Accuracy: 0.6502878289473685\n",
      "Epoch [137/500]\t Loss: 0.9736069754550332\t Accuracy: 0.6500822368421053\n",
      "Epoch [138/500]\t Loss: 0.9728055533609892\t Accuracy: 0.6513157894736842\n",
      "Epoch [139/500]\t Loss: 0.972009793708199\t Accuracy: 0.6517269736842105\n",
      "Epoch [140/500]\t Loss: 0.9712196274807579\t Accuracy: 0.6519325657894737\n",
      "Epoch [141/500]\t Loss: 0.9704349511548093\t Accuracy: 0.6529605263157895\n",
      "Epoch [142/500]\t Loss: 0.9696556863031889\t Accuracy: 0.653577302631579\n",
      "Epoch [143/500]\t Loss: 0.9688817262649536\t Accuracy: 0.653577302631579\n",
      "Epoch [144/500]\t Loss: 0.9681130208467182\t Accuracy: 0.6537828947368421\n",
      "Epoch [145/500]\t Loss: 0.9673494978954917\t Accuracy: 0.6548108552631579\n",
      "Epoch [146/500]\t Loss: 0.9665910319278115\t Accuracy: 0.6548108552631579\n",
      "Epoch [147/500]\t Loss: 0.965837604121158\t Accuracy: 0.6552220394736842\n",
      "Epoch [148/500]\t Loss: 0.9650890733066358\t Accuracy: 0.6556332236842105\n",
      "Epoch [149/500]\t Loss: 0.9643453736054269\t Accuracy: 0.6556332236842105\n",
      "Epoch [150/500]\t Loss: 0.9636065332513106\t Accuracy: 0.6564555921052632\n",
      "Epoch [151/500]\t Loss: 0.962872326374054\t Accuracy: 0.6566611842105263\n",
      "Epoch [152/500]\t Loss: 0.9621428000299554\t Accuracy: 0.6568667763157895\n",
      "Epoch [153/500]\t Loss: 0.9614178663805911\t Accuracy: 0.6572779605263158\n",
      "Epoch [154/500]\t Loss: 0.9606974124908447\t Accuracy: 0.657483552631579\n",
      "Epoch [155/500]\t Loss: 0.9599814352236296\t Accuracy: 0.6570723684210527\n",
      "Epoch [156/500]\t Loss: 0.959269831055089\t Accuracy: 0.6581003289473685\n",
      "Epoch [157/500]\t Loss: 0.9585625215580589\t Accuracy: 0.6585115131578947\n",
      "Epoch [158/500]\t Loss: 0.9578595098696256\t Accuracy: 0.6585115131578947\n",
      "Epoch [159/500]\t Loss: 0.9571606673692402\t Accuracy: 0.6587171052631579\n",
      "Epoch [160/500]\t Loss: 0.9564659909198159\t Accuracy: 0.6585115131578947\n",
      "Epoch [161/500]\t Loss: 0.9557754115054482\t Accuracy: 0.658922697368421\n",
      "Epoch [162/500]\t Loss: 0.9550888350135401\t Accuracy: 0.6595394736842105\n",
      "Epoch [163/500]\t Loss: 0.9544062300732261\t Accuracy: 0.66015625\n",
      "Epoch [164/500]\t Loss: 0.9537276155070255\t Accuracy: 0.6605674342105263\n",
      "Epoch [165/500]\t Loss: 0.9530528219122636\t Accuracy: 0.6609786184210527\n",
      "Epoch [166/500]\t Loss: 0.9523818367405942\t Accuracy: 0.6609786184210527\n",
      "Epoch [167/500]\t Loss: 0.9517146443065844\t Accuracy: 0.6609786184210527\n",
      "Epoch [168/500]\t Loss: 0.951051181868503\t Accuracy: 0.6607730263157895\n",
      "Epoch [169/500]\t Loss: 0.950391389821705\t Accuracy: 0.661389802631579\n",
      "Epoch [170/500]\t Loss: 0.9497351991502863\t Accuracy: 0.661389802631579\n",
      "Epoch [171/500]\t Loss: 0.9490826255396793\t Accuracy: 0.6618009868421053\n",
      "Epoch [172/500]\t Loss: 0.948433540369335\t Accuracy: 0.6620065789473685\n",
      "Epoch [173/500]\t Loss: 0.9477880095180712\t Accuracy: 0.6624177631578947\n",
      "Epoch [174/500]\t Loss: 0.9471459012282523\t Accuracy: 0.6626233552631579\n",
      "Epoch [175/500]\t Loss: 0.9465072154998779\t Accuracy: 0.662828947368421\n",
      "Epoch [176/500]\t Loss: 0.9458718990024767\t Accuracy: 0.6630345394736842\n",
      "Epoch [177/500]\t Loss: 0.9452398325267591\t Accuracy: 0.6632401315789473\n",
      "Epoch [178/500]\t Loss: 0.9446111509674474\t Accuracy: 0.6634457236842105\n",
      "Epoch [179/500]\t Loss: 0.9439856723735207\t Accuracy: 0.6638569078947368\n",
      "Epoch [180/500]\t Loss: 0.9433633998820656\t Accuracy: 0.6642680921052632\n",
      "Epoch [181/500]\t Loss: 0.9427442613400911\t Accuracy: 0.6642680921052632\n",
      "Epoch [182/500]\t Loss: 0.9421283038038957\t Accuracy: 0.6646792763157895\n",
      "Epoch [183/500]\t Loss: 0.9415154331608823\t Accuracy: 0.6648848684210527\n",
      "Epoch [184/500]\t Loss: 0.9409056274514449\t Accuracy: 0.6657072368421053\n",
      "Epoch [185/500]\t Loss: 0.9402988019742464\t Accuracy: 0.6659128289473685\n",
      "Epoch [186/500]\t Loss: 0.939694997511412\t Accuracy: 0.6661184210526315\n",
      "Epoch [187/500]\t Loss: 0.9390941701437298\t Accuracy: 0.6663240131578947\n",
      "Epoch [188/500]\t Loss: 0.938496188113564\t Accuracy: 0.666735197368421\n",
      "Epoch [189/500]\t Loss: 0.9379011737672907\t Accuracy: 0.666735197368421\n",
      "Epoch [190/500]\t Loss: 0.9373089639764083\t Accuracy: 0.666735197368421\n",
      "Epoch [191/500]\t Loss: 0.9367196246197349\t Accuracy: 0.6671463815789473\n",
      "Epoch [192/500]\t Loss: 0.9361330239396346\t Accuracy: 0.6675575657894737\n",
      "Epoch [193/500]\t Loss: 0.9355492717341373\t Accuracy: 0.66796875\n",
      "Epoch [194/500]\t Loss: 0.9349681923263952\t Accuracy: 0.6677631578947368\n",
      "Epoch [195/500]\t Loss: 0.9343898170872739\t Accuracy: 0.6677631578947368\n",
      "Epoch [196/500]\t Loss: 0.9338141115088212\t Accuracy: 0.66796875\n",
      "Epoch [197/500]\t Loss: 0.9332410818652103\t Accuracy: 0.66796875\n",
      "Epoch [198/500]\t Loss: 0.9326706654147098\t Accuracy: 0.6681743421052632\n",
      "Epoch [199/500]\t Loss: 0.9321028245122809\t Accuracy: 0.6683799342105263\n",
      "Epoch [200/500]\t Loss: 0.9315375403354043\t Accuracy: 0.6683799342105263\n",
      "Epoch [201/500]\t Loss: 0.9309748379807723\t Accuracy: 0.6687911184210527\n",
      "Epoch [202/500]\t Loss: 0.9304146013761821\t Accuracy: 0.6689967105263158\n",
      "Epoch [203/500]\t Loss: 0.9298568681666726\t Accuracy: 0.669202302631579\n",
      "Epoch [204/500]\t Loss: 0.9293016226668107\t Accuracy: 0.6696134868421053\n",
      "Epoch [205/500]\t Loss: 0.9287487519414801\t Accuracy: 0.6702302631578947\n",
      "Epoch [206/500]\t Loss: 0.928198334417845\t Accuracy: 0.6702302631578947\n",
      "Epoch [207/500]\t Loss: 0.9276503136283473\t Accuracy: 0.6704358552631579\n",
      "Epoch [208/500]\t Loss: 0.9271046676133808\t Accuracy: 0.6708470394736842\n",
      "Epoch [209/500]\t Loss: 0.9265612834378293\t Accuracy: 0.6710526315789473\n",
      "Epoch [210/500]\t Loss: 0.9260202834480687\t Accuracy: 0.6712582236842105\n",
      "Epoch [211/500]\t Loss: 0.925481567257329\t Accuracy: 0.6716694078947368\n",
      "Epoch [212/500]\t Loss: 0.9249451034947446\t Accuracy: 0.6716694078947368\n",
      "Epoch [213/500]\t Loss: 0.9244109611762198\t Accuracy: 0.671875\n",
      "Epoch [214/500]\t Loss: 0.9238789771732531\t Accuracy: 0.671875\n",
      "Epoch [215/500]\t Loss: 0.9233491765825372\t Accuracy: 0.671875\n",
      "Epoch [216/500]\t Loss: 0.9228216346941496\t Accuracy: 0.6720805921052632\n",
      "Epoch [217/500]\t Loss: 0.9222962103391948\t Accuracy: 0.6722861842105263\n",
      "Epoch [218/500]\t Loss: 0.9217729850819236\t Accuracy: 0.6726973684210527\n",
      "Epoch [219/500]\t Loss: 0.921251820890527\t Accuracy: 0.6724917763157895\n",
      "Epoch [220/500]\t Loss: 0.9207328056034288\t Accuracy: 0.6729029605263158\n",
      "Epoch [221/500]\t Loss: 0.9202158890272442\t Accuracy: 0.6729029605263158\n",
      "Epoch [222/500]\t Loss: 0.919700983323549\t Accuracy: 0.673108552631579\n",
      "Epoch [223/500]\t Loss: 0.9191881731936806\t Accuracy: 0.6729029605263158\n",
      "Epoch [224/500]\t Loss: 0.9186773613879555\t Accuracy: 0.6729029605263158\n",
      "Epoch [225/500]\t Loss: 0.9181686231964513\t Accuracy: 0.6733141447368421\n",
      "Epoch [226/500]\t Loss: 0.9176618362727919\t Accuracy: 0.6739309210526315\n",
      "Epoch [227/500]\t Loss: 0.9171569755202845\t Accuracy: 0.6739309210526315\n",
      "Epoch [228/500]\t Loss: 0.9166541538740459\t Accuracy: 0.6741365131578947\n",
      "Epoch [229/500]\t Loss: 0.9161532207539207\t Accuracy: 0.6747532894736842\n",
      "Epoch [230/500]\t Loss: 0.9156542639983328\t Accuracy: 0.6749588815789473\n",
      "Epoch [231/500]\t Loss: 0.9151572365509836\t Accuracy: 0.6751644736842105\n",
      "Epoch [232/500]\t Loss: 0.9146619941058912\t Accuracy: 0.6755756578947368\n",
      "Epoch [233/500]\t Loss: 0.9141686652836046\t Accuracy: 0.67578125\n",
      "Epoch [234/500]\t Loss: 0.9136772375357779\t Accuracy: 0.67578125\n",
      "Epoch [235/500]\t Loss: 0.9131876481206793\t Accuracy: 0.67578125\n",
      "Epoch [236/500]\t Loss: 0.9126998562561838\t Accuracy: 0.67578125\n",
      "Epoch [237/500]\t Loss: 0.9122138964502435\t Accuracy: 0.6766036184210527\n",
      "Epoch [238/500]\t Loss: 0.9117297561545121\t Accuracy: 0.6768092105263158\n",
      "Epoch [239/500]\t Loss: 0.9112473130226135\t Accuracy: 0.6766036184210527\n",
      "Epoch [240/500]\t Loss: 0.910766717634703\t Accuracy: 0.6766036184210527\n",
      "Epoch [241/500]\t Loss: 0.910287835096058\t Accuracy: 0.677014802631579\n",
      "Epoch [242/500]\t Loss: 0.9098107312854967\t Accuracy: 0.677014802631579\n",
      "Epoch [243/500]\t Loss: 0.9093353152275085\t Accuracy: 0.6774259868421053\n",
      "Epoch [244/500]\t Loss: 0.9088616182929591\t Accuracy: 0.6780427631578947\n",
      "Epoch [245/500]\t Loss: 0.9083896279335022\t Accuracy: 0.6780427631578947\n",
      "Epoch [246/500]\t Loss: 0.9079193096411856\t Accuracy: 0.6780427631578947\n",
      "Epoch [247/500]\t Loss: 0.9074506791014421\t Accuracy: 0.6780427631578947\n",
      "Epoch [248/500]\t Loss: 0.9069836704354537\t Accuracy: 0.678453947368421\n",
      "Epoch [249/500]\t Loss: 0.9065183777558176\t Accuracy: 0.6792763157894737\n",
      "Epoch [250/500]\t Loss: 0.9060545940148202\t Accuracy: 0.6794819078947368\n",
      "Epoch [251/500]\t Loss: 0.905592541945608\t Accuracy: 0.6792763157894737\n",
      "Epoch [252/500]\t Loss: 0.9051320207746405\t Accuracy: 0.6794819078947368\n",
      "Epoch [253/500]\t Loss: 0.9046731340257745\t Accuracy: 0.6796875\n",
      "Epoch [254/500]\t Loss: 0.9042157844493264\t Accuracy: 0.6798930921052632\n",
      "Epoch [255/500]\t Loss: 0.9037600536095468\t Accuracy: 0.6800986842105263\n",
      "Epoch [256/500]\t Loss: 0.9033058285713196\t Accuracy: 0.6803042763157895\n",
      "Epoch [257/500]\t Loss: 0.9028531877618087\t Accuracy: 0.6800986842105263\n",
      "Epoch [258/500]\t Loss: 0.9024020653021964\t Accuracy: 0.6798930921052632\n",
      "Epoch [259/500]\t Loss: 0.9019524894262615\t Accuracy: 0.6807154605263158\n",
      "Epoch [260/500]\t Loss: 0.9015043503359744\t Accuracy: 0.6811266447368421\n",
      "Epoch [261/500]\t Loss: 0.9010577735147978\t Accuracy: 0.6813322368421053\n",
      "Epoch [262/500]\t Loss: 0.9006126272050958\t Accuracy: 0.6815378289473685\n",
      "Epoch [263/500]\t Loss: 0.9001689804227728\t Accuracy: 0.6815378289473685\n",
      "Epoch [264/500]\t Loss: 0.8997268206194827\t Accuracy: 0.6817434210526315\n",
      "Epoch [265/500]\t Loss: 0.8992861258356195\t Accuracy: 0.6817434210526315\n",
      "Epoch [266/500]\t Loss: 0.8988468270552786\t Accuracy: 0.6817434210526315\n",
      "Epoch [267/500]\t Loss: 0.8984089964314511\t Accuracy: 0.6817434210526315\n",
      "Epoch [268/500]\t Loss: 0.8979725931820116\t Accuracy: 0.6819490131578947\n",
      "Epoch [269/500]\t Loss: 0.8975375796619215\t Accuracy: 0.6821546052631579\n",
      "Epoch [270/500]\t Loss: 0.8971039464599208\t Accuracy: 0.682360197368421\n",
      "Epoch [271/500]\t Loss: 0.896671712398529\t Accuracy: 0.682360197368421\n",
      "Epoch [272/500]\t Loss: 0.8962408931631791\t Accuracy: 0.6825657894736842\n",
      "Epoch [273/500]\t Loss: 0.8958114416975724\t Accuracy: 0.6825657894736842\n",
      "Epoch [274/500]\t Loss: 0.8953833297679299\t Accuracy: 0.6825657894736842\n",
      "Epoch [275/500]\t Loss: 0.8949565761967709\t Accuracy: 0.6829769736842105\n",
      "Epoch [276/500]\t Loss: 0.8945311590244895\t Accuracy: 0.6829769736842105\n",
      "Epoch [277/500]\t Loss: 0.8941070970736051\t Accuracy: 0.6837993421052632\n",
      "Epoch [278/500]\t Loss: 0.8936843621103387\t Accuracy: 0.6837993421052632\n",
      "Epoch [279/500]\t Loss: 0.8932629290379976\t Accuracy: 0.6840049342105263\n",
      "Epoch [280/500]\t Loss: 0.8928428135420147\t Accuracy: 0.6846217105263158\n",
      "Epoch [281/500]\t Loss: 0.8924239873886108\t Accuracy: 0.684827302631579\n",
      "Epoch [282/500]\t Loss: 0.8920064129327473\t Accuracy: 0.684827302631579\n",
      "Epoch [283/500]\t Loss: 0.8915901591903285\t Accuracy: 0.6846217105263158\n",
      "Epoch [284/500]\t Loss: 0.8911751979275754\t Accuracy: 0.6846217105263158\n",
      "Epoch [285/500]\t Loss: 0.890761441306064\t Accuracy: 0.6844161184210527\n",
      "Epoch [286/500]\t Loss: 0.8903489897125646\t Accuracy: 0.6844161184210527\n",
      "Epoch [287/500]\t Loss: 0.8899377270748741\t Accuracy: 0.6850328947368421\n",
      "Epoch [288/500]\t Loss: 0.8895277349572432\t Accuracy: 0.6852384868421053\n",
      "Epoch [289/500]\t Loss: 0.8891189725775468\t Accuracy: 0.6854440789473685\n",
      "Epoch [290/500]\t Loss: 0.8887114399357846\t Accuracy: 0.6854440789473685\n",
      "Epoch [291/500]\t Loss: 0.8883050993869179\t Accuracy: 0.6852384868421053\n",
      "Epoch [292/500]\t Loss: 0.8879000105355915\t Accuracy: 0.6858552631578947\n",
      "Epoch [293/500]\t Loss: 0.8874960855433816\t Accuracy: 0.6860608552631579\n",
      "Epoch [294/500]\t Loss: 0.8870933463698939\t Accuracy: 0.686266447368421\n",
      "Epoch [295/500]\t Loss: 0.8866917898780421\t Accuracy: 0.6866776315789473\n",
      "Epoch [296/500]\t Loss: 0.886291431753259\t Accuracy: 0.6868832236842105\n",
      "Epoch [297/500]\t Loss: 0.8858921778829474\t Accuracy: 0.6872944078947368\n",
      "Epoch [298/500]\t Loss: 0.8854941286538777\t Accuracy: 0.6872944078947368\n",
      "Epoch [299/500]\t Loss: 0.885097252695184\t Accuracy: 0.6872944078947368\n",
      "Epoch [300/500]\t Loss: 0.8847014621684426\t Accuracy: 0.6877055921052632\n",
      "Epoch [301/500]\t Loss: 0.884306854323337\t Accuracy: 0.6879111842105263\n",
      "Epoch [302/500]\t Loss: 0.8839133883777418\t Accuracy: 0.6879111842105263\n",
      "Epoch [303/500]\t Loss: 0.8835210015899256\t Accuracy: 0.6883223684210527\n",
      "Epoch [304/500]\t Loss: 0.8831297410161871\t Accuracy: 0.6881167763157895\n",
      "Epoch [305/500]\t Loss: 0.8827395909710934\t Accuracy: 0.6881167763157895\n",
      "Epoch [306/500]\t Loss: 0.8823505577288175\t Accuracy: 0.6883223684210527\n",
      "Epoch [307/500]\t Loss: 0.8819625785476283\t Accuracy: 0.6883223684210527\n",
      "Epoch [308/500]\t Loss: 0.8815757569513822\t Accuracy: 0.6883223684210527\n",
      "Epoch [309/500]\t Loss: 0.8811899611824437\t Accuracy: 0.6883223684210527\n",
      "Epoch [310/500]\t Loss: 0.8808052633938036\t Accuracy: 0.6879111842105263\n",
      "Epoch [311/500]\t Loss: 0.8804216228033367\t Accuracy: 0.6879111842105263\n",
      "Epoch [312/500]\t Loss: 0.8800390331368697\t Accuracy: 0.6877055921052632\n",
      "Epoch [313/500]\t Loss: 0.8796575100798356\t Accuracy: 0.6875\n",
      "Epoch [314/500]\t Loss: 0.8792770442209745\t Accuracy: 0.6879111842105263\n",
      "Epoch [315/500]\t Loss: 0.8788976230119404\t Accuracy: 0.6881167763157895\n",
      "Epoch [316/500]\t Loss: 0.8785192684123391\t Accuracy: 0.6885279605263158\n",
      "Epoch [317/500]\t Loss: 0.8781418863095736\t Accuracy: 0.688733552631579\n",
      "Epoch [318/500]\t Loss: 0.8777655425824618\t Accuracy: 0.688733552631579\n",
      "Epoch [319/500]\t Loss: 0.8773902309568304\t Accuracy: 0.6889391447368421\n",
      "Epoch [320/500]\t Loss: 0.8770159482955933\t Accuracy: 0.6893503289473685\n",
      "Epoch [321/500]\t Loss: 0.8766426349941053\t Accuracy: 0.6895559210526315\n",
      "Epoch [322/500]\t Loss: 0.8762703537940979\t Accuracy: 0.6899671052631579\n",
      "Epoch [323/500]\t Loss: 0.8758990137200606\t Accuracy: 0.6897615131578947\n",
      "Epoch [324/500]\t Loss: 0.8755287402554562\t Accuracy: 0.6899671052631579\n",
      "Epoch [325/500]\t Loss: 0.8751594079168219\t Accuracy: 0.690172697368421\n",
      "Epoch [326/500]\t Loss: 0.87479105121211\t Accuracy: 0.6905838815789473\n",
      "Epoch [327/500]\t Loss: 0.8744236670042339\t Accuracy: 0.6903782894736842\n",
      "Epoch [328/500]\t Loss: 0.8740572552931937\t Accuracy: 0.6907894736842105\n",
      "Epoch [329/500]\t Loss: 0.8736917847081235\t Accuracy: 0.6920230263157895\n",
      "Epoch [330/500]\t Loss: 0.8733272834828025\t Accuracy: 0.6920230263157895\n",
      "Epoch [331/500]\t Loss: 0.8729637265205383\t Accuracy: 0.6922286184210527\n",
      "Epoch [332/500]\t Loss: 0.8726011263696771\t Accuracy: 0.6922286184210527\n",
      "Epoch [333/500]\t Loss: 0.8722394516593531\t Accuracy: 0.6922286184210527\n",
      "Epoch [334/500]\t Loss: 0.8718787619942113\t Accuracy: 0.6924342105263158\n",
      "Epoch [335/500]\t Loss: 0.8715189193424425\t Accuracy: 0.6922286184210527\n",
      "Epoch [336/500]\t Loss: 0.8711600554616827\t Accuracy: 0.6924342105263158\n",
      "Epoch [337/500]\t Loss: 0.8708020856505946\t Accuracy: 0.692639802631579\n",
      "Epoch [338/500]\t Loss: 0.8704450506913034\t Accuracy: 0.692639802631579\n",
      "Epoch [339/500]\t Loss: 0.8700889223500302\t Accuracy: 0.692639802631579\n",
      "Epoch [340/500]\t Loss: 0.8697336692559091\t Accuracy: 0.692639802631579\n",
      "Epoch [341/500]\t Loss: 0.869379322779806\t Accuracy: 0.692639802631579\n",
      "Epoch [342/500]\t Loss: 0.8690258923329806\t Accuracy: 0.692639802631579\n",
      "Epoch [343/500]\t Loss: 0.8686733120366147\t Accuracy: 0.6930509868421053\n",
      "Epoch [344/500]\t Loss: 0.8683216540436995\t Accuracy: 0.6928453947368421\n",
      "Epoch [345/500]\t Loss: 0.8679708336528978\t Accuracy: 0.6930509868421053\n",
      "Epoch [346/500]\t Loss: 0.8676209104688544\t Accuracy: 0.6936677631578947\n",
      "Epoch [347/500]\t Loss: 0.8672718217498377\t Accuracy: 0.694078947368421\n",
      "Epoch [348/500]\t Loss: 0.8669236553342718\t Accuracy: 0.694078947368421\n",
      "Epoch [349/500]\t Loss: 0.866576329657906\t Accuracy: 0.6942845394736842\n",
      "Epoch [350/500]\t Loss: 0.8662298792286923\t Accuracy: 0.6942845394736842\n",
      "Epoch [351/500]\t Loss: 0.8658842193452936\t Accuracy: 0.6942845394736842\n",
      "Epoch [352/500]\t Loss: 0.8655394598057395\t Accuracy: 0.694078947368421\n",
      "Epoch [353/500]\t Loss: 0.8651955096345199\t Accuracy: 0.6938733552631579\n",
      "Epoch [354/500]\t Loss: 0.8648524033395868\t Accuracy: 0.694078947368421\n",
      "Epoch [355/500]\t Loss: 0.8645101252355074\t Accuracy: 0.694078947368421\n",
      "Epoch [356/500]\t Loss: 0.864168709830234\t Accuracy: 0.694078947368421\n",
      "Epoch [357/500]\t Loss: 0.8638280724224291\t Accuracy: 0.6944901315789473\n",
      "Epoch [358/500]\t Loss: 0.863488278890911\t Accuracy: 0.6946957236842105\n",
      "Epoch [359/500]\t Loss: 0.8631493072760733\t Accuracy: 0.6951069078947368\n",
      "Epoch [360/500]\t Loss: 0.8628111481666565\t Accuracy: 0.6957236842105263\n",
      "Epoch [361/500]\t Loss: 0.8624738015626606\t Accuracy: 0.6957236842105263\n",
      "Epoch [362/500]\t Loss: 0.8621372078594408\t Accuracy: 0.6959292763157895\n",
      "Epoch [363/500]\t Loss: 0.861801498814633\t Accuracy: 0.6959292763157895\n",
      "Epoch [364/500]\t Loss: 0.8614664705176103\t Accuracy: 0.6963404605263158\n",
      "Epoch [365/500]\t Loss: 0.8611323017823068\t Accuracy: 0.6963404605263158\n",
      "Epoch [366/500]\t Loss: 0.8607989581007707\t Accuracy: 0.6963404605263158\n",
      "Epoch [367/500]\t Loss: 0.8604663296749717\t Accuracy: 0.6963404605263158\n",
      "Epoch [368/500]\t Loss: 0.86013452630294\t Accuracy: 0.6967516447368421\n",
      "Epoch [369/500]\t Loss: 0.8598034695575112\t Accuracy: 0.6967516447368421\n",
      "Epoch [370/500]\t Loss: 0.8594731719870317\t Accuracy: 0.6967516447368421\n",
      "Epoch [371/500]\t Loss: 0.8591436680994535\t Accuracy: 0.6969572368421053\n",
      "Epoch [372/500]\t Loss: 0.8588149077013919\t Accuracy: 0.6967516447368421\n",
      "Epoch [373/500]\t Loss: 0.8584869378491452\t Accuracy: 0.6969572368421053\n",
      "Epoch [374/500]\t Loss: 0.8581596832526358\t Accuracy: 0.6971628289473685\n",
      "Epoch [375/500]\t Loss: 0.857833228613201\t Accuracy: 0.6975740131578947\n",
      "Epoch [376/500]\t Loss: 0.8575074609957243\t Accuracy: 0.6977796052631579\n",
      "Epoch [377/500]\t Loss: 0.8571824839240626\t Accuracy: 0.6975740131578947\n",
      "Epoch [378/500]\t Loss: 0.8568582221081382\t Accuracy: 0.6973684210526315\n",
      "Epoch [379/500]\t Loss: 0.8565347069188168\t Accuracy: 0.6977796052631579\n",
      "Epoch [380/500]\t Loss: 0.856211919533579\t Accuracy: 0.697985197368421\n",
      "Epoch [381/500]\t Loss: 0.8558898913232904\t Accuracy: 0.697985197368421\n",
      "Epoch [382/500]\t Loss: 0.8555685626833063\t Accuracy: 0.697985197368421\n",
      "Epoch [383/500]\t Loss: 0.8552479712586654\t Accuracy: 0.697985197368421\n",
      "Epoch [384/500]\t Loss: 0.8549280856785021\t Accuracy: 0.697985197368421\n",
      "Epoch [385/500]\t Loss: 0.8546089059428165\t Accuracy: 0.697985197368421\n",
      "Epoch [386/500]\t Loss: 0.8542904665595606\t Accuracy: 0.6983963815789473\n",
      "Epoch [387/500]\t Loss: 0.8539727267466093\t Accuracy: 0.6986019736842105\n",
      "Epoch [388/500]\t Loss: 0.8536556833668759\t Accuracy: 0.6986019736842105\n",
      "Epoch [389/500]\t Loss: 0.853339323872014\t Accuracy: 0.6988075657894737\n",
      "Epoch [390/500]\t Loss: 0.8530237455117075\t Accuracy: 0.6994243421052632\n",
      "Epoch [391/500]\t Loss: 0.8527087663349352\t Accuracy: 0.6996299342105263\n",
      "Epoch [392/500]\t Loss: 0.8523945369218525\t Accuracy: 0.6996299342105263\n",
      "Epoch [393/500]\t Loss: 0.8520809662969488\t Accuracy: 0.7002467105263158\n",
      "Epoch [394/500]\t Loss: 0.8517680921052632\t Accuracy: 0.6998355263157895\n",
      "Epoch [395/500]\t Loss: 0.8514558986613625\t Accuracy: 0.7000411184210527\n",
      "Epoch [396/500]\t Loss: 0.8511443514572946\t Accuracy: 0.7002467105263158\n",
      "Epoch [397/500]\t Loss: 0.8508335038235313\t Accuracy: 0.7002467105263158\n",
      "Epoch [398/500]\t Loss: 0.8505233777196783\t Accuracy: 0.7002467105263158\n",
      "Epoch [399/500]\t Loss: 0.8502138413881001\t Accuracy: 0.7002467105263158\n",
      "Epoch [400/500]\t Loss: 0.8499050830539904\t Accuracy: 0.700452302631579\n",
      "Epoch [401/500]\t Loss: 0.8495969050808957\t Accuracy: 0.700452302631579\n",
      "Epoch [402/500]\t Loss: 0.8492893670734606\t Accuracy: 0.700452302631579\n",
      "Epoch [403/500]\t Loss: 0.8489825474588495\t Accuracy: 0.7006578947368421\n",
      "Epoch [404/500]\t Loss: 0.8486763709469846\t Accuracy: 0.7006578947368421\n",
      "Epoch [405/500]\t Loss: 0.8483708249895197\t Accuracy: 0.7006578947368421\n",
      "Epoch [406/500]\t Loss: 0.8480659158606279\t Accuracy: 0.700452302631579\n",
      "Epoch [407/500]\t Loss: 0.8477617031649539\t Accuracy: 0.700452302631579\n",
      "Epoch [408/500]\t Loss: 0.8474580959269875\t Accuracy: 0.700452302631579\n",
      "Epoch [409/500]\t Loss: 0.8471551443401136\t Accuracy: 0.7006578947368421\n",
      "Epoch [410/500]\t Loss: 0.8468527887996874\t Accuracy: 0.700452302631579\n",
      "Epoch [411/500]\t Loss: 0.8465511108699598\t Accuracy: 0.7006578947368421\n",
      "Epoch [412/500]\t Loss: 0.8462500446721127\t Accuracy: 0.7008634868421053\n",
      "Epoch [413/500]\t Loss: 0.8459496435366178\t Accuracy: 0.7008634868421053\n",
      "Epoch [414/500]\t Loss: 0.845649822762138\t Accuracy: 0.7012746710526315\n",
      "Epoch [415/500]\t Loss: 0.8453506294049715\t Accuracy: 0.7012746710526315\n",
      "Epoch [416/500]\t Loss: 0.8450520760134647\t Accuracy: 0.7010690789473685\n",
      "Epoch [417/500]\t Loss: 0.8447541186684057\t Accuracy: 0.7012746710526315\n",
      "Epoch [418/500]\t Loss: 0.8444568075631794\t Accuracy: 0.7014802631578947\n",
      "Epoch [419/500]\t Loss: 0.844160070544795\t Accuracy: 0.7014802631578947\n",
      "Epoch [420/500]\t Loss: 0.8438639672178971\t Accuracy: 0.7014802631578947\n",
      "Epoch [421/500]\t Loss: 0.8435684787599664\t Accuracy: 0.7014802631578947\n",
      "Epoch [422/500]\t Loss: 0.8432735957597431\t Accuracy: 0.7014802631578947\n",
      "Epoch [423/500]\t Loss: 0.8429792680238423\t Accuracy: 0.7014802631578947\n",
      "Epoch [424/500]\t Loss: 0.8426856053502936\t Accuracy: 0.7014802631578947\n",
      "Epoch [425/500]\t Loss: 0.8423925010781539\t Accuracy: 0.7014802631578947\n",
      "Epoch [426/500]\t Loss: 0.8420999803041157\t Accuracy: 0.701891447368421\n",
      "Epoch [427/500]\t Loss: 0.8418080273427462\t Accuracy: 0.701891447368421\n",
      "Epoch [428/500]\t Loss: 0.8415167268953825\t Accuracy: 0.701891447368421\n",
      "Epoch [429/500]\t Loss: 0.8412259534785622\t Accuracy: 0.701891447368421\n",
      "Epoch [430/500]\t Loss: 0.840935816890315\t Accuracy: 0.701891447368421\n",
      "Epoch [431/500]\t Loss: 0.8406462418405634\t Accuracy: 0.701891447368421\n",
      "Epoch [432/500]\t Loss: 0.840357265974346\t Accuracy: 0.7020970394736842\n",
      "Epoch [433/500]\t Loss: 0.840068845372451\t Accuracy: 0.7023026315789473\n",
      "Epoch [434/500]\t Loss: 0.8397809549381858\t Accuracy: 0.7025082236842105\n",
      "Epoch [435/500]\t Loss: 0.8394936699616281\t Accuracy: 0.7029194078947368\n",
      "Epoch [436/500]\t Loss: 0.8392069433864794\t Accuracy: 0.7029194078947368\n",
      "Epoch [437/500]\t Loss: 0.8389208442286441\t Accuracy: 0.7027138157894737\n",
      "Epoch [438/500]\t Loss: 0.8386352470046595\t Accuracy: 0.7029194078947368\n",
      "Epoch [439/500]\t Loss: 0.8383502238675168\t Accuracy: 0.7029194078947368\n",
      "Epoch [440/500]\t Loss: 0.8380658155993411\t Accuracy: 0.7029194078947368\n",
      "Epoch [441/500]\t Loss: 0.8377818935795834\t Accuracy: 0.703125\n",
      "Epoch [442/500]\t Loss: 0.8374984891791093\t Accuracy: 0.7033305921052632\n",
      "Epoch [443/500]\t Loss: 0.837215709058862\t Accuracy: 0.7033305921052632\n",
      "Epoch [444/500]\t Loss: 0.8369334591062445\t Accuracy: 0.7035361842105263\n",
      "Epoch [445/500]\t Loss: 0.8366517581437763\t Accuracy: 0.7035361842105263\n",
      "Epoch [446/500]\t Loss: 0.8363705904860246\t Accuracy: 0.7035361842105263\n",
      "Epoch [447/500]\t Loss: 0.8360900126005474\t Accuracy: 0.7035361842105263\n",
      "Epoch [448/500]\t Loss: 0.835809936648921\t Accuracy: 0.7037417763157895\n",
      "Epoch [449/500]\t Loss: 0.8355303783165781\t Accuracy: 0.7037417763157895\n",
      "Epoch [450/500]\t Loss: 0.8352513627002114\t Accuracy: 0.7037417763157895\n",
      "Epoch [451/500]\t Loss: 0.834972924307773\t Accuracy: 0.7033305921052632\n",
      "Epoch [452/500]\t Loss: 0.8346949721637525\t Accuracy: 0.7033305921052632\n",
      "Epoch [453/500]\t Loss: 0.8344175752840544\t Accuracy: 0.7037417763157895\n",
      "Epoch [454/500]\t Loss: 0.8341407211203324\t Accuracy: 0.7039473684210527\n",
      "Epoch [455/500]\t Loss: 0.8338643814388075\t Accuracy: 0.7041529605263158\n",
      "Epoch [456/500]\t Loss: 0.8335885531023929\t Accuracy: 0.7041529605263158\n",
      "Epoch [457/500]\t Loss: 0.8333132549336082\t Accuracy: 0.7041529605263158\n",
      "Epoch [458/500]\t Loss: 0.8330384869324533\t Accuracy: 0.7041529605263158\n",
      "Epoch [459/500]\t Loss: 0.8327641832201105\t Accuracy: 0.704358552631579\n",
      "Epoch [460/500]\t Loss: 0.8324904535946093\t Accuracy: 0.7047697368421053\n",
      "Epoch [461/500]\t Loss: 0.8322171631612276\t Accuracy: 0.7047697368421053\n",
      "Epoch [462/500]\t Loss: 0.831944443677601\t Accuracy: 0.7047697368421053\n",
      "Epoch [463/500]\t Loss: 0.831672235539085\t Accuracy: 0.7047697368421053\n",
      "Epoch [464/500]\t Loss: 0.8314005293344197\t Accuracy: 0.7049753289473685\n",
      "Epoch [465/500]\t Loss: 0.8311293093781722\t Accuracy: 0.7049753289473685\n",
      "Epoch [466/500]\t Loss: 0.8308585819445158\t Accuracy: 0.7049753289473685\n",
      "Epoch [467/500]\t Loss: 0.8305884254606146\t Accuracy: 0.7047697368421053\n",
      "Epoch [468/500]\t Loss: 0.830318714443006\t Accuracy: 0.7047697368421053\n",
      "Epoch [469/500]\t Loss: 0.8300494928109018\t Accuracy: 0.7051809210526315\n",
      "Epoch [470/500]\t Loss: 0.8297807637013888\t Accuracy: 0.7053865131578947\n",
      "Epoch [471/500]\t Loss: 0.8295125396628129\t Accuracy: 0.7053865131578947\n",
      "Epoch [472/500]\t Loss: 0.82924485206604\t Accuracy: 0.7053865131578947\n",
      "Epoch [473/500]\t Loss: 0.8289775817017806\t Accuracy: 0.7053865131578947\n",
      "Epoch [474/500]\t Loss: 0.8287108352309779\t Accuracy: 0.7055921052631579\n",
      "Epoch [475/500]\t Loss: 0.828444546774814\t Accuracy: 0.7060032894736842\n",
      "Epoch [476/500]\t Loss: 0.8281787571154142\t Accuracy: 0.7060032894736842\n",
      "Epoch [477/500]\t Loss: 0.8279134756640384\t Accuracy: 0.7060032894736842\n",
      "Epoch [478/500]\t Loss: 0.8276486804610804\t Accuracy: 0.7060032894736842\n",
      "Epoch [479/500]\t Loss: 0.8273843275873285\t Accuracy: 0.7060032894736842\n",
      "Epoch [480/500]\t Loss: 0.8271204672361675\t Accuracy: 0.7060032894736842\n",
      "Epoch [481/500]\t Loss: 0.8268570554883856\t Accuracy: 0.7060032894736842\n",
      "Epoch [482/500]\t Loss: 0.826594164496974\t Accuracy: 0.7062088815789473\n",
      "Epoch [483/500]\t Loss: 0.8263316876009891\t Accuracy: 0.7062088815789473\n",
      "Epoch [484/500]\t Loss: 0.8260696875421625\t Accuracy: 0.7062088815789473\n",
      "Epoch [485/500]\t Loss: 0.825808164320494\t Accuracy: 0.7062088815789473\n",
      "Epoch [486/500]\t Loss: 0.8255471618551957\t Accuracy: 0.7068256578947368\n",
      "Epoch [487/500]\t Loss: 0.8252865577998915\t Accuracy: 0.7068256578947368\n",
      "Epoch [488/500]\t Loss: 0.82502638979962\t Accuracy: 0.7068256578947368\n",
      "Epoch [489/500]\t Loss: 0.824766783337844\t Accuracy: 0.7068256578947368\n",
      "Epoch [490/500]\t Loss: 0.8245075250926771\t Accuracy: 0.7068256578947368\n",
      "Epoch [491/500]\t Loss: 0.8242488221118325\t Accuracy: 0.7076480263157895\n",
      "Epoch [492/500]\t Loss: 0.8239905206780684\t Accuracy: 0.7076480263157895\n",
      "Epoch [493/500]\t Loss: 0.8237326458880776\t Accuracy: 0.7078536184210527\n",
      "Epoch [494/500]\t Loss: 0.8234752855802837\t Accuracy: 0.7080592105263158\n",
      "Epoch [495/500]\t Loss: 0.8232183268195704\t Accuracy: 0.7080592105263158\n",
      "Epoch [496/500]\t Loss: 0.8229618637185347\t Accuracy: 0.7080592105263158\n",
      "Epoch [497/500]\t Loss: 0.8227058147129259\t Accuracy: 0.708264802631579\n",
      "Epoch [498/500]\t Loss: 0.8224502174477828\t Accuracy: 0.708264802631579\n",
      "Epoch [499/500]\t Loss: 0.8221950593747591\t Accuracy: 0.708264802631579\n",
      "[FINAL]\t Loss: 0.9526710529481212\t Accuracy: 0.6495715725806451\n"
     ]
    }
   ],
   "source": [
    "main(0,args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cec801-15fb-445a-9fa3-4f3338280898",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
