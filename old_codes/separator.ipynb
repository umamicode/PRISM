{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28bf9e86-0994-4379-aa8e-0a1c25c89ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import argparse\n",
    "\n",
    "# distributed training\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DataParallel\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "# TensorBoard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# SimCLR\n",
    "from simclr import SimCLR\n",
    "from simclr.modules import NT_Xent, get_resnet\n",
    "from simclr.modules.transformations import TransformsSimCLR\n",
    "from simclr.modules.sync_batchnorm import convert_model\n",
    "\n",
    "#ReLIC\n",
    "#[TODO]\n",
    "from relic import ReLIC\n",
    "from relic.modules import ReLIC_Loss, get_resnet\n",
    "from relic.modules.transformations import TransformsRelic\n",
    "from relic.modules.sync_batchnorm import convert_model\n",
    "from relic.modules.separator import Separator\n",
    "\n",
    "from model import load_optimizer, save_model\n",
    "from utils import yaml_config_hook\n",
    "\n",
    "#linear_evaluation.py\n",
    "import linear_evaluation \n",
    "\n",
    "\n",
    "#PACS Dataset\n",
    "NUM_CLASSES = 7      # 7 classes for each domain: 'dog', 'elephant', 'giraffe', 'guitar', 'horse', 'house', 'person'\n",
    "DATASETS_NAMES = ['photo', 'art', 'cartoon', 'sketch']\n",
    "CLASSES_NAMES = ['Dog', 'Elephant', 'Giraffe', 'Guitar', 'Horse', 'House', 'Person']\n",
    "DIR_PHOTO = './datasets/PACS/photo'\n",
    "DIR_ART = './datasets/PACS/art_painting'\n",
    "DIR_CARTOON = './datasets/PACS/cartoon'\n",
    "DIR_SKETCH = './datasets/PACS/sketch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7c787ab-8e34-45de-907e-9dc70c352898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, train_loader, model, criterion, optimizer, writer, relic=False):\n",
    "    loss_epoch = 0\n",
    "\n",
    "    #Vanilla SimCLR\n",
    "    if relic==False:  #RELIC\n",
    "        for step, ((x_i, x_j), _) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            x_i = x_i.cuda(non_blocking=True)\n",
    "            x_j = x_j.cuda(non_blocking=True)\n",
    "\n",
    "            # positive pair, with encoding\n",
    "            h_i, h_j, z_i, z_j = model(x_i, x_j)\n",
    "\n",
    "            loss = criterion(z_i, z_j)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            if dist.is_available() and dist.is_initialized():\n",
    "                loss = loss.data.clone()\n",
    "                dist.all_reduce(loss.div_(dist.get_world_size()))\n",
    "\n",
    "            if args.nr == 0 and step % 50 == 0:\n",
    "                print(f\"Step [{step}/{len(train_loader)}]\\t Loss: {loss.item()}\")\n",
    "\n",
    "            if args.nr == 0:\n",
    "                writer.add_scalar(\"Loss/train_epoch\", loss.item(), args.global_step)\n",
    "                args.global_step += 1\n",
    "\n",
    "            loss_epoch += loss.item()\n",
    "        return loss_epoch\n",
    "    \n",
    "    #ReLIC\n",
    "    if relic==True:  #RELIC\n",
    "            for step, ((x_i, x_j,x_orig), _) in enumerate(train_loader):\n",
    "                optimizer.zero_grad()\n",
    "                x_i = x_i.cuda(non_blocking=True)\n",
    "                x_j = x_j.cuda(non_blocking=True)\n",
    "                \n",
    "                x_orig= x_orig.cuda(non_blocking=True)\n",
    "\n",
    "                # positive pair, with encoding\n",
    "\n",
    "                #dkcho\n",
    "                #_,_, online_1,online_2,target_1,target_2, original_features = model(x_i, x_j, x_orig)\n",
    "                #new version\n",
    "                online_1,target_1, online_2, target_2, original_features = model(x_i, x_j, x_orig)\n",
    "\n",
    "\n",
    "                loss_1, loss_2 = criterion(online_1, target_2, original_features), criterion(online_2, target_1, original_features)\n",
    "\n",
    "\n",
    "\n",
    "                loss = loss_1 + loss_2\n",
    "                #loss = criterion(z_i, z_j)\n",
    "                loss.backward()\n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "                if dist.is_available() and dist.is_initialized():\n",
    "                    loss = loss.data.clone()\n",
    "                    dist.all_reduce(loss.div_(dist.get_world_size()))\n",
    "\n",
    "                if args.nr == 0 and step % 50 == 0:\n",
    "                    print(f\"Step [{step}/{len(train_loader)}]\\t Loss: {loss.item()}\")\n",
    "\n",
    "                if args.nr == 0:\n",
    "                    writer.add_scalar(\"Loss/train_epoch\", loss.item(), args.global_step)\n",
    "                    args.global_step += 1\n",
    "\n",
    "                loss_epoch += loss.item()\n",
    "            return loss_epoch\n",
    "\n",
    "def main(gpu, args):\n",
    "    ###TEST [TODO- ADDED]\n",
    "\n",
    "    print(\"ReLIC -- {relic}\".format(relic=args.relic))\n",
    "    print(\"Saving Model In -- {m}, Train Epochs: {e}\".format(m= args.model_path, e= args.epochs))\n",
    "    print(\"All Training Args --\", args)\n",
    "    \n",
    "\n",
    "\n",
    "    rank = args.nr * args.gpus + gpu\n",
    "\n",
    "    if args.nodes > 1:\n",
    "        dist.init_process_group(\"nccl\", rank=rank, world_size=args.world_size)\n",
    "        torch.cuda.set_device(gpu)\n",
    "\n",
    "    torch.manual_seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "\n",
    "\n",
    "    #SimCLR\n",
    "    if args.relic== False:\n",
    "        if args.dataset == \"STL10\":\n",
    "            train_dataset = torchvision.datasets.STL10(\n",
    "                args.dataset_dir,\n",
    "                split=\"unlabeled\",\n",
    "                download=True,\n",
    "                transform=TransformsSimCLR(size=args.image_size),\n",
    "            )\n",
    "        elif args.dataset == \"CIFAR10\":\n",
    "            train_dataset = torchvision.datasets.CIFAR10(\n",
    "                args.dataset_dir,\n",
    "                download=True,\n",
    "                transform=TransformsSimCLR(size=args.image_size),\n",
    "            )\n",
    "        elif args.dataset == \"PACS\":\n",
    "                pacs_convertor= {'none':DIR_PHOTO, 'photo':DIR_PHOTO, 'art':DIR_ART, 'cartoon':DIR_CARTOON, 'sketch':DIR_SKETCH}\n",
    "                train_dataset= torchvision.datasets.ImageFolder(pacs_convertor[args.pacs_style], transform=TransformsSimCLR(size=args.image_size))\n",
    "                \n",
    "                '''\n",
    "                photo_dataset = torchvision.datasets.ImageFolder(DIR_PHOTO, transform=TransformsRelic(size=args.image_size))\n",
    "                art_dataset = torchvision.datasets.ImageFolder(DIR_ART, transform=TransformsRelic(size=args.image_size))\n",
    "                cartoon_dataset = torchvision.datasets.ImageFolder(DIR_CARTOON, transform=TransformsRelic(size=args.image_size))\n",
    "                sketch_dataset = torchvision.datasets.ImageFolder(DIR_SKETCH, transform=TransformsRelic(size=args.image_size))\n",
    "                '''\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "    \n",
    "\n",
    "    #ReLIC\n",
    "    elif args.relic== True:\n",
    "            if args.dataset == \"STL10\":\n",
    "                train_dataset = torchvision.datasets.STL10(\n",
    "                    args.dataset_dir,\n",
    "                    split=\"unlabeled\",\n",
    "                    download=True,\n",
    "                    transform=TransformsRelic(size=args.image_size),\n",
    "                )\n",
    "            elif args.dataset == \"CIFAR10\":\n",
    "                train_dataset = torchvision.datasets.CIFAR10(\n",
    "                    args.dataset_dir,\n",
    "                    download=True,\n",
    "                    transform=TransformsRelic(size=args.image_size),\n",
    "                )\n",
    "            elif args.dataset == \"PACS\":\n",
    "                pacs_convertor= {'default':DIR_PHOTO, 'photo':DIR_PHOTO, 'art':DIR_ART, 'cartoon':DIR_CARTOON, 'sketch':DIR_SKETCH}\n",
    "                train_dataset= torchvision.datasets.ImageFolder(pacs_convertor[args.pacs_style], transform=TransformsRelic(size=args.image_size))\n",
    "\n",
    "                '''\n",
    "                photo_dataset = torchvision.datasets.ImageFolder(DIR_PHOTO, transform=TransformsRelic(size=args.image_size))\n",
    "                art_dataset = torchvision.datasets.ImageFolder(DIR_ART, transform=TransformsRelic(size=args.image_size))\n",
    "                cartoon_dataset = torchvision.datasets.ImageFolder(DIR_CARTOON, transform=TransformsRelic(size=args.image_size))\n",
    "                sketch_dataset = torchvision.datasets.ImageFolder(DIR_SKETCH, transform=TransformsRelic(size=args.image_size))\n",
    "                '''\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "\n",
    "    if args.nodes > 1:\n",
    "        train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "            train_dataset, num_replicas=args.world_size, rank=rank, shuffle=True\n",
    "        )\n",
    "    else:\n",
    "        train_sampler = None\n",
    "\n",
    "    '''\n",
    "    # Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling)\n",
    "    (REF: https://github.com/robertofranceschi/Domain-adaptation-on-PACS-dataset/blob/master/code/main.py)\n",
    "\n",
    "    photo_dataloader = DataLoader(photo_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None), num_workers=args.workers, drop_last=True)\n",
    "    art_dataloader = DataLoader(art_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None), num_workers=args.workers, drop_last=False)\n",
    "    cartoon_dataloader = DataLoader(cartoon_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None), num_workers=args.workers, drop_last=False)\n",
    "    sketch_dataloader = DataLoader(sketch_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None), num_workers=args.workers, drop_last=False)\n",
    "\n",
    "    '''\n",
    "\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=(train_sampler is None),\n",
    "        drop_last=True,\n",
    "        num_workers=args.workers,\n",
    "        sampler=train_sampler,\n",
    "    )\n",
    "\n",
    "    # initialize ResNet\n",
    "    encoder = get_resnet(args.resnet, pretrained=args.pretrain) #[MODIFIED- False -> args.pretrain]\n",
    "    n_features = encoder.fc.in_features  # get dimensions of fc layer\n",
    "\n",
    "    # initialize model\n",
    "    if args.relic== False:\n",
    "        model = SimCLR(encoder, args.projection_dim, n_features)\n",
    "    elif args.relic== True:\n",
    "        #[TODO]\n",
    "        model= ReLIC(encoder, args.projection_dim, n_features)\n",
    "        \n",
    "\n",
    "    if args.reload:\n",
    "        model_fp = os.path.join(\n",
    "            args.model_path, \"checkpoint_{}.tar\".format(args.epoch_num)\n",
    "        )\n",
    "        model.load_state_dict(torch.load(model_fp, map_location=args.device.type))\n",
    "    model = model.to(args.device)\n",
    "\n",
    "    # optimizer / loss\n",
    "    optimizer, scheduler = load_optimizer(args, model)\n",
    "\n",
    "    # [TODO] Add ReLIC Objective ici.\n",
    "    if args.relic== False:\n",
    "        criterion = NT_Xent(args.batch_size, args.temperature, args.world_size)\n",
    "    #[TODO- Added] Add ReLic Loss\n",
    "    if args.relic==True:   \n",
    "       criterion = ReLIC_Loss(args.relic_normalize, args.relic_temp, args.relic_alpha)\n",
    "\n",
    "    # DDP / DP\n",
    "    if args.dataparallel:\n",
    "        model = convert_model(model)\n",
    "        model = DataParallel(model)\n",
    "    else:\n",
    "        if args.nodes > 1:\n",
    "            model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model)\n",
    "            model = DDP(model, device_ids=[gpu])\n",
    "\n",
    "    model = model.to(args.device)\n",
    "\n",
    "    writer = None\n",
    "    if args.nr == 0:\n",
    "        writer = SummaryWriter()\n",
    "\n",
    "    args.global_step = 0\n",
    "    args.current_epoch = 0\n",
    "    for epoch in range(args.start_epoch, args.epochs):\n",
    "        if train_sampler is not None:\n",
    "            train_sampler.set_epoch(epoch)\n",
    "        \n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        loss_epoch = train(args, train_loader, model, criterion, optimizer, writer, relic=args.relic)\n",
    "\n",
    "        if args.nr == 0 and scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        if args.nr == 0 and epoch % 10 == 0:\n",
    "            save_model(args, model, optimizer)\n",
    "\n",
    "        if args.nr == 0:\n",
    "            writer.add_scalar(\"Loss/train\", loss_epoch / len(train_loader), epoch)\n",
    "            writer.add_scalar(\"Misc/learning_rate\", lr, epoch)\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{args.epochs}]\\t Loss: {loss_epoch / len(train_loader)}\\t lr: {round(lr, 5)}\"\n",
    "            )\n",
    "            args.current_epoch += 1\n",
    "\n",
    "    ## end training\n",
    "    save_model(args, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d27adfd4-15aa-42fe-b270-1e1271665e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"SimCLR/ReLIC\")\n",
    "config = yaml_config_hook(\"./config/config.yaml\")\n",
    "for k, v in config.items():\n",
    "    parser.add_argument(f\"--{k}\", default=v, type=type(v))\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "# Master address for distributed data parallel\n",
    "os.environ[\"MASTER_ADDR\"] = \"127.0.0.1\"\n",
    "os.environ[\"MASTER_PORT\"] = \"8000\"\n",
    "\n",
    "if not os.path.exists(args.model_path):\n",
    "    os.makedirs(args.model_path)\n",
    "\n",
    "args.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "args.num_gpus = torch.cuda.device_count()\n",
    "args.world_size = args.gpus * args.nodes\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e11a4c3-da63-4d87-9aab-f087fde518ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.relic= True\n",
    "args.projection_dim= 128\n",
    "args.model_path= 'save/relic/relic128/200'\n",
    "args.epoch_num= 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0126e51c-b3f7-47d2-becd-8ee0068570fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLIC -- True\n",
      "Model From -- save/relic/relic128/200, Epoch: 200\n",
      "All Evaluation args --  Namespace(nodes=1, gpus=1, nr=0, dataparallel=0, workers=8, dataset_dir='./datasets', seed=42, batch_size=128, image_size=224, start_epoch=0, epochs=200, dataset='CIFAR10', test_dataset='STL10', pacs_style='default', pretrain=False, relic=True, relic_normalize=True, relic_temp=1.0, relic_alpha=0.5, resnet='resnet18', projection_dim=128, optimizer='LARS', weight_decay=1e-06, temperature=0.5, model_path='save/relic/relic128/200', epoch_num=200, reload=False, logistic_batch_size=256, logistic_epochs=500, device=device(type='cuda', index=0), num_gpus=4, world_size=1)\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "### Creating features from pre-trained context model ###\n",
      "Step [0/19]\t Computing features...\n",
      "Features shape (4864, 512)\n",
      "Step [0/31]\t Computing features...\n",
      "Step [20/31]\t Computing features...\n",
      "Features shape (7936, 512)\n",
      "Epoch [0/500]\t Loss: 2.15664321497867\t Accuracy: 0.24424342105263158\n",
      "Epoch [1/500]\t Loss: 1.8348705141167891\t Accuracy: 0.4342105263157895\n",
      "Epoch [2/500]\t Loss: 1.6321286464992322\t Accuracy: 0.4948601973684211\n",
      "Epoch [3/500]\t Loss: 1.5035455477865118\t Accuracy: 0.5191200657894737\n",
      "Epoch [4/500]\t Loss: 1.4171767987703021\t Accuracy: 0.532483552631579\n",
      "Epoch [5/500]\t Loss: 1.3552401505018536\t Accuracy: 0.5450246710526315\n",
      "Epoch [6/500]\t Loss: 1.3085946346584119\t Accuracy: 0.5540707236842105\n",
      "Epoch [7/500]\t Loss: 1.2719597816467285\t Accuracy: 0.5627055921052632\n",
      "Epoch [8/500]\t Loss: 1.242243064077277\t Accuracy: 0.5682565789473685\n",
      "Epoch [9/500]\t Loss: 1.2175170245923495\t Accuracy: 0.5740131578947368\n",
      "Epoch [10/500]\t Loss: 1.1965110490196629\t Accuracy: 0.5805921052631579\n",
      "Epoch [11/500]\t Loss: 1.1783549848355745\t Accuracy: 0.5834703947368421\n",
      "Epoch [12/500]\t Loss: 1.1624337497510409\t Accuracy: 0.5879934210526315\n",
      "Epoch [13/500]\t Loss: 1.1483005410746525\t Accuracy: 0.59375\n",
      "Epoch [14/500]\t Loss: 1.1356228025336015\t Accuracy: 0.5984786184210527\n",
      "Epoch [15/500]\t Loss: 1.1241476849505776\t Accuracy: 0.6015625\n",
      "Epoch [16/500]\t Loss: 1.113679848219219\t Accuracy: 0.6034128289473685\n",
      "Epoch [17/500]\t Loss: 1.1040656692103337\t Accuracy: 0.606702302631579\n",
      "Epoch [18/500]\t Loss: 1.0951825850888302\t Accuracy: 0.609375\n",
      "Epoch [19/500]\t Loss: 1.0869318058616237\t Accuracy: 0.6110197368421053\n",
      "Epoch [20/500]\t Loss: 1.0792324072436283\t Accuracy: 0.6149259868421053\n",
      "Epoch [21/500]\t Loss: 1.072017635169782\t Accuracy: 0.615953947368421\n",
      "Epoch [22/500]\t Loss: 1.0652319851674532\t Accuracy: 0.6167763157894737\n",
      "Epoch [23/500]\t Loss: 1.0588285609295494\t Accuracy: 0.6204769736842105\n",
      "Epoch [24/500]\t Loss: 1.0527678163428056\t Accuracy: 0.6239720394736842\n",
      "Epoch [25/500]\t Loss: 1.0470158206789117\t Accuracy: 0.626233552631579\n",
      "Epoch [26/500]\t Loss: 1.0415434335407459\t Accuracy: 0.6268503289473685\n",
      "Epoch [27/500]\t Loss: 1.0363255331390782\t Accuracy: 0.6287006578947368\n",
      "Epoch [28/500]\t Loss: 1.031340109674554\t Accuracy: 0.6313733552631579\n",
      "Epoch [29/500]\t Loss: 1.0265679296694303\t Accuracy: 0.6328125\n",
      "Epoch [30/500]\t Loss: 1.0219920591304177\t Accuracy: 0.6328125\n",
      "Epoch [31/500]\t Loss: 1.0175976502267938\t Accuracy: 0.6326069078947368\n",
      "Epoch [32/500]\t Loss: 1.013371207212147\t Accuracy: 0.6342516447368421\n",
      "Epoch [33/500]\t Loss: 1.0093009754231101\t Accuracy: 0.6358963815789473\n",
      "Epoch [34/500]\t Loss: 1.0053762605315761\t Accuracy: 0.6381578947368421\n",
      "Epoch [35/500]\t Loss: 1.0015874254076105\t Accuracy: 0.6404194078947368\n",
      "Epoch [36/500]\t Loss: 0.9979258807081925\t Accuracy: 0.6414473684210527\n",
      "Epoch [37/500]\t Loss: 0.9943837303864328\t Accuracy: 0.6437088815789473\n",
      "Epoch [38/500]\t Loss: 0.9909538438445643\t Accuracy: 0.6455592105263158\n",
      "Epoch [39/500]\t Loss: 0.9876297210392199\t Accuracy: 0.6463815789473685\n",
      "Epoch [40/500]\t Loss: 0.9844053230787578\t Accuracy: 0.6476151315789473\n",
      "Epoch [41/500]\t Loss: 0.9812752259405035\t Accuracy: 0.6488486842105263\n",
      "Epoch [42/500]\t Loss: 0.9782343663667378\t Accuracy: 0.6500822368421053\n",
      "Epoch [43/500]\t Loss: 0.9752781642110724\t Accuracy: 0.6506990131578947\n",
      "Epoch [44/500]\t Loss: 0.9724021836331016\t Accuracy: 0.6517269736842105\n",
      "Epoch [45/500]\t Loss: 0.9696025879759538\t Accuracy: 0.6513157894736842\n",
      "Epoch [46/500]\t Loss: 0.9668755531311035\t Accuracy: 0.6525493421052632\n",
      "Epoch [47/500]\t Loss: 0.9642177600609628\t Accuracy: 0.6531661184210527\n",
      "Epoch [48/500]\t Loss: 0.9616258489458185\t Accuracy: 0.6539884868421053\n",
      "Epoch [49/500]\t Loss: 0.959096980722327\t Accuracy: 0.6541940789473685\n",
      "Epoch [50/500]\t Loss: 0.9566282504483273\t Accuracy: 0.6554276315789473\n",
      "Epoch [51/500]\t Loss: 0.9542170480677956\t Accuracy: 0.65625\n",
      "Epoch [52/500]\t Loss: 0.9518609580240751\t Accuracy: 0.6564555921052632\n",
      "Epoch [53/500]\t Loss: 0.9495575804459421\t Accuracy: 0.6570723684210527\n",
      "Epoch [54/500]\t Loss: 0.947304832307916\t Accuracy: 0.6585115131578947\n",
      "Epoch [55/500]\t Loss: 0.9451006494070354\t Accuracy: 0.6591282894736842\n",
      "Epoch [56/500]\t Loss: 0.9429429581290797\t Accuracy: 0.6599506578947368\n",
      "Epoch [57/500]\t Loss: 0.9408301585598996\t Accuracy: 0.661389802631579\n",
      "Epoch [58/500]\t Loss: 0.9387603245283428\t Accuracy: 0.6620065789473685\n",
      "Epoch [59/500]\t Loss: 0.9367319565070303\t Accuracy: 0.6620065789473685\n",
      "Epoch [60/500]\t Loss: 0.934743373017562\t Accuracy: 0.6626233552631579\n",
      "Epoch [61/500]\t Loss: 0.9327932941286188\t Accuracy: 0.6632401315789473\n",
      "Epoch [62/500]\t Loss: 0.9308801638452631\t Accuracy: 0.6638569078947368\n",
      "Epoch [63/500]\t Loss: 0.9290027085103487\t Accuracy: 0.6638569078947368\n",
      "Epoch [64/500]\t Loss: 0.9271597203455473\t Accuracy: 0.6644736842105263\n",
      "Epoch [65/500]\t Loss: 0.9253499351049724\t Accuracy: 0.6650904605263158\n",
      "Epoch [66/500]\t Loss: 0.9235723081387972\t Accuracy: 0.6655016447368421\n",
      "Epoch [67/500]\t Loss: 0.9218256128461737\t Accuracy: 0.6659128289473685\n",
      "Epoch [68/500]\t Loss: 0.9201089708428634\t Accuracy: 0.6661184210526315\n",
      "Epoch [69/500]\t Loss: 0.9184212998340004\t Accuracy: 0.6669407894736842\n",
      "Epoch [70/500]\t Loss: 0.9167616618307013\t Accuracy: 0.6677631578947368\n",
      "Epoch [71/500]\t Loss: 0.91512919413416\t Accuracy: 0.6694078947368421\n",
      "Epoch [72/500]\t Loss: 0.9135230654164365\t Accuracy: 0.6700246710526315\n",
      "Epoch [73/500]\t Loss: 0.9119423847449454\t Accuracy: 0.6704358552631579\n",
      "Epoch [74/500]\t Loss: 0.9103864117672569\t Accuracy: 0.670641447368421\n",
      "Epoch [75/500]\t Loss: 0.9088543778971622\t Accuracy: 0.6712582236842105\n",
      "Epoch [76/500]\t Loss: 0.9073456023868761\t Accuracy: 0.6714638157894737\n",
      "Epoch [77/500]\t Loss: 0.9058593260614496\t Accuracy: 0.6724917763157895\n",
      "Epoch [78/500]\t Loss: 0.9043949089552227\t Accuracy: 0.6733141447368421\n",
      "Epoch [79/500]\t Loss: 0.9029517330621418\t Accuracy: 0.6735197368421053\n",
      "Epoch [80/500]\t Loss: 0.9015292242953652\t Accuracy: 0.6737253289473685\n",
      "Epoch [81/500]\t Loss: 0.9001267207296271\t Accuracy: 0.6743421052631579\n",
      "Epoch [82/500]\t Loss: 0.8987437267052499\t Accuracy: 0.6747532894736842\n",
      "Epoch [83/500]\t Loss: 0.8973797246029502\t Accuracy: 0.6755756578947368\n",
      "Epoch [84/500]\t Loss: 0.8960340368120294\t Accuracy: 0.6763980263157895\n",
      "Epoch [85/500]\t Loss: 0.8947063308013113\t Accuracy: 0.6774259868421053\n",
      "Epoch [86/500]\t Loss: 0.8933960638548198\t Accuracy: 0.6780427631578947\n",
      "Epoch [87/500]\t Loss: 0.8921028406996476\t Accuracy: 0.6792763157894737\n",
      "Epoch [88/500]\t Loss: 0.8908260590151736\t Accuracy: 0.6790707236842105\n",
      "Epoch [89/500]\t Loss: 0.8895654709715592\t Accuracy: 0.6796875\n",
      "Epoch [90/500]\t Loss: 0.888320483659443\t Accuracy: 0.6798930921052632\n",
      "Epoch [91/500]\t Loss: 0.8870908868940253\t Accuracy: 0.6805098684210527\n",
      "Epoch [92/500]\t Loss: 0.8858761410964163\t Accuracy: 0.680921052631579\n",
      "Epoch [93/500]\t Loss: 0.8846759827513444\t Accuracy: 0.6807154605263158\n",
      "Epoch [94/500]\t Loss: 0.8834899758037768\t Accuracy: 0.680921052631579\n",
      "Epoch [95/500]\t Loss: 0.8823178128192299\t Accuracy: 0.6811266447368421\n",
      "Epoch [96/500]\t Loss: 0.8811591644036142\t Accuracy: 0.6817434210526315\n",
      "Epoch [97/500]\t Loss: 0.8800136854774073\t Accuracy: 0.6819490131578947\n",
      "Epoch [98/500]\t Loss: 0.8788810811544719\t Accuracy: 0.682360197368421\n",
      "Epoch [99/500]\t Loss: 0.877761047137411\t Accuracy: 0.6825657894736842\n",
      "Epoch [100/500]\t Loss: 0.8766532446208753\t Accuracy: 0.6831825657894737\n",
      "Epoch [101/500]\t Loss: 0.8755575230247096\t Accuracy: 0.6833881578947368\n",
      "Epoch [102/500]\t Loss: 0.8744734557051408\t Accuracy: 0.6842105263157895\n",
      "Epoch [103/500]\t Loss: 0.8734008952191001\t Accuracy: 0.6850328947368421\n",
      "Epoch [104/500]\t Loss: 0.8723395058983251\t Accuracy: 0.6860608552631579\n",
      "Epoch [105/500]\t Loss: 0.8712890901063618\t Accuracy: 0.6864720394736842\n",
      "Epoch [106/500]\t Loss: 0.8702494125617178\t Accuracy: 0.6866776315789473\n",
      "Epoch [107/500]\t Loss: 0.8692202066120348\t Accuracy: 0.6870888157894737\n",
      "Epoch [108/500]\t Loss: 0.868201262072513\t Accuracy: 0.6870888157894737\n",
      "Epoch [109/500]\t Loss: 0.8671923656212656\t Accuracy: 0.6879111842105263\n",
      "Epoch [110/500]\t Loss: 0.866193269428454\t Accuracy: 0.688733552631579\n",
      "Epoch [111/500]\t Loss: 0.8652038260510093\t Accuracy: 0.6889391447368421\n",
      "Epoch [112/500]\t Loss: 0.8642238221670452\t Accuracy: 0.6889391447368421\n",
      "Epoch [113/500]\t Loss: 0.8632530256321556\t Accuracy: 0.690172697368421\n",
      "Epoch [114/500]\t Loss: 0.8622913235112241\t Accuracy: 0.6903782894736842\n",
      "Epoch [115/500]\t Loss: 0.8613384773856715\t Accuracy: 0.6907894736842105\n",
      "Epoch [116/500]\t Loss: 0.860394255111092\t Accuracy: 0.6907894736842105\n",
      "Epoch [117/500]\t Loss: 0.8594586221795333\t Accuracy: 0.6912006578947368\n",
      "Epoch [118/500]\t Loss: 0.8585312648823387\t Accuracy: 0.6912006578947368\n",
      "Epoch [119/500]\t Loss: 0.8576121643969887\t Accuracy: 0.69140625\n",
      "Epoch [120/500]\t Loss: 0.8567010854419909\t Accuracy: 0.6918174342105263\n",
      "Epoch [121/500]\t Loss: 0.8557978837113631\t Accuracy: 0.6924342105263158\n",
      "Epoch [122/500]\t Loss: 0.8549024180362099\t Accuracy: 0.6928453947368421\n",
      "Epoch [123/500]\t Loss: 0.8540145566588954\t Accuracy: 0.6932565789473685\n",
      "Epoch [124/500]\t Loss: 0.8531340737091867\t Accuracy: 0.6930509868421053\n",
      "Epoch [125/500]\t Loss: 0.8522609754612571\t Accuracy: 0.6936677631578947\n",
      "Epoch [126/500]\t Loss: 0.851395004674008\t Accuracy: 0.6944901315789473\n",
      "Epoch [127/500]\t Loss: 0.8505360766461021\t Accuracy: 0.6946957236842105\n",
      "Epoch [128/500]\t Loss: 0.8496840847165961\t Accuracy: 0.6949013157894737\n",
      "Epoch [129/500]\t Loss: 0.8488389034020273\t Accuracy: 0.6951069078947368\n",
      "Epoch [130/500]\t Loss: 0.8480004009447599\t Accuracy: 0.6957236842105263\n",
      "Epoch [131/500]\t Loss: 0.8471684455871582\t Accuracy: 0.6959292763157895\n",
      "Epoch [132/500]\t Loss: 0.8463428836119803\t Accuracy: 0.6957236842105263\n",
      "Epoch [133/500]\t Loss: 0.8455237401159186\t Accuracy: 0.6963404605263158\n",
      "Epoch [134/500]\t Loss: 0.8447107735433077\t Accuracy: 0.6961348684210527\n",
      "Epoch [135/500]\t Loss: 0.8439039368378488\t Accuracy: 0.6963404605263158\n",
      "Epoch [136/500]\t Loss: 0.8431031484352914\t Accuracy: 0.6963404605263158\n",
      "Epoch [137/500]\t Loss: 0.8423082326587877\t Accuracy: 0.6967516447368421\n",
      "Epoch [138/500]\t Loss: 0.8415191957825109\t Accuracy: 0.6971628289473685\n",
      "Epoch [139/500]\t Loss: 0.8407358621296129\t Accuracy: 0.6975740131578947\n",
      "Epoch [140/500]\t Loss: 0.8399581375874972\t Accuracy: 0.6981907894736842\n",
      "Epoch [141/500]\t Loss: 0.8391859750998648\t Accuracy: 0.6983963815789473\n",
      "Epoch [142/500]\t Loss: 0.8384192617315995\t Accuracy: 0.69921875\n",
      "Epoch [143/500]\t Loss: 0.8376579378780565\t Accuracy: 0.6990131578947368\n",
      "Epoch [144/500]\t Loss: 0.8369018843299464\t Accuracy: 0.6998355263157895\n",
      "Epoch [145/500]\t Loss: 0.8361510665793168\t Accuracy: 0.7002467105263158\n",
      "Epoch [146/500]\t Loss: 0.8354053183605796\t Accuracy: 0.7000411184210527\n",
      "Epoch [147/500]\t Loss: 0.8346646490849947\t Accuracy: 0.7000411184210527\n",
      "Epoch [148/500]\t Loss: 0.8339289050353201\t Accuracy: 0.6998355263157895\n",
      "Epoch [149/500]\t Loss: 0.8331981175824216\t Accuracy: 0.7002467105263158\n",
      "Epoch [150/500]\t Loss: 0.8324720639931528\t Accuracy: 0.7006578947368421\n",
      "Epoch [151/500]\t Loss: 0.8317508446542841\t Accuracy: 0.7012746710526315\n",
      "Epoch [152/500]\t Loss: 0.8310342995744002\t Accuracy: 0.7014802631578947\n",
      "Epoch [153/500]\t Loss: 0.8303223126812985\t Accuracy: 0.701891447368421\n",
      "Epoch [154/500]\t Loss: 0.8296148651524594\t Accuracy: 0.7023026315789473\n",
      "Epoch [155/500]\t Loss: 0.8289119256170172\t Accuracy: 0.7027138157894737\n",
      "Epoch [156/500]\t Loss: 0.8282133685915094\t Accuracy: 0.703125\n",
      "Epoch [157/500]\t Loss: 0.8275192160355417\t Accuracy: 0.703125\n",
      "Epoch [158/500]\t Loss: 0.8268292954093531\t Accuracy: 0.7035361842105263\n",
      "Epoch [159/500]\t Loss: 0.826143625535463\t Accuracy: 0.704358552631579\n",
      "Epoch [160/500]\t Loss: 0.82546214367214\t Accuracy: 0.704358552631579\n",
      "Epoch [161/500]\t Loss: 0.8247847525697005\t Accuracy: 0.705797697368421\n",
      "Epoch [162/500]\t Loss: 0.8241114365427118\t Accuracy: 0.7060032894736842\n",
      "Epoch [163/500]\t Loss: 0.8234420889302304\t Accuracy: 0.7062088815789473\n",
      "Epoch [164/500]\t Loss: 0.822776690909737\t Accuracy: 0.7066200657894737\n",
      "Epoch [165/500]\t Loss: 0.8221152550295779\t Accuracy: 0.70703125\n",
      "Epoch [166/500]\t Loss: 0.8214576118870786\t Accuracy: 0.7072368421052632\n",
      "Epoch [167/500]\t Loss: 0.8208037332484597\t Accuracy: 0.7072368421052632\n",
      "Epoch [168/500]\t Loss: 0.8201536285249811\t Accuracy: 0.7076480263157895\n",
      "Epoch [169/500]\t Loss: 0.8195072192894785\t Accuracy: 0.7080592105263158\n",
      "Epoch [170/500]\t Loss: 0.818864433388961\t Accuracy: 0.708264802631579\n",
      "Epoch [171/500]\t Loss: 0.818225267686342\t Accuracy: 0.708264802631579\n",
      "Epoch [172/500]\t Loss: 0.8175896876736691\t Accuracy: 0.7084703947368421\n",
      "Epoch [173/500]\t Loss: 0.8169575741416529\t Accuracy: 0.7088815789473685\n",
      "Epoch [174/500]\t Loss: 0.8163289427757263\t Accuracy: 0.7088815789473685\n",
      "Epoch [175/500]\t Loss: 0.815703715148725\t Accuracy: 0.7090871710526315\n",
      "Epoch [176/500]\t Loss: 0.815081913220255\t Accuracy: 0.7092927631578947\n",
      "Epoch [177/500]\t Loss: 0.814463430329373\t Accuracy: 0.7094983552631579\n",
      "Epoch [178/500]\t Loss: 0.8138482351052133\t Accuracy: 0.709703947368421\n",
      "Epoch [179/500]\t Loss: 0.8132363181365164\t Accuracy: 0.7107319078947368\n",
      "Epoch [180/500]\t Loss: 0.8126275915848581\t Accuracy: 0.7111430921052632\n",
      "Epoch [181/500]\t Loss: 0.8120220209422865\t Accuracy: 0.7113486842105263\n",
      "Epoch [182/500]\t Loss: 0.8114196469909266\t Accuracy: 0.7113486842105263\n",
      "Epoch [183/500]\t Loss: 0.810820388166528\t Accuracy: 0.7115542763157895\n",
      "Epoch [184/500]\t Loss: 0.8102241785902726\t Accuracy: 0.7119654605263158\n",
      "Epoch [185/500]\t Loss: 0.8096309900283813\t Accuracy: 0.7123766447368421\n",
      "Epoch [186/500]\t Loss: 0.8090408130695945\t Accuracy: 0.7127878289473685\n",
      "Epoch [187/500]\t Loss: 0.8084536571251718\t Accuracy: 0.7129934210526315\n",
      "Epoch [188/500]\t Loss: 0.8078693182844865\t Accuracy: 0.7134046052631579\n",
      "Epoch [189/500]\t Loss: 0.8072879596760398\t Accuracy: 0.7134046052631579\n",
      "Epoch [190/500]\t Loss: 0.8067094495421961\t Accuracy: 0.7134046052631579\n",
      "Epoch [191/500]\t Loss: 0.8061337659233495\t Accuracy: 0.7140213815789473\n",
      "Epoch [192/500]\t Loss: 0.8055608899969804\t Accuracy: 0.7142269736842105\n",
      "Epoch [193/500]\t Loss: 0.804990762158444\t Accuracy: 0.7150493421052632\n",
      "Epoch [194/500]\t Loss: 0.8044233918190002\t Accuracy: 0.7150493421052632\n",
      "Epoch [195/500]\t Loss: 0.8038587287852639\t Accuracy: 0.7156661184210527\n",
      "Epoch [196/500]\t Loss: 0.8032968044281006\t Accuracy: 0.7156661184210527\n",
      "Epoch [197/500]\t Loss: 0.8027374713044417\t Accuracy: 0.7166940789473685\n",
      "Epoch [198/500]\t Loss: 0.8021807733334994\t Accuracy: 0.7164884868421053\n",
      "Epoch [199/500]\t Loss: 0.8016266791444076\t Accuracy: 0.7164884868421053\n",
      "Epoch [200/500]\t Loss: 0.8010751322696084\t Accuracy: 0.7164884868421053\n",
      "Epoch [201/500]\t Loss: 0.8005261546687076\t Accuracy: 0.7162828947368421\n",
      "Epoch [202/500]\t Loss: 0.7999796741887143\t Accuracy: 0.716077302631579\n",
      "Epoch [203/500]\t Loss: 0.7994357347488403\t Accuracy: 0.716077302631579\n",
      "Epoch [204/500]\t Loss: 0.7988942140027097\t Accuracy: 0.7162828947368421\n",
      "Epoch [205/500]\t Loss: 0.7983551339099282\t Accuracy: 0.7166940789473685\n",
      "Epoch [206/500]\t Loss: 0.7978184474141974\t Accuracy: 0.7168996710526315\n",
      "Epoch [207/500]\t Loss: 0.7972842047089025\t Accuracy: 0.7171052631578947\n",
      "Epoch [208/500]\t Loss: 0.7967523148185328\t Accuracy: 0.7177220394736842\n",
      "Epoch [209/500]\t Loss: 0.7962227338238766\t Accuracy: 0.7183388157894737\n",
      "Epoch [210/500]\t Loss: 0.7956955119183189\t Accuracy: 0.7189555921052632\n",
      "Epoch [211/500]\t Loss: 0.7951705581263492\t Accuracy: 0.7189555921052632\n",
      "Epoch [212/500]\t Loss: 0.794647919504266\t Accuracy: 0.7195723684210527\n",
      "Epoch [213/500]\t Loss: 0.794127483116953\t Accuracy: 0.7201891447368421\n",
      "Epoch [214/500]\t Loss: 0.7936093242544877\t Accuracy: 0.7201891447368421\n",
      "Epoch [215/500]\t Loss: 0.793093320570494\t Accuracy: 0.7203947368421053\n",
      "Epoch [216/500]\t Loss: 0.792579566177569\t Accuracy: 0.7206003289473685\n",
      "Epoch [217/500]\t Loss: 0.7920679261809901\t Accuracy: 0.7210115131578947\n",
      "Epoch [218/500]\t Loss: 0.7915584413628829\t Accuracy: 0.7212171052631579\n",
      "Epoch [219/500]\t Loss: 0.7910511242715936\t Accuracy: 0.7212171052631579\n",
      "Epoch [220/500]\t Loss: 0.7905458902057848\t Accuracy: 0.7216282894736842\n",
      "Epoch [221/500]\t Loss: 0.7900427172058507\t Accuracy: 0.7218338815789473\n",
      "Epoch [222/500]\t Loss: 0.7895416491910031\t Accuracy: 0.7218338815789473\n",
      "Epoch [223/500]\t Loss: 0.7890426108711645\t Accuracy: 0.7220394736842105\n",
      "Epoch [224/500]\t Loss: 0.7885455740125555\t Accuracy: 0.7220394736842105\n",
      "Epoch [225/500]\t Loss: 0.7880505793973019\t Accuracy: 0.7218338815789473\n",
      "Epoch [226/500]\t Loss: 0.7875575831061915\t Accuracy: 0.7218338815789473\n",
      "Epoch [227/500]\t Loss: 0.7870665318087527\t Accuracy: 0.7222450657894737\n",
      "Epoch [228/500]\t Loss: 0.7865775290288424\t Accuracy: 0.7230674342105263\n",
      "Epoch [229/500]\t Loss: 0.7860903677187467\t Accuracy: 0.7232730263157895\n",
      "Epoch [230/500]\t Loss: 0.7856051482652363\t Accuracy: 0.7234786184210527\n",
      "Epoch [231/500]\t Loss: 0.7851218926279169\t Accuracy: 0.7234786184210527\n",
      "Epoch [232/500]\t Loss: 0.7846404470895466\t Accuracy: 0.7236842105263158\n",
      "Epoch [233/500]\t Loss: 0.7841609088998092\t Accuracy: 0.7243009868421053\n",
      "Epoch [234/500]\t Loss: 0.7836832435507524\t Accuracy: 0.7245065789473685\n",
      "Epoch [235/500]\t Loss: 0.7832073851635581\t Accuracy: 0.7247121710526315\n",
      "Epoch [236/500]\t Loss: 0.7827333651090923\t Accuracy: 0.7251233552631579\n",
      "Epoch [237/500]\t Loss: 0.7822611488794026\t Accuracy: 0.7255345394736842\n",
      "Epoch [238/500]\t Loss: 0.7817907458857486\t Accuracy: 0.7257401315789473\n",
      "Epoch [239/500]\t Loss: 0.7813221341685245\t Accuracy: 0.7263569078947368\n",
      "Epoch [240/500]\t Loss: 0.7808552258893063\t Accuracy: 0.7263569078947368\n",
      "Epoch [241/500]\t Loss: 0.780390086926912\t Accuracy: 0.7263569078947368\n",
      "Epoch [242/500]\t Loss: 0.7799267078700819\t Accuracy: 0.7265625\n",
      "Epoch [243/500]\t Loss: 0.7794650322512576\t Accuracy: 0.7269736842105263\n",
      "Epoch [244/500]\t Loss: 0.7790050632075259\t Accuracy: 0.7267680921052632\n",
      "Epoch [245/500]\t Loss: 0.7785468070130599\t Accuracy: 0.7271792763157895\n",
      "Epoch [246/500]\t Loss: 0.7780902260228207\t Accuracy: 0.7273848684210527\n",
      "Epoch [247/500]\t Loss: 0.7776352825917696\t Accuracy: 0.7273848684210527\n",
      "Epoch [248/500]\t Loss: 0.7771820143649453\t Accuracy: 0.7280016447368421\n",
      "Epoch [249/500]\t Loss: 0.776730361737703\t Accuracy: 0.7280016447368421\n",
      "Epoch [250/500]\t Loss: 0.7762803623550817\t Accuracy: 0.7280016447368421\n",
      "Epoch [251/500]\t Loss: 0.7758319126932245\t Accuracy: 0.7280016447368421\n",
      "Epoch [252/500]\t Loss: 0.7753851288243344\t Accuracy: 0.7282072368421053\n",
      "Epoch [253/500]\t Loss: 0.7749398915391219\t Accuracy: 0.7284128289473685\n",
      "Epoch [254/500]\t Loss: 0.7744962729905781\t Accuracy: 0.7284128289473685\n",
      "Epoch [255/500]\t Loss: 0.7740542041627985\t Accuracy: 0.7286184210526315\n",
      "Epoch [256/500]\t Loss: 0.7736136850557829\t Accuracy: 0.7290296052631579\n",
      "Epoch [257/500]\t Loss: 0.7731746466536271\t Accuracy: 0.7290296052631579\n",
      "Epoch [258/500]\t Loss: 0.7727371987543608\t Accuracy: 0.7290296052631579\n",
      "Epoch [259/500]\t Loss: 0.7723012503824735\t Accuracy: 0.729235197368421\n",
      "Epoch [260/500]\t Loss: 0.7718667576187536\t Accuracy: 0.7296463815789473\n",
      "Epoch [261/500]\t Loss: 0.7714338083016244\t Accuracy: 0.7300575657894737\n",
      "Epoch [262/500]\t Loss: 0.7710023302780954\t Accuracy: 0.7300575657894737\n",
      "Epoch [263/500]\t Loss: 0.7705722953143873\t Accuracy: 0.73046875\n",
      "Epoch [264/500]\t Loss: 0.7701437536038851\t Accuracy: 0.73046875\n",
      "Epoch [265/500]\t Loss: 0.7697166361306843\t Accuracy: 0.7302631578947368\n",
      "Epoch [266/500]\t Loss: 0.7692909899510836\t Accuracy: 0.7302631578947368\n",
      "Epoch [267/500]\t Loss: 0.7688667209524858\t Accuracy: 0.7306743421052632\n",
      "Epoch [268/500]\t Loss: 0.7684438636428431\t Accuracy: 0.7308799342105263\n",
      "Epoch [269/500]\t Loss: 0.768022430570502\t Accuracy: 0.7310855263157895\n",
      "Epoch [270/500]\t Loss: 0.7676024154612893\t Accuracy: 0.7310855263157895\n",
      "Epoch [271/500]\t Loss: 0.7671837304767809\t Accuracy: 0.7310855263157895\n",
      "Epoch [272/500]\t Loss: 0.7667664477699682\t Accuracy: 0.7310855263157895\n",
      "Epoch [273/500]\t Loss: 0.7663505422441583\t Accuracy: 0.73046875\n",
      "Epoch [274/500]\t Loss: 0.7659359856655723\t Accuracy: 0.7302631578947368\n",
      "Epoch [275/500]\t Loss: 0.7655227341149983\t Accuracy: 0.7306743421052632\n",
      "Epoch [276/500]\t Loss: 0.765110897390466\t Accuracy: 0.7308799342105263\n",
      "Epoch [277/500]\t Loss: 0.7647003186376471\t Accuracy: 0.7312911184210527\n",
      "Epoch [278/500]\t Loss: 0.7642910700095328\t Accuracy: 0.7312911184210527\n",
      "Epoch [279/500]\t Loss: 0.7638831420948631\t Accuracy: 0.7314967105263158\n",
      "Epoch [280/500]\t Loss: 0.7634764941115129\t Accuracy: 0.7314967105263158\n",
      "Epoch [281/500]\t Loss: 0.7630711731157804\t Accuracy: 0.731702302631579\n",
      "Epoch [282/500]\t Loss: 0.762667084995069\t Accuracy: 0.7323190789473685\n",
      "Epoch [283/500]\t Loss: 0.7622642987652829\t Accuracy: 0.7327302631578947\n",
      "Epoch [284/500]\t Loss: 0.7618627579588639\t Accuracy: 0.733141447368421\n",
      "Epoch [285/500]\t Loss: 0.7614624625758121\t Accuracy: 0.7333470394736842\n",
      "Epoch [286/500]\t Loss: 0.7610634471240797\t Accuracy: 0.7333470394736842\n",
      "Epoch [287/500]\t Loss: 0.7606656457248487\t Accuracy: 0.7333470394736842\n",
      "Epoch [288/500]\t Loss: 0.7602690803377252\t Accuracy: 0.7333470394736842\n",
      "Epoch [289/500]\t Loss: 0.7598736819468046\t Accuracy: 0.7333470394736842\n",
      "Epoch [290/500]\t Loss: 0.7594795603501169\t Accuracy: 0.7333470394736842\n",
      "Epoch [291/500]\t Loss: 0.7590866465317575\t Accuracy: 0.7335526315789473\n",
      "Epoch [292/500]\t Loss: 0.7586948997096011\t Accuracy: 0.7337582236842105\n",
      "Epoch [293/500]\t Loss: 0.7583043136094746\t Accuracy: 0.7337582236842105\n",
      "Epoch [294/500]\t Loss: 0.7579149352876764\t Accuracy: 0.7339638157894737\n",
      "Epoch [295/500]\t Loss: 0.7575267647442064\t Accuracy: 0.7339638157894737\n",
      "Epoch [296/500]\t Loss: 0.7571396890439486\t Accuracy: 0.7339638157894737\n",
      "Epoch [297/500]\t Loss: 0.7567538305332786\t Accuracy: 0.7339638157894737\n",
      "Epoch [298/500]\t Loss: 0.7563691170592057\t Accuracy: 0.7341694078947368\n",
      "Epoch [299/500]\t Loss: 0.7559855015654313\t Accuracy: 0.7345805921052632\n",
      "Epoch [300/500]\t Loss: 0.7556030248340807\t Accuracy: 0.734375\n",
      "Epoch [301/500]\t Loss: 0.7552216994135004\t Accuracy: 0.7345805921052632\n",
      "Epoch [302/500]\t Loss: 0.7548414845215646\t Accuracy: 0.7347861842105263\n",
      "Epoch [303/500]\t Loss: 0.7544623832953604\t Accuracy: 0.7351973684210527\n",
      "Epoch [304/500]\t Loss: 0.7540844082832336\t Accuracy: 0.7354029605263158\n",
      "Epoch [305/500]\t Loss: 0.7537074685096741\t Accuracy: 0.735608552631579\n",
      "Epoch [306/500]\t Loss: 0.7533316800468847\t Accuracy: 0.735608552631579\n",
      "Epoch [307/500]\t Loss: 0.7529569832902205\t Accuracy: 0.7358141447368421\n",
      "Epoch [308/500]\t Loss: 0.7525833468688162\t Accuracy: 0.7360197368421053\n",
      "Epoch [309/500]\t Loss: 0.7522107896051908\t Accuracy: 0.7362253289473685\n",
      "Epoch [310/500]\t Loss: 0.751839258168873\t Accuracy: 0.737047697368421\n",
      "Epoch [311/500]\t Loss: 0.7514688215757671\t Accuracy: 0.7372532894736842\n",
      "Epoch [312/500]\t Loss: 0.7510994233583149\t Accuracy: 0.7372532894736842\n",
      "Epoch [313/500]\t Loss: 0.7507310321456507\t Accuracy: 0.7372532894736842\n",
      "Epoch [314/500]\t Loss: 0.7503637640099776\t Accuracy: 0.7372532894736842\n",
      "Epoch [315/500]\t Loss: 0.7499974495486209\t Accuracy: 0.7376644736842105\n",
      "Epoch [316/500]\t Loss: 0.7496322299304762\t Accuracy: 0.7378700657894737\n",
      "Epoch [317/500]\t Loss: 0.7492679639866477\t Accuracy: 0.7378700657894737\n",
      "Epoch [318/500]\t Loss: 0.7489047395555597\t Accuracy: 0.7378700657894737\n",
      "Epoch [319/500]\t Loss: 0.7485425127179999\t Accuracy: 0.73828125\n",
      "Epoch [320/500]\t Loss: 0.7481812897481417\t Accuracy: 0.7386924342105263\n",
      "Epoch [321/500]\t Loss: 0.7478210580976385\t Accuracy: 0.7386924342105263\n",
      "Epoch [322/500]\t Loss: 0.7474618271777504\t Accuracy: 0.7386924342105263\n",
      "Epoch [323/500]\t Loss: 0.7471035969884772\t Accuracy: 0.7388980263157895\n",
      "Epoch [324/500]\t Loss: 0.7467463424331263\t Accuracy: 0.7393092105263158\n",
      "Epoch [325/500]\t Loss: 0.7463900007699665\t Accuracy: 0.7393092105263158\n",
      "Epoch [326/500]\t Loss: 0.7460346943453738\t Accuracy: 0.739514802631579\n",
      "Epoch [327/500]\t Loss: 0.7456803510063573\t Accuracy: 0.7397203947368421\n",
      "Epoch [328/500]\t Loss: 0.7453268985999258\t Accuracy: 0.7399259868421053\n",
      "Epoch [329/500]\t Loss: 0.7449744155532435\t Accuracy: 0.7403371710526315\n",
      "Epoch [330/500]\t Loss: 0.7446228861808777\t Accuracy: 0.7403371710526315\n",
      "Epoch [331/500]\t Loss: 0.7442723073457417\t Accuracy: 0.7405427631578947\n",
      "Epoch [332/500]\t Loss: 0.7439226790478355\t Accuracy: 0.7405427631578947\n",
      "Epoch [333/500]\t Loss: 0.7435739197229084\t Accuracy: 0.740953947368421\n",
      "Epoch [334/500]\t Loss: 0.7432261391689903\t Accuracy: 0.7411595394736842\n",
      "Epoch [335/500]\t Loss: 0.7428792526847438\t Accuracy: 0.7411595394736842\n",
      "Epoch [336/500]\t Loss: 0.7425332571330824\t Accuracy: 0.7413651315789473\n",
      "Epoch [337/500]\t Loss: 0.7421881964332179\t Accuracy: 0.7413651315789473\n",
      "Epoch [338/500]\t Loss: 0.7418440078434191\t Accuracy: 0.7413651315789473\n",
      "Epoch [339/500]\t Loss: 0.7415007290087248\t Accuracy: 0.7413651315789473\n",
      "Epoch [340/500]\t Loss: 0.7411583756145678\t Accuracy: 0.7413651315789473\n",
      "Epoch [341/500]\t Loss: 0.7408168723708705\t Accuracy: 0.7415707236842105\n",
      "Epoch [342/500]\t Loss: 0.7404762537855851\t Accuracy: 0.7419819078947368\n",
      "Epoch [343/500]\t Loss: 0.7401364916249326\t Accuracy: 0.7421875\n",
      "Epoch [344/500]\t Loss: 0.7397976674531636\t Accuracy: 0.7421875\n",
      "Epoch [345/500]\t Loss: 0.73945961500469\t Accuracy: 0.7421875\n",
      "Epoch [346/500]\t Loss: 0.739122494270927\t Accuracy: 0.7421875\n",
      "Epoch [347/500]\t Loss: 0.7387862393730565\t Accuracy: 0.7423930921052632\n",
      "Epoch [348/500]\t Loss: 0.7384507844322606\t Accuracy: 0.7425986842105263\n",
      "Epoch [349/500]\t Loss: 0.7381162141498766\t Accuracy: 0.7428042763157895\n",
      "Epoch [350/500]\t Loss: 0.7377824689212599\t Accuracy: 0.7428042763157895\n",
      "Epoch [351/500]\t Loss: 0.7374495299238908\t Accuracy: 0.7432154605263158\n",
      "Epoch [352/500]\t Loss: 0.7371175100928858\t Accuracy: 0.7432154605263158\n",
      "Epoch [353/500]\t Loss: 0.736786236888484\t Accuracy: 0.7436266447368421\n",
      "Epoch [354/500]\t Loss: 0.7364558703020999\t Accuracy: 0.7438322368421053\n",
      "Epoch [355/500]\t Loss: 0.7361262628906652\t Accuracy: 0.7438322368421053\n",
      "Epoch [356/500]\t Loss: 0.7357974836700841\t Accuracy: 0.7442434210526315\n",
      "Epoch [357/500]\t Loss: 0.7354695106807508\t Accuracy: 0.7444490131578947\n",
      "Epoch [358/500]\t Loss: 0.7351423721564444\t Accuracy: 0.7444490131578947\n",
      "Epoch [359/500]\t Loss: 0.7348159990812603\t Accuracy: 0.7442434210526315\n",
      "Epoch [360/500]\t Loss: 0.7344904541969299\t Accuracy: 0.7442434210526315\n",
      "Epoch [361/500]\t Loss: 0.7341656841729817\t Accuracy: 0.7442434210526315\n",
      "Epoch [362/500]\t Loss: 0.7338417266544542\t Accuracy: 0.7446546052631579\n",
      "Epoch [363/500]\t Loss: 0.733518543996309\t Accuracy: 0.7446546052631579\n",
      "Epoch [364/500]\t Loss: 0.7331961393356323\t Accuracy: 0.7446546052631579\n",
      "Epoch [365/500]\t Loss: 0.7328745252207706\t Accuracy: 0.744860197368421\n",
      "Epoch [366/500]\t Loss: 0.7325536577325118\t Accuracy: 0.7452713815789473\n",
      "Epoch [367/500]\t Loss: 0.7322335996125874\t Accuracy: 0.7454769736842105\n",
      "Epoch [368/500]\t Loss: 0.731914288119266\t Accuracy: 0.7452713815789473\n",
      "Epoch [369/500]\t Loss: 0.731595726389634\t Accuracy: 0.7454769736842105\n",
      "Epoch [370/500]\t Loss: 0.7312779583429035\t Accuracy: 0.7456825657894737\n",
      "Epoch [371/500]\t Loss: 0.7309608961406507\t Accuracy: 0.7456825657894737\n",
      "Epoch [372/500]\t Loss: 0.7306446182100397\t Accuracy: 0.7456825657894737\n",
      "Epoch [373/500]\t Loss: 0.7303291182768973\t Accuracy: 0.7458881578947368\n",
      "Epoch [374/500]\t Loss: 0.7300142426239816\t Accuracy: 0.7462993421052632\n",
      "Epoch [375/500]\t Loss: 0.7297002077102661\t Accuracy: 0.7465049342105263\n",
      "Epoch [376/500]\t Loss: 0.7293869319714998\t Accuracy: 0.7465049342105263\n",
      "Epoch [377/500]\t Loss: 0.7290743495288649\t Accuracy: 0.7465049342105263\n",
      "Epoch [378/500]\t Loss: 0.7287624917532268\t Accuracy: 0.7465049342105263\n",
      "Epoch [379/500]\t Loss: 0.7284513617816725\t Accuracy: 0.7465049342105263\n",
      "Epoch [380/500]\t Loss: 0.72814090628373\t Accuracy: 0.74609375\n",
      "Epoch [381/500]\t Loss: 0.7278312381945158\t Accuracy: 0.74609375\n",
      "Epoch [382/500]\t Loss: 0.7275222508530867\t Accuracy: 0.74609375\n",
      "Epoch [383/500]\t Loss: 0.7272139630819622\t Accuracy: 0.7462993421052632\n",
      "Epoch [384/500]\t Loss: 0.7269064313487003\t Accuracy: 0.7465049342105263\n",
      "Epoch [385/500]\t Loss: 0.7265995489923578\t Accuracy: 0.7467105263157895\n",
      "Epoch [386/500]\t Loss: 0.7262934226738779\t Accuracy: 0.7467105263157895\n",
      "Epoch [387/500]\t Loss: 0.7259879457323175\t Accuracy: 0.7471217105263158\n",
      "Epoch [388/500]\t Loss: 0.7256831683610615\t Accuracy: 0.7471217105263158\n",
      "Epoch [389/500]\t Loss: 0.7253790748746771\t Accuracy: 0.7469161184210527\n",
      "Epoch [390/500]\t Loss: 0.7250756684102511\t Accuracy: 0.747327302631579\n",
      "Epoch [391/500]\t Loss: 0.7247729301452637\t Accuracy: 0.7477384868421053\n",
      "Epoch [392/500]\t Loss: 0.7244709290956196\t Accuracy: 0.7475328947368421\n",
      "Epoch [393/500]\t Loss: 0.7241695868341547\t Accuracy: 0.7481496710526315\n",
      "Epoch [394/500]\t Loss: 0.7238688876754359\t Accuracy: 0.7481496710526315\n",
      "Epoch [395/500]\t Loss: 0.7235689037724545\t Accuracy: 0.7485608552631579\n",
      "Epoch [396/500]\t Loss: 0.7232695410126134\t Accuracy: 0.7485608552631579\n",
      "Epoch [397/500]\t Loss: 0.7229708276296917\t Accuracy: 0.7485608552631579\n",
      "Epoch [398/500]\t Loss: 0.7226728357766804\t Accuracy: 0.7485608552631579\n",
      "Epoch [399/500]\t Loss: 0.7223754650668094\t Accuracy: 0.748766447368421\n",
      "Epoch [400/500]\t Loss: 0.7220787562822041\t Accuracy: 0.7489720394736842\n",
      "Epoch [401/500]\t Loss: 0.7217827156970376\t Accuracy: 0.7493832236842105\n",
      "Epoch [402/500]\t Loss: 0.7214872962550113\t Accuracy: 0.7495888157894737\n",
      "Epoch [403/500]\t Loss: 0.7211925387382507\t Accuracy: 0.75\n",
      "Epoch [404/500]\t Loss: 0.720898405501717\t Accuracy: 0.75\n",
      "Epoch [405/500]\t Loss: 0.7206049373275355\t Accuracy: 0.75\n",
      "Epoch [406/500]\t Loss: 0.7203121059819272\t Accuracy: 0.7504111842105263\n",
      "Epoch [407/500]\t Loss: 0.7200199051907188\t Accuracy: 0.7504111842105263\n",
      "Epoch [408/500]\t Loss: 0.719728265938006\t Accuracy: 0.7504111842105263\n",
      "Epoch [409/500]\t Loss: 0.7194373168443379\t Accuracy: 0.7506167763157895\n",
      "Epoch [410/500]\t Loss: 0.7191470171275892\t Accuracy: 0.7506167763157895\n",
      "Epoch [411/500]\t Loss: 0.7188572977718554\t Accuracy: 0.7506167763157895\n",
      "Epoch [412/500]\t Loss: 0.7185682152446947\t Accuracy: 0.7506167763157895\n",
      "Epoch [413/500]\t Loss: 0.7182797099414625\t Accuracy: 0.7506167763157895\n",
      "Epoch [414/500]\t Loss: 0.717991894797275\t Accuracy: 0.7506167763157895\n",
      "Epoch [415/500]\t Loss: 0.7177046160948904\t Accuracy: 0.751233552631579\n",
      "Epoch [416/500]\t Loss: 0.7174179899065118\t Accuracy: 0.751233552631579\n",
      "Epoch [417/500]\t Loss: 0.7171319629016676\t Accuracy: 0.7514391447368421\n",
      "Epoch [418/500]\t Loss: 0.7168464974353188\t Accuracy: 0.7514391447368421\n",
      "Epoch [419/500]\t Loss: 0.7165616687975431\t Accuracy: 0.7514391447368421\n",
      "Epoch [420/500]\t Loss: 0.7162774330691287\t Accuracy: 0.7514391447368421\n",
      "Epoch [421/500]\t Loss: 0.7159937996613351\t Accuracy: 0.7516447368421053\n",
      "Epoch [422/500]\t Loss: 0.7157107246549506\t Accuracy: 0.7516447368421053\n",
      "Epoch [423/500]\t Loss: 0.7154282896142257\t Accuracy: 0.7518503289473685\n",
      "Epoch [424/500]\t Loss: 0.7151463816040441\t Accuracy: 0.7520559210526315\n",
      "Epoch [425/500]\t Loss: 0.7148650915999162\t Accuracy: 0.7522615131578947\n",
      "Epoch [426/500]\t Loss: 0.7145844039164091\t Accuracy: 0.7528782894736842\n",
      "Epoch [427/500]\t Loss: 0.7143042338521857\t Accuracy: 0.7530838815789473\n",
      "Epoch [428/500]\t Loss: 0.7140247163019682\t Accuracy: 0.7532894736842105\n",
      "Epoch [429/500]\t Loss: 0.7137457069597746\t Accuracy: 0.7532894736842105\n",
      "Epoch [430/500]\t Loss: 0.7134673030752885\t Accuracy: 0.7537006578947368\n",
      "Epoch [431/500]\t Loss: 0.7131894607292978\t Accuracy: 0.75390625\n",
      "Epoch [432/500]\t Loss: 0.7129121893330624\t Accuracy: 0.75390625\n",
      "Epoch [433/500]\t Loss: 0.712635476338236\t Accuracy: 0.75390625\n",
      "Epoch [434/500]\t Loss: 0.7123593123335588\t Accuracy: 0.75390625\n",
      "Epoch [435/500]\t Loss: 0.7120837255528099\t Accuracy: 0.75390625\n",
      "Epoch [436/500]\t Loss: 0.7118086940363834\t Accuracy: 0.75390625\n",
      "Epoch [437/500]\t Loss: 0.7115341770021539\t Accuracy: 0.75390625\n",
      "Epoch [438/500]\t Loss: 0.7112602654256319\t Accuracy: 0.75390625\n",
      "Epoch [439/500]\t Loss: 0.7109868620571337\t Accuracy: 0.75390625\n",
      "Epoch [440/500]\t Loss: 0.7107140766946893\t Accuracy: 0.7537006578947368\n",
      "Epoch [441/500]\t Loss: 0.7104417650323165\t Accuracy: 0.75390625\n",
      "Epoch [442/500]\t Loss: 0.7101699898117467\t Accuracy: 0.7541118421052632\n",
      "Epoch [443/500]\t Loss: 0.7098987824038455\t Accuracy: 0.7543174342105263\n",
      "Epoch [444/500]\t Loss: 0.7096281333973533\t Accuracy: 0.7543174342105263\n",
      "Epoch [445/500]\t Loss: 0.7093579863247118\t Accuracy: 0.7547286184210527\n",
      "Epoch [446/500]\t Loss: 0.7090884070647391\t Accuracy: 0.7547286184210527\n",
      "Epoch [447/500]\t Loss: 0.7088193046419244\t Accuracy: 0.7549342105263158\n",
      "Epoch [448/500]\t Loss: 0.7085507919913844\t Accuracy: 0.755139802631579\n",
      "Epoch [449/500]\t Loss: 0.7082827624521757\t Accuracy: 0.755139802631579\n",
      "Epoch [450/500]\t Loss: 0.7080152724918566\t Accuracy: 0.755139802631579\n",
      "Epoch [451/500]\t Loss: 0.707748315836254\t Accuracy: 0.7553453947368421\n",
      "Epoch [452/500]\t Loss: 0.7074818548403288\t Accuracy: 0.7553453947368421\n",
      "Epoch [453/500]\t Loss: 0.7072159240120336\t Accuracy: 0.7557565789473685\n",
      "Epoch [454/500]\t Loss: 0.7069505139401084\t Accuracy: 0.7557565789473685\n",
      "Epoch [455/500]\t Loss: 0.7066856183503804\t Accuracy: 0.7557565789473685\n",
      "Epoch [456/500]\t Loss: 0.7064211901865507\t Accuracy: 0.7557565789473685\n",
      "Epoch [457/500]\t Loss: 0.70615732042413\t Accuracy: 0.7559621710526315\n",
      "Epoch [458/500]\t Loss: 0.7058939714180795\t Accuracy: 0.7559621710526315\n",
      "Epoch [459/500]\t Loss: 0.7056310835637545\t Accuracy: 0.7563733552631579\n",
      "Epoch [460/500]\t Loss: 0.705368719602886\t Accuracy: 0.7563733552631579\n",
      "Epoch [461/500]\t Loss: 0.7051068262050026\t Accuracy: 0.756578947368421\n",
      "Epoch [462/500]\t Loss: 0.7048454974827013\t Accuracy: 0.756578947368421\n",
      "Epoch [463/500]\t Loss: 0.7045846361862985\t Accuracy: 0.756578947368421\n",
      "Epoch [464/500]\t Loss: 0.7043242642754003\t Accuracy: 0.7563733552631579\n",
      "Epoch [465/500]\t Loss: 0.7040643692016602\t Accuracy: 0.7563733552631579\n",
      "Epoch [466/500]\t Loss: 0.7038049854730305\t Accuracy: 0.756578947368421\n",
      "Epoch [467/500]\t Loss: 0.7035460974040785\t Accuracy: 0.7569901315789473\n",
      "Epoch [468/500]\t Loss: 0.7032876830351981\t Accuracy: 0.7574013157894737\n",
      "Epoch [469/500]\t Loss: 0.7030297423663893\t Accuracy: 0.7574013157894737\n",
      "Epoch [470/500]\t Loss: 0.7027722785347387\t Accuracy: 0.7576069078947368\n",
      "Epoch [471/500]\t Loss: 0.7025153542819776\t Accuracy: 0.7580180921052632\n",
      "Epoch [472/500]\t Loss: 0.7022588441246435\t Accuracy: 0.7580180921052632\n",
      "Epoch [473/500]\t Loss: 0.7020028641349391\t Accuracy: 0.7584292763157895\n",
      "Epoch [474/500]\t Loss: 0.7017473327486139\t Accuracy: 0.7584292763157895\n",
      "Epoch [475/500]\t Loss: 0.7014922531027543\t Accuracy: 0.7586348684210527\n",
      "Epoch [476/500]\t Loss: 0.7012376848020052\t Accuracy: 0.7588404605263158\n",
      "Epoch [477/500]\t Loss: 0.700983609023847\t Accuracy: 0.7586348684210527\n",
      "Epoch [478/500]\t Loss: 0.7007299473411158\t Accuracy: 0.7586348684210527\n",
      "Epoch [479/500]\t Loss: 0.7004767624955428\t Accuracy: 0.7594572368421053\n",
      "Epoch [480/500]\t Loss: 0.7002240419387817\t Accuracy: 0.7596628289473685\n",
      "Epoch [481/500]\t Loss: 0.6999717982191789\t Accuracy: 0.7598684210526315\n",
      "Epoch [482/500]\t Loss: 0.6997200062400416\t Accuracy: 0.7598684210526315\n",
      "Epoch [483/500]\t Loss: 0.699468709920582\t Accuracy: 0.7602796052631579\n",
      "Epoch [484/500]\t Loss: 0.6992177963256836\t Accuracy: 0.7602796052631579\n",
      "Epoch [485/500]\t Loss: 0.6989674034871554\t Accuracy: 0.760485197368421\n",
      "Epoch [486/500]\t Loss: 0.6987174435665733\t Accuracy: 0.760485197368421\n",
      "Epoch [487/500]\t Loss: 0.6984679385235435\t Accuracy: 0.760485197368421\n",
      "Epoch [488/500]\t Loss: 0.6982188789468062\t Accuracy: 0.760485197368421\n",
      "Epoch [489/500]\t Loss: 0.697970261699275\t Accuracy: 0.760485197368421\n",
      "Epoch [490/500]\t Loss: 0.6977221307001615\t Accuracy: 0.760485197368421\n",
      "Epoch [491/500]\t Loss: 0.6974743761514363\t Accuracy: 0.760485197368421\n",
      "Epoch [492/500]\t Loss: 0.6972271078511288\t Accuracy: 0.760485197368421\n",
      "Epoch [493/500]\t Loss: 0.6969802693316811\t Accuracy: 0.7606907894736842\n",
      "Epoch [494/500]\t Loss: 0.6967338731414393\t Accuracy: 0.7606907894736842\n",
      "Epoch [495/500]\t Loss: 0.6964879349658364\t Accuracy: 0.7606907894736842\n",
      "Epoch [496/500]\t Loss: 0.6962424077485737\t Accuracy: 0.7608963815789473\n",
      "Epoch [497/500]\t Loss: 0.6959973291346901\t Accuracy: 0.7611019736842105\n",
      "Epoch [498/500]\t Loss: 0.6957527116725319\t Accuracy: 0.7613075657894737\n",
      "Epoch [499/500]\t Loss: 0.6955084863461947\t Accuracy: 0.76171875\n",
      "[FINAL]\t Loss: 0.8537360775855279\t Accuracy: 0.6901461693548387\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#main(0, args)\n",
    "    \n",
    "#Linear Evaluation (=Test Sequence)\n",
    "linear_evaluation.main(0,args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21e3666-30bd-4624-8231-300080ca0cae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
