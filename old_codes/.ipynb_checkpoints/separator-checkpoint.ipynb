{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28bf9e86-0994-4379-aa8e-0a1c25c89ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "#SimCLR\n",
    "from simclr import SimCLR\n",
    "from simclr.modules import LogisticRegression, get_resnet\n",
    "from simclr.modules.transformations import TransformsSimCLR\n",
    "\n",
    "#ReLIC\n",
    "#[TODO]\n",
    "from relic import ReLIC\n",
    "#from relic.modules import ReLIC_Loss, get_resnet\n",
    "from relic.modules.transformations import TransformsRelic\n",
    "\n",
    "# TensorBoard\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "from utils import yaml_config_hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7c787ab-8e34-45de-907e-9dc70c352898",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"SimCLR/ReLIC\")\n",
    "config = yaml_config_hook(\"./config/config.yaml\")\n",
    "for k, v in config.items():\n",
    "    parser.add_argument(f\"--{k}\", default=v, type=type(v))\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "\n",
    "# Master address for distributed data parallel\n",
    "os.environ[\"MASTER_ADDR\"] = \"127.0.0.1\"\n",
    "os.environ[\"MASTER_PORT\"] = \"8000\"\n",
    "\n",
    "if not os.path.exists(args.model_path):\n",
    "    os.makedirs(args.model_path)\n",
    "\n",
    "args.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "args.num_gpus = torch.cuda.device_count()\n",
    "args.world_size = args.gpus * args.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e883616-3055-4582-814a-9738207d446d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(loader, ssl_model, device ,relic):\n",
    "    feature_vector = []\n",
    "    labels_vector = []\n",
    "    #SIMCLR\n",
    "    if relic == False:\n",
    "        for step, (x, y) in enumerate(loader):\n",
    "            x = x.to(device)\n",
    "\n",
    "            # get encoding\n",
    "            with torch.no_grad():\n",
    "                h, _, z, _ = ssl_model(x, x)\n",
    "\n",
    "            h = h.detach()\n",
    "\n",
    "            feature_vector.extend(h.cpu().detach().numpy())\n",
    "            labels_vector.extend(y.numpy())\n",
    "\n",
    "            if step % 20 == 0:\n",
    "                print(f\"Step [{step}/{len(loader)}]\\t Computing features...\")\n",
    "\n",
    "        feature_vector = np.array(feature_vector)\n",
    "        labels_vector = np.array(labels_vector)\n",
    "        print(\"Features shape {}\".format(feature_vector.shape))\n",
    "        return feature_vector, labels_vector\n",
    "    #ReLIC\n",
    "    elif relic == True:\n",
    "        for step, (x, y) in enumerate(loader):\n",
    "            x = x.to(device)\n",
    "\n",
    "            # get encoding\n",
    "            with torch.no_grad():\n",
    "                #[TODO] inference\n",
    "                \n",
    "                #dkcho\n",
    "                #h,_,_, _, _, _, _ = ssl_model(x, x, x)\n",
    "                \n",
    "                #new\n",
    "                h= ssl_model(x,x,x, test= True)\n",
    "                \n",
    "\n",
    "\n",
    "            \n",
    "            h = h.detach() #(256,512)\n",
    "\n",
    "            feature_vector.extend(h.cpu().detach().numpy())\n",
    "            labels_vector.extend(y.numpy())\n",
    "\n",
    "            \n",
    "\n",
    "            if step % 20 == 0:\n",
    "                print(f\"Step [{step}/{len(loader)}]\\t Computing features...\")\n",
    "\n",
    "        feature_vector = np.array(feature_vector)\n",
    "        labels_vector = np.array(labels_vector)\n",
    "        print(\"Features shape {}\".format(feature_vector.shape))\n",
    "        return feature_vector, labels_vector        \n",
    "\n",
    "def get_features(ssl_model, train_loader, test_loader, device, relic):\n",
    "    train_X, train_y = inference(train_loader, ssl_model, device, relic) #relic\n",
    "    test_X, test_y = inference(test_loader, ssl_model, device, relic) #relic\n",
    "    return train_X, train_y, test_X, test_y\n",
    "\n",
    "\n",
    "def create_data_loaders_from_arrays(X_train, y_train, X_test, y_test, batch_size):\n",
    "    train = torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(X_train), torch.from_numpy(y_train)\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "\n",
    "    test = torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(X_test), torch.from_numpy(y_test)\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "def train(args, loader, ssl_model, model, criterion, optimizer):\n",
    "    loss_epoch = 0\n",
    "    accuracy_epoch = 0\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x = x.to(args.device)\n",
    "        y = y.to(args.device)\n",
    "        \n",
    "\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        predicted = output.argmax(1)\n",
    "        acc = (predicted == y).sum().item() / y.size(0)\n",
    "        accuracy_epoch += acc\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_epoch += loss.item()\n",
    "        # if step % 100 == 0:\n",
    "        #     print(\n",
    "        #         f\"Step [{step}/{len(loader)}]\\t Loss: {loss.item()}\\t Accuracy: {acc}\"\n",
    "        #     )\n",
    "\n",
    "    return loss_epoch, accuracy_epoch\n",
    "\n",
    "\n",
    "def test(args, loader, ssl_model, model, criterion, optimizer):\n",
    "    loss_epoch = 0\n",
    "    accuracy_epoch = 0\n",
    "    model.eval()\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        model.zero_grad()\n",
    "\n",
    "        x = x.to(args.device)\n",
    "        y = y.to(args.device)\n",
    "\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        predicted = output.argmax(1)\n",
    "        acc = (predicted == y).sum().item() / y.size(0)\n",
    "        accuracy_epoch += acc\n",
    "\n",
    "        loss_epoch += loss.item()\n",
    "\n",
    "    return loss_epoch, accuracy_epoch\n",
    "\n",
    "def main(gpu,args):\n",
    "\n",
    "    print(\"ReLIC -- {c}\".format(c= args.relic))\n",
    "    print(\"Model From -- {m}, Epoch: {e}\".format(m= args.model_path, e= args.epoch_num))\n",
    "    print(\"All Evaluation args -- \", args)\n",
    "\n",
    "    \n",
    "    if args.relic == False:\n",
    "        if args.test_dataset == \"STL10\":\n",
    "            train_dataset = torchvision.datasets.STL10(\n",
    "                args.dataset_dir,\n",
    "                split=\"train\",\n",
    "                download=True,\n",
    "                transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "            )\n",
    "            test_dataset = torchvision.datasets.STL10(\n",
    "                args.dataset_dir,\n",
    "                split=\"test\",\n",
    "                download=True,\n",
    "                transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "            )\n",
    "        elif args.test_dataset == \"CIFAR10\":\n",
    "            train_dataset = torchvision.datasets.CIFAR10(\n",
    "                args.dataset_dir,\n",
    "                train=True,\n",
    "                download=True,\n",
    "                transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "            )\n",
    "            test_dataset = torchvision.datasets.CIFAR10(\n",
    "                args.dataset_dir,\n",
    "                train=False,\n",
    "                download=True,\n",
    "                transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "            )\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "    \n",
    "    #[TODO - Added] ReLIC\n",
    "    elif args.relic == True:\n",
    "        if args.test_dataset == \"STL10\":\n",
    "            train_dataset = torchvision.datasets.STL10(\n",
    "                args.dataset_dir,\n",
    "                split=\"train\",\n",
    "                download=True,\n",
    "                transform=TransformsRelic(size=args.image_size).test_transform,\n",
    "            )\n",
    "            test_dataset = torchvision.datasets.STL10(\n",
    "                args.dataset_dir,\n",
    "                split=\"test\",\n",
    "                download=True,\n",
    "                transform=TransformsRelic(size=args.image_size).test_transform,\n",
    "            )\n",
    "        elif args.test_dataset == \"CIFAR10\":\n",
    "            train_dataset = torchvision.datasets.CIFAR10(\n",
    "                args.dataset_dir,\n",
    "                train=True,\n",
    "                download=True,\n",
    "                transform=TransformsRelic(size=args.image_size).test_transform,\n",
    "            )\n",
    "            test_dataset = torchvision.datasets.CIFAR10(\n",
    "                args.dataset_dir,\n",
    "                train=False,\n",
    "                download=True,\n",
    "                transform=TransformsRelic(size=args.image_size).test_transform,\n",
    "            )\n",
    "        else:\n",
    "            raise NotImplementedError       \n",
    "\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=args.logistic_batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        num_workers=args.workers,\n",
    "    )\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=args.logistic_batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=True,\n",
    "        num_workers=args.workers,\n",
    "    )\n",
    "\n",
    "    encoder = get_resnet(args.resnet, pretrained=False)\n",
    "    n_features = encoder.fc.in_features  # get dimensions of fc layer\n",
    "\n",
    "    # load pre-trained model from checkpoint\n",
    "    if args.relic ==  False:\n",
    "        simclr_model = SimCLR(encoder, args.projection_dim, n_features)\n",
    "        model_fp = os.path.join(args.model_path, \"checkpoint_{}.tar\".format(args.epoch_num))\n",
    "        simclr_model.load_state_dict(torch.load(model_fp, map_location=args.device.type))\n",
    "        simclr_model = simclr_model.to(args.device)\n",
    "        simclr_model.eval()\n",
    "\n",
    "        ## Logistic Regression\n",
    "        n_classes = 10  # CIFAR-10 / STL-10\n",
    "        model = LogisticRegression(simclr_model.n_features, n_classes)\n",
    "        model = model.to(args.device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        print(\"### Creating features from pre-trained context model ###\")\n",
    "        (train_X, train_y, test_X, test_y) = get_features(\n",
    "            simclr_model, train_loader, test_loader, args.device, args.relic\n",
    "        )\n",
    "\n",
    "        arr_train_loader, arr_test_loader = create_data_loaders_from_arrays(\n",
    "            train_X, train_y, test_X, test_y, args.logistic_batch_size\n",
    "        )\n",
    "\n",
    "        for epoch in range(args.logistic_epochs):\n",
    "            loss_epoch, accuracy_epoch = train(\n",
    "                args, arr_train_loader, simclr_model, model, criterion, optimizer\n",
    "            )\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{args.logistic_epochs}]\\t Loss: {loss_epoch / len(arr_train_loader)}\\t Accuracy: {accuracy_epoch / len(arr_train_loader)}\"\n",
    "            )\n",
    "\n",
    "        # final testing\n",
    "        loss_epoch, accuracy_epoch = test(\n",
    "            args, arr_test_loader, simclr_model, model, criterion, optimizer\n",
    "        )\n",
    "        print(\n",
    "            f\"[FINAL]\\t Loss: {loss_epoch / len(arr_test_loader)}\\t Accuracy: {accuracy_epoch / len(arr_test_loader)}\"\n",
    "        )\n",
    "\n",
    "    #[TODO - ADDED] ReLIC\n",
    "    if args.relic == True:\n",
    "        relic_model = ReLIC(encoder, args.projection_dim, n_features)\n",
    "        model_fp = os.path.join(args.model_path, \"checkpoint_{}.tar\".format(args.epoch_num))\n",
    "        relic_model.load_state_dict(torch.load(model_fp, map_location=args.device.type))\n",
    "\n",
    "        #[TODO] JUST USE ENCODER PART ###CAUTION\n",
    "        #saved_n_features= relic_model.n_features\n",
    "        #relic_model= relic_model.encoder\n",
    "\n",
    "        relic_model = relic_model.to(args.device)\n",
    "        relic_model.eval()\n",
    "\n",
    "        \n",
    "\n",
    "        ## Logistic Regression\n",
    "        n_classes = 10  # CIFAR-10 / STL-10\n",
    "        #[TODO] JUST USE ENCODER PART ### CAUTION / OR USE Smaller Model (args.projection_dim)\n",
    "        #model = LogisticRegression(args.projection_dim, n_classes)\n",
    "        \n",
    "        model = LogisticRegression(relic_model.n_features, n_classes) #(relic_model.n_features, n_classes)= (512,10)\n",
    "        model = model.to(args.device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        print(\"### Creating features from pre-trained context model ###\")\n",
    "        (train_X, train_y, test_X, test_y) = get_features(\n",
    "            relic_model, train_loader, test_loader, args.device, args.relic\n",
    "        )\n",
    "\n",
    "        arr_train_loader, arr_test_loader = create_data_loaders_from_arrays(\n",
    "            train_X, train_y, test_X, test_y, args.logistic_batch_size\n",
    "        )\n",
    "\n",
    "        for epoch in range(args.logistic_epochs):\n",
    "            loss_epoch, accuracy_epoch = train(\n",
    "                args, arr_train_loader, relic_model, model, criterion, optimizer\n",
    "            )\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{args.logistic_epochs}]\\t Loss: {loss_epoch / len(arr_train_loader)}\\t Accuracy: {accuracy_epoch / len(arr_train_loader)}\"\n",
    "            )\n",
    "\n",
    "        # final testing\n",
    "        loss_epoch, accuracy_epoch = test(\n",
    "            args, arr_test_loader, relic_model, model, criterion, optimizer\n",
    "        )\n",
    "        print(\n",
    "            f\"[FINAL]\\t Loss: {loss_epoch / len(arr_test_loader)}\\t Accuracy: {accuracy_epoch / len(arr_test_loader)}\"\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c69b165e-05b8-4070-842a-6cae60bc00f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.test_dataset = 'STL10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e11a4c3-da63-4d87-9aab-f087fde518ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.relic= True\n",
    "args.projection_dim= 64\n",
    "args.model_path= 'save/relic/300'\n",
    "args.epoch_num= 220"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0126e51c-b3f7-47d2-becd-8ee0068570fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLIC -- True\n",
      "Model From -- save/relic/300, Epoch: 220\n",
      "All Evaluation args --  Namespace(nodes=1, gpus=1, nr=0, dataparallel=0, workers=8, dataset_dir='./datasets', seed=42, batch_size=128, image_size=224, start_epoch=0, epochs=100, dataset='CIFAR10', test_dataset='STL10', pacs_style='default', pretrain=False, relic=True, relic_normalize=True, relic_temp=1.0, relic_alpha=0.5, resnet='resnet18', projection_dim=64, optimizer='LARS', weight_decay=1e-06, temperature=0.5, model_path='save/relic/300', epoch_num=220, reload=False, logistic_batch_size=256, logistic_epochs=500, device=device(type='cuda', index=0), num_gpus=4, world_size=1)\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/simclr/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/simclr/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Creating features from pre-trained context model ###\n",
      "Step [0/19]\t Computing features...\n",
      "Features shape (4864, 512)\n",
      "Step [0/31]\t Computing features...\n",
      "Step [20/31]\t Computing features...\n",
      "Features shape (7936, 512)\n",
      "Epoch [0/500]\t Loss: 2.2047311883223686\t Accuracy: 0.20374177631578946\n",
      "Epoch [1/500]\t Loss: 1.8820405194633885\t Accuracy: 0.42475328947368424\n",
      "Epoch [2/500]\t Loss: 1.6696390729201467\t Accuracy: 0.5098684210526315\n",
      "Epoch [3/500]\t Loss: 1.534337319825825\t Accuracy: 0.536389802631579\n",
      "Epoch [4/500]\t Loss: 1.4410598842721236\t Accuracy: 0.5569490131578947\n",
      "Epoch [5/500]\t Loss: 1.3733746942720915\t Accuracy: 0.569078947368421\n",
      "Epoch [6/500]\t Loss: 1.321794309114155\t Accuracy: 0.5773026315789473\n",
      "Epoch [7/500]\t Loss: 1.28088935425407\t Accuracy: 0.5834703947368421\n",
      "Epoch [8/500]\t Loss: 1.247501580338729\t Accuracy: 0.5896381578947368\n",
      "Epoch [9/500]\t Loss: 1.219613746592873\t Accuracy: 0.5943667763157895\n",
      "Epoch [10/500]\t Loss: 1.1958767301157902\t Accuracy: 0.5980674342105263\n",
      "Epoch [11/500]\t Loss: 1.1753612380278737\t Accuracy: 0.6023848684210527\n",
      "Epoch [12/500]\t Loss: 1.1573992779380398\t Accuracy: 0.606702302631579\n",
      "Epoch [13/500]\t Loss: 1.141498521754616\t Accuracy: 0.6085526315789473\n",
      "Epoch [14/500]\t Loss: 1.1272881344745034\t Accuracy: 0.6126644736842105\n",
      "Epoch [15/500]\t Loss: 1.1144826537684391\t Accuracy: 0.615953947368421\n",
      "Epoch [16/500]\t Loss: 1.1028587190728438\t Accuracy: 0.6186266447368421\n",
      "Epoch [17/500]\t Loss: 1.0922389406906932\t Accuracy: 0.6200657894736842\n",
      "Epoch [18/500]\t Loss: 1.0824805811831826\t Accuracy: 0.6231496710526315\n",
      "Epoch [19/500]\t Loss: 1.0734673362029226\t Accuracy: 0.6256167763157895\n",
      "Epoch [20/500]\t Loss: 1.0651034901016636\t Accuracy: 0.6278782894736842\n",
      "Epoch [21/500]\t Loss: 1.0573096181216992\t Accuracy: 0.6303453947368421\n",
      "Epoch [22/500]\t Loss: 1.0500189818834003\t Accuracy: 0.6332236842105263\n",
      "Epoch [23/500]\t Loss: 1.0431753679325706\t Accuracy: 0.6348684210526315\n",
      "Epoch [24/500]\t Loss: 1.036730894916936\t Accuracy: 0.6356907894736842\n",
      "Epoch [25/500]\t Loss: 1.030644416809082\t Accuracy: 0.6385690789473685\n",
      "Epoch [26/500]\t Loss: 1.0248807072639465\t Accuracy: 0.640625\n",
      "Epoch [27/500]\t Loss: 1.0194089663656134\t Accuracy: 0.6410361842105263\n",
      "Epoch [28/500]\t Loss: 1.01420259475708\t Accuracy: 0.6435032894736842\n",
      "Epoch [29/500]\t Loss: 1.0092381521275169\t Accuracy: 0.64453125\n",
      "Epoch [30/500]\t Loss: 1.0044950435036106\t Accuracy: 0.6461759868421053\n",
      "Epoch [31/500]\t Loss: 0.9999551616216961\t Accuracy: 0.647203947368421\n",
      "Epoch [32/500]\t Loss: 0.9956023002925672\t Accuracy: 0.6478207236842105\n",
      "Epoch [33/500]\t Loss: 0.9914221481273049\t Accuracy: 0.6484375\n",
      "Epoch [34/500]\t Loss: 0.9874018367968107\t Accuracy: 0.6498766447368421\n",
      "Epoch [35/500]\t Loss: 0.9835298939755088\t Accuracy: 0.6506990131578947\n",
      "Epoch [36/500]\t Loss: 0.9797959923744202\t Accuracy: 0.6515213815789473\n",
      "Epoch [37/500]\t Loss: 0.9761907207338434\t Accuracy: 0.6527549342105263\n",
      "Epoch [38/500]\t Loss: 0.9727057093068173\t Accuracy: 0.653577302631579\n",
      "Epoch [39/500]\t Loss: 0.9693332565458197\t Accuracy: 0.6552220394736842\n",
      "Epoch [40/500]\t Loss: 0.9660663887074119\t Accuracy: 0.6570723684210527\n",
      "Epoch [41/500]\t Loss: 0.9628987908363342\t Accuracy: 0.6583059210526315\n",
      "Epoch [42/500]\t Loss: 0.9598245432502345\t Accuracy: 0.6597450657894737\n",
      "Epoch [43/500]\t Loss: 0.9568384164258054\t Accuracy: 0.6618009868421053\n",
      "Epoch [44/500]\t Loss: 0.9539354725887901\t Accuracy: 0.6632401315789473\n",
      "Epoch [45/500]\t Loss: 0.9511112664875231\t Accuracy: 0.6634457236842105\n",
      "Epoch [46/500]\t Loss: 0.9483615191359269\t Accuracy: 0.6642680921052632\n",
      "Epoch [47/500]\t Loss: 0.9456825319089388\t Accuracy: 0.6644736842105263\n",
      "Epoch [48/500]\t Loss: 0.9430706783344871\t Accuracy: 0.6648848684210527\n",
      "Epoch [49/500]\t Loss: 0.940522711527975\t Accuracy: 0.6659128289473685\n",
      "Epoch [50/500]\t Loss: 0.9380355477333069\t Accuracy: 0.6665296052631579\n",
      "Epoch [51/500]\t Loss: 0.9356063039679277\t Accuracy: 0.66796875\n",
      "Epoch [52/500]\t Loss: 0.9332323701758134\t Accuracy: 0.66796875\n",
      "Epoch [53/500]\t Loss: 0.9309112868810955\t Accuracy: 0.66796875\n",
      "Epoch [54/500]\t Loss: 0.9286406667608964\t Accuracy: 0.6681743421052632\n",
      "Epoch [55/500]\t Loss: 0.9264184048301295\t Accuracy: 0.6681743421052632\n",
      "Epoch [56/500]\t Loss: 0.9242424400229203\t Accuracy: 0.6696134868421053\n",
      "Epoch [57/500]\t Loss: 0.9221109120469344\t Accuracy: 0.6704358552631579\n",
      "Epoch [58/500]\t Loss: 0.9200219480614913\t Accuracy: 0.670641447368421\n",
      "Epoch [59/500]\t Loss: 0.9179738822736239\t Accuracy: 0.6708470394736842\n",
      "Epoch [60/500]\t Loss: 0.9159651147691827\t Accuracy: 0.6712582236842105\n",
      "Epoch [61/500]\t Loss: 0.9139942181737799\t Accuracy: 0.6716694078947368\n",
      "Epoch [62/500]\t Loss: 0.9120597337421618\t Accuracy: 0.6726973684210527\n",
      "Epoch [63/500]\t Loss: 0.9101602905674985\t Accuracy: 0.673108552631579\n",
      "Epoch [64/500]\t Loss: 0.9082946275409899\t Accuracy: 0.6729029605263158\n",
      "Epoch [65/500]\t Loss: 0.9064615713922601\t Accuracy: 0.6726973684210527\n",
      "Epoch [66/500]\t Loss: 0.9046599833588851\t Accuracy: 0.6735197368421053\n",
      "Epoch [67/500]\t Loss: 0.9028887842830858\t Accuracy: 0.6737253289473685\n",
      "Epoch [68/500]\t Loss: 0.901146882458737\t Accuracy: 0.6739309210526315\n",
      "Epoch [69/500]\t Loss: 0.8994333555823878\t Accuracy: 0.6737253289473685\n",
      "Epoch [70/500]\t Loss: 0.8977473221327129\t Accuracy: 0.6747532894736842\n",
      "Epoch [71/500]\t Loss: 0.8960878284353959\t Accuracy: 0.6766036184210527\n",
      "Epoch [72/500]\t Loss: 0.8944539961061979\t Accuracy: 0.6772203947368421\n",
      "Epoch [73/500]\t Loss: 0.892845072244343\t Accuracy: 0.6776315789473685\n",
      "Epoch [74/500]\t Loss: 0.8912603698278728\t Accuracy: 0.6786595394736842\n",
      "Epoch [75/500]\t Loss: 0.8896990292950681\t Accuracy: 0.6805098684210527\n",
      "Epoch [76/500]\t Loss: 0.8881604044060958\t Accuracy: 0.680921052631579\n",
      "Epoch [77/500]\t Loss: 0.8866437799052188\t Accuracy: 0.6817434210526315\n",
      "Epoch [78/500]\t Loss: 0.8851485722943356\t Accuracy: 0.6821546052631579\n",
      "Epoch [79/500]\t Loss: 0.8836741510190462\t Accuracy: 0.6829769736842105\n",
      "Epoch [80/500]\t Loss: 0.8822199325812491\t Accuracy: 0.6833881578947368\n",
      "Epoch [81/500]\t Loss: 0.8807852927007174\t Accuracy: 0.68359375\n",
      "Epoch [82/500]\t Loss: 0.8793697796369854\t Accuracy: 0.6840049342105263\n",
      "Epoch [83/500]\t Loss: 0.8779728255773845\t Accuracy: 0.6854440789473685\n",
      "Epoch [84/500]\t Loss: 0.8765939411364103\t Accuracy: 0.6856496710526315\n",
      "Epoch [85/500]\t Loss: 0.8752326432027315\t Accuracy: 0.6858552631578947\n",
      "Epoch [86/500]\t Loss: 0.8738884800358823\t Accuracy: 0.686266447368421\n",
      "Epoch [87/500]\t Loss: 0.8725610187179164\t Accuracy: 0.6868832236842105\n",
      "Epoch [88/500]\t Loss: 0.8712498012341952\t Accuracy: 0.6877055921052632\n",
      "Epoch [89/500]\t Loss: 0.8699544072151184\t Accuracy: 0.6885279605263158\n",
      "Epoch [90/500]\t Loss: 0.8686745135407699\t Accuracy: 0.6891447368421053\n",
      "Epoch [91/500]\t Loss: 0.8674096621965107\t Accuracy: 0.6893503289473685\n",
      "Epoch [92/500]\t Loss: 0.8661595582962036\t Accuracy: 0.690172697368421\n",
      "Epoch [93/500]\t Loss: 0.8649237657848158\t Accuracy: 0.6905838815789473\n",
      "Epoch [94/500]\t Loss: 0.8637020180099889\t Accuracy: 0.6907894736842105\n",
      "Epoch [95/500]\t Loss: 0.862493938521335\t Accuracy: 0.6905838815789473\n",
      "Epoch [96/500]\t Loss: 0.8612992543923227\t Accuracy: 0.6916118421052632\n",
      "Epoch [97/500]\t Loss: 0.8601175797613043\t Accuracy: 0.6922286184210527\n",
      "Epoch [98/500]\t Loss: 0.858948710717653\t Accuracy: 0.6928453947368421\n",
      "Epoch [99/500]\t Loss: 0.8577922896335\t Accuracy: 0.6936677631578947\n",
      "Epoch [100/500]\t Loss: 0.8566480875015259\t Accuracy: 0.6936677631578947\n",
      "Epoch [101/500]\t Loss: 0.8555158094355935\t Accuracy: 0.694078947368421\n",
      "Epoch [102/500]\t Loss: 0.8543952201542101\t Accuracy: 0.6936677631578947\n",
      "Epoch [103/500]\t Loss: 0.8532860373195849\t Accuracy: 0.6949013157894737\n",
      "Epoch [104/500]\t Loss: 0.8521880036906192\t Accuracy: 0.6959292763157895\n",
      "Epoch [105/500]\t Loss: 0.8511009498646385\t Accuracy: 0.6963404605263158\n",
      "Epoch [106/500]\t Loss: 0.8500245966409382\t Accuracy: 0.6963404605263158\n",
      "Epoch [107/500]\t Loss: 0.8489587934393632\t Accuracy: 0.6969572368421053\n",
      "Epoch [108/500]\t Loss: 0.8479032108658239\t Accuracy: 0.6973684210526315\n",
      "Epoch [109/500]\t Loss: 0.8468577140255978\t Accuracy: 0.697985197368421\n",
      "Epoch [110/500]\t Loss: 0.8458220770484522\t Accuracy: 0.6981907894736842\n",
      "Epoch [111/500]\t Loss: 0.8447961368058857\t Accuracy: 0.6986019736842105\n",
      "Epoch [112/500]\t Loss: 0.8437797270323101\t Accuracy: 0.6990131578947368\n",
      "Epoch [113/500]\t Loss: 0.8427725497045016\t Accuracy: 0.69921875\n",
      "Epoch [114/500]\t Loss: 0.841774510709863\t Accuracy: 0.6990131578947368\n",
      "Epoch [115/500]\t Loss: 0.8407854626053258\t Accuracy: 0.6994243421052632\n",
      "Epoch [116/500]\t Loss: 0.8398051826577437\t Accuracy: 0.7000411184210527\n",
      "Epoch [117/500]\t Loss: 0.8388335077386153\t Accuracy: 0.6996299342105263\n",
      "Epoch [118/500]\t Loss: 0.837870318638651\t Accuracy: 0.6998355263157895\n",
      "Epoch [119/500]\t Loss: 0.8369154145843104\t Accuracy: 0.7002467105263158\n",
      "Epoch [120/500]\t Loss: 0.8359686795033907\t Accuracy: 0.7008634868421053\n",
      "Epoch [121/500]\t Loss: 0.8350299345819574\t Accuracy: 0.7012746710526315\n",
      "Epoch [122/500]\t Loss: 0.8340990574736344\t Accuracy: 0.7020970394736842\n",
      "Epoch [123/500]\t Loss: 0.8331759195578726\t Accuracy: 0.7027138157894737\n",
      "Epoch [124/500]\t Loss: 0.8322603765286898\t Accuracy: 0.7029194078947368\n",
      "Epoch [125/500]\t Loss: 0.8313523091767964\t Accuracy: 0.7037417763157895\n",
      "Epoch [126/500]\t Loss: 0.8304515512366044\t Accuracy: 0.704358552631579\n",
      "Epoch [127/500]\t Loss: 0.8295580085955168\t Accuracy: 0.7045641447368421\n",
      "Epoch [128/500]\t Loss: 0.8286715871409366\t Accuracy: 0.7047697368421053\n",
      "Epoch [129/500]\t Loss: 0.82779208923641\t Accuracy: 0.704358552631579\n",
      "Epoch [130/500]\t Loss: 0.8269194552772924\t Accuracy: 0.7039473684210527\n",
      "Epoch [131/500]\t Loss: 0.826053544094688\t Accuracy: 0.704358552631579\n",
      "Epoch [132/500]\t Loss: 0.8251943274548179\t Accuracy: 0.7049753289473685\n",
      "Epoch [133/500]\t Loss: 0.8243415951728821\t Accuracy: 0.7051809210526315\n",
      "Epoch [134/500]\t Loss: 0.8234953158780148\t Accuracy: 0.7055921052631579\n",
      "Epoch [135/500]\t Loss: 0.8226553170304549\t Accuracy: 0.7060032894736842\n",
      "Epoch [136/500]\t Loss: 0.8218215641222502\t Accuracy: 0.7062088815789473\n",
      "Epoch [137/500]\t Loss: 0.820993931669938\t Accuracy: 0.7068256578947368\n",
      "Epoch [138/500]\t Loss: 0.8201723098754883\t Accuracy: 0.70703125\n",
      "Epoch [139/500]\t Loss: 0.8193566234488237\t Accuracy: 0.7072368421052632\n",
      "Epoch [140/500]\t Loss: 0.8185468316078186\t Accuracy: 0.70703125\n",
      "Epoch [141/500]\t Loss: 0.8177426927968076\t Accuracy: 0.70703125\n",
      "Epoch [142/500]\t Loss: 0.8169443513217726\t Accuracy: 0.70703125\n",
      "Epoch [143/500]\t Loss: 0.8161515154336628\t Accuracy: 0.7068256578947368\n",
      "Epoch [144/500]\t Loss: 0.8153642290516904\t Accuracy: 0.7072368421052632\n",
      "Epoch [145/500]\t Loss: 0.8145823541440462\t Accuracy: 0.7076480263157895\n",
      "Epoch [146/500]\t Loss: 0.8138058185577393\t Accuracy: 0.7074424342105263\n",
      "Epoch [147/500]\t Loss: 0.8130345626881248\t Accuracy: 0.7080592105263158\n",
      "Epoch [148/500]\t Loss: 0.8122684798742595\t Accuracy: 0.7084703947368421\n",
      "Epoch [149/500]\t Loss: 0.8115075387452778\t Accuracy: 0.7086759868421053\n",
      "Epoch [150/500]\t Loss: 0.810751642051496\t Accuracy: 0.7092927631578947\n",
      "Epoch [151/500]\t Loss: 0.8100006925432306\t Accuracy: 0.7088815789473685\n",
      "Epoch [152/500]\t Loss: 0.8092547278655203\t Accuracy: 0.7092927631578947\n",
      "Epoch [153/500]\t Loss: 0.8085135472448248\t Accuracy: 0.709703947368421\n",
      "Epoch [154/500]\t Loss: 0.8077771381327981\t Accuracy: 0.7101151315789473\n",
      "Epoch [155/500]\t Loss: 0.8070454691585741\t Accuracy: 0.7101151315789473\n",
      "Epoch [156/500]\t Loss: 0.8063184493466428\t Accuracy: 0.7103207236842105\n",
      "Epoch [157/500]\t Loss: 0.8055960096810993\t Accuracy: 0.7107319078947368\n",
      "Epoch [158/500]\t Loss: 0.8048780591864335\t Accuracy: 0.7111430921052632\n",
      "Epoch [159/500]\t Loss: 0.8041646198222512\t Accuracy: 0.7115542763157895\n",
      "Epoch [160/500]\t Loss: 0.8034555661050897\t Accuracy: 0.7117598684210527\n",
      "Epoch [161/500]\t Loss: 0.8027508541157371\t Accuracy: 0.7117598684210527\n",
      "Epoch [162/500]\t Loss: 0.8020504305237218\t Accuracy: 0.7117598684210527\n",
      "Epoch [163/500]\t Loss: 0.8013543110144766\t Accuracy: 0.7123766447368421\n",
      "Epoch [164/500]\t Loss: 0.8006623418707597\t Accuracy: 0.7123766447368421\n",
      "Epoch [165/500]\t Loss: 0.7999744979958785\t Accuracy: 0.7127878289473685\n",
      "Epoch [166/500]\t Loss: 0.7992907072368421\t Accuracy: 0.7129934210526315\n",
      "Epoch [167/500]\t Loss: 0.7986109758678236\t Accuracy: 0.7131990131578947\n",
      "Epoch [168/500]\t Loss: 0.7979352191874856\t Accuracy: 0.713610197368421\n",
      "Epoch [169/500]\t Loss: 0.797263387002443\t Accuracy: 0.7140213815789473\n",
      "Epoch [170/500]\t Loss: 0.7965954510789168\t Accuracy: 0.7142269736842105\n",
      "Epoch [171/500]\t Loss: 0.795931383183128\t Accuracy: 0.7142269736842105\n",
      "Epoch [172/500]\t Loss: 0.7952710735170465\t Accuracy: 0.7144325657894737\n",
      "Epoch [173/500]\t Loss: 0.7946144907098067\t Accuracy: 0.7146381578947368\n",
      "Epoch [174/500]\t Loss: 0.7939616065276297\t Accuracy: 0.71484375\n",
      "Epoch [175/500]\t Loss: 0.7933124209705152\t Accuracy: 0.7150493421052632\n",
      "Epoch [176/500]\t Loss: 0.7926667960066545\t Accuracy: 0.7144325657894737\n",
      "Epoch [177/500]\t Loss: 0.7920247912406921\t Accuracy: 0.7152549342105263\n",
      "Epoch [178/500]\t Loss: 0.7913862874633387\t Accuracy: 0.7154605263157895\n",
      "Epoch [179/500]\t Loss: 0.7907512815375077\t Accuracy: 0.7154605263157895\n",
      "Epoch [180/500]\t Loss: 0.7901197766002855\t Accuracy: 0.7154605263157895\n",
      "Epoch [181/500]\t Loss: 0.7894916063860843\t Accuracy: 0.7156661184210527\n",
      "Epoch [182/500]\t Loss: 0.7888668367737218\t Accuracy: 0.7156661184210527\n",
      "Epoch [183/500]\t Loss: 0.788245395610207\t Accuracy: 0.7156661184210527\n",
      "Epoch [184/500]\t Loss: 0.7876272483875877\t Accuracy: 0.7156661184210527\n",
      "Epoch [185/500]\t Loss: 0.7870123511866519\t Accuracy: 0.716077302631579\n",
      "Epoch [186/500]\t Loss: 0.7864007353782654\t Accuracy: 0.7162828947368421\n",
      "Epoch [187/500]\t Loss: 0.7857922723418788\t Accuracy: 0.7166940789473685\n",
      "Epoch [188/500]\t Loss: 0.7851869589404056\t Accuracy: 0.7173108552631579\n",
      "Epoch [189/500]\t Loss: 0.7845848014480189\t Accuracy: 0.7179276315789473\n",
      "Epoch [190/500]\t Loss: 0.7839856649699964\t Accuracy: 0.7179276315789473\n",
      "Epoch [191/500]\t Loss: 0.7833896310705888\t Accuracy: 0.7181332236842105\n",
      "Epoch [192/500]\t Loss: 0.7827966181855452\t Accuracy: 0.7183388157894737\n",
      "Epoch [193/500]\t Loss: 0.7822065572989615\t Accuracy: 0.71875\n",
      "Epoch [194/500]\t Loss: 0.7816195080154821\t Accuracy: 0.7189555921052632\n",
      "Epoch [195/500]\t Loss: 0.7810353417145578\t Accuracy: 0.7195723684210527\n",
      "Epoch [196/500]\t Loss: 0.7804541305491799\t Accuracy: 0.7206003289473685\n",
      "Epoch [197/500]\t Loss: 0.7798757113908467\t Accuracy: 0.7216282894736842\n",
      "Epoch [198/500]\t Loss: 0.7793001971746746\t Accuracy: 0.7216282894736842\n",
      "Epoch [199/500]\t Loss: 0.7787274561430279\t Accuracy: 0.7222450657894737\n",
      "Epoch [200/500]\t Loss: 0.7781574600621274\t Accuracy: 0.7222450657894737\n",
      "Epoch [201/500]\t Loss: 0.7775902716737044\t Accuracy: 0.7228618421052632\n",
      "Epoch [202/500]\t Loss: 0.7770258062764218\t Accuracy: 0.7232730263157895\n",
      "Epoch [203/500]\t Loss: 0.77646404504776\t Accuracy: 0.7232730263157895\n",
      "Epoch [204/500]\t Loss: 0.7759048750526026\t Accuracy: 0.7232730263157895\n",
      "Epoch [205/500]\t Loss: 0.7753484374598453\t Accuracy: 0.7234786184210527\n",
      "Epoch [206/500]\t Loss: 0.7747946005118521\t Accuracy: 0.7236842105263158\n",
      "Epoch [207/500]\t Loss: 0.7742432638218528\t Accuracy: 0.723889802631579\n",
      "Epoch [208/500]\t Loss: 0.7736945967925223\t Accuracy: 0.723889802631579\n",
      "Epoch [209/500]\t Loss: 0.7731484457066184\t Accuracy: 0.7236842105263158\n",
      "Epoch [210/500]\t Loss: 0.772604829386661\t Accuracy: 0.7236842105263158\n",
      "Epoch [211/500]\t Loss: 0.7720636599942258\t Accuracy: 0.7234786184210527\n",
      "Epoch [212/500]\t Loss: 0.7715249877226981\t Accuracy: 0.7234786184210527\n",
      "Epoch [213/500]\t Loss: 0.7709887561045194\t Accuracy: 0.7236842105263158\n",
      "Epoch [214/500]\t Loss: 0.7704549714138633\t Accuracy: 0.723889802631579\n",
      "Epoch [215/500]\t Loss: 0.7699235520864788\t Accuracy: 0.7240953947368421\n",
      "Epoch [216/500]\t Loss: 0.7693945294932315\t Accuracy: 0.7243009868421053\n",
      "Epoch [217/500]\t Loss: 0.7688678408923902\t Accuracy: 0.7247121710526315\n",
      "Epoch [218/500]\t Loss: 0.7683434831468683\t Accuracy: 0.7247121710526315\n",
      "Epoch [219/500]\t Loss: 0.7678215033129642\t Accuracy: 0.7247121710526315\n",
      "Epoch [220/500]\t Loss: 0.7673017821813884\t Accuracy: 0.725328947368421\n",
      "Epoch [221/500]\t Loss: 0.7667843166150545\t Accuracy: 0.7259457236842105\n",
      "Epoch [222/500]\t Loss: 0.7662691034768757\t Accuracy: 0.7263569078947368\n",
      "Epoch [223/500]\t Loss: 0.7657561176701596\t Accuracy: 0.7265625\n",
      "Epoch [224/500]\t Loss: 0.7652452964531747\t Accuracy: 0.7265625\n",
      "Epoch [225/500]\t Loss: 0.7647367245272586\t Accuracy: 0.7269736842105263\n",
      "Epoch [226/500]\t Loss: 0.764230307779814\t Accuracy: 0.7271792763157895\n",
      "Epoch [227/500]\t Loss: 0.763725996017456\t Accuracy: 0.7273848684210527\n",
      "Epoch [228/500]\t Loss: 0.7632238927640413\t Accuracy: 0.7275904605263158\n",
      "Epoch [229/500]\t Loss: 0.7627238254798087\t Accuracy: 0.727796052631579\n",
      "Epoch [230/500]\t Loss: 0.7622259290594804\t Accuracy: 0.7280016447368421\n",
      "Epoch [231/500]\t Loss: 0.7617300811566805\t Accuracy: 0.7282072368421053\n",
      "Epoch [232/500]\t Loss: 0.7612362535376298\t Accuracy: 0.7280016447368421\n",
      "Epoch [233/500]\t Loss: 0.7607445120811462\t Accuracy: 0.7282072368421053\n",
      "Epoch [234/500]\t Loss: 0.7602547783600656\t Accuracy: 0.7286184210526315\n",
      "Epoch [235/500]\t Loss: 0.7597670492373014\t Accuracy: 0.7290296052631579\n",
      "Epoch [236/500]\t Loss: 0.7592813215757671\t Accuracy: 0.729235197368421\n",
      "Epoch [237/500]\t Loss: 0.7587975326337313\t Accuracy: 0.729235197368421\n",
      "Epoch [238/500]\t Loss: 0.7583157702496177\t Accuracy: 0.7294407894736842\n",
      "Epoch [239/500]\t Loss: 0.7578358556094923\t Accuracy: 0.7294407894736842\n",
      "Epoch [240/500]\t Loss: 0.7573579204709906\t Accuracy: 0.7294407894736842\n",
      "Epoch [241/500]\t Loss: 0.7568818487619099\t Accuracy: 0.7300575657894737\n",
      "Epoch [242/500]\t Loss: 0.7564076906756351\t Accuracy: 0.73046875\n",
      "Epoch [243/500]\t Loss: 0.7559354085671274\t Accuracy: 0.7310855263157895\n",
      "Epoch [244/500]\t Loss: 0.7554649804767809\t Accuracy: 0.7312911184210527\n",
      "Epoch [245/500]\t Loss: 0.7549964220900285\t Accuracy: 0.7312911184210527\n",
      "Epoch [246/500]\t Loss: 0.7545296894876581\t Accuracy: 0.7314967105263158\n",
      "Epoch [247/500]\t Loss: 0.7540647230650249\t Accuracy: 0.7314967105263158\n",
      "Epoch [248/500]\t Loss: 0.753601588700947\t Accuracy: 0.731702302631579\n",
      "Epoch [249/500]\t Loss: 0.7531402644358183\t Accuracy: 0.731702302631579\n",
      "Epoch [250/500]\t Loss: 0.7526807126246\t Accuracy: 0.731702302631579\n",
      "Epoch [251/500]\t Loss: 0.7522228830739072\t Accuracy: 0.731702302631579\n",
      "Epoch [252/500]\t Loss: 0.7517668197029516\t Accuracy: 0.7319078947368421\n",
      "Epoch [253/500]\t Loss: 0.7513124503587422\t Accuracy: 0.7319078947368421\n",
      "Epoch [254/500]\t Loss: 0.7508598158234044\t Accuracy: 0.7319078947368421\n",
      "Epoch [255/500]\t Loss: 0.7504088627664667\t Accuracy: 0.7321134868421053\n",
      "Epoch [256/500]\t Loss: 0.749959625695881\t Accuracy: 0.7323190789473685\n",
      "Epoch [257/500]\t Loss: 0.7495120920633015\t Accuracy: 0.7327302631578947\n",
      "Epoch [258/500]\t Loss: 0.7490661834415636\t Accuracy: 0.733141447368421\n",
      "Epoch [259/500]\t Loss: 0.7486219029677542\t Accuracy: 0.7333470394736842\n",
      "Epoch [260/500]\t Loss: 0.7481793071094313\t Accuracy: 0.7333470394736842\n",
      "Epoch [261/500]\t Loss: 0.7477383268506903\t Accuracy: 0.7333470394736842\n",
      "Epoch [262/500]\t Loss: 0.7472989308206659\t Accuracy: 0.7339638157894737\n",
      "Epoch [263/500]\t Loss: 0.7468611723498294\t Accuracy: 0.7345805921052632\n",
      "Epoch [264/500]\t Loss: 0.7464249667368437\t Accuracy: 0.7345805921052632\n",
      "Epoch [265/500]\t Loss: 0.745990326530055\t Accuracy: 0.7347861842105263\n",
      "Epoch [266/500]\t Loss: 0.7455573019228483\t Accuracy: 0.7347861842105263\n",
      "Epoch [267/500]\t Loss: 0.7451258144880596\t Accuracy: 0.7347861842105263\n",
      "Epoch [268/500]\t Loss: 0.7446958516773424\t Accuracy: 0.7349917763157895\n",
      "Epoch [269/500]\t Loss: 0.7442673946681776\t Accuracy: 0.7354029605263158\n",
      "Epoch [270/500]\t Loss: 0.7438404967910365\t Accuracy: 0.7351973684210527\n",
      "Epoch [271/500]\t Loss: 0.743415145497573\t Accuracy: 0.7354029605263158\n",
      "Epoch [272/500]\t Loss: 0.7429911776592857\t Accuracy: 0.7358141447368421\n",
      "Epoch [273/500]\t Loss: 0.7425687720901087\t Accuracy: 0.7360197368421053\n",
      "Epoch [274/500]\t Loss: 0.7421477970324064\t Accuracy: 0.7362253289473685\n",
      "Epoch [275/500]\t Loss: 0.7417283340504295\t Accuracy: 0.7362253289473685\n",
      "Epoch [276/500]\t Loss: 0.7413102827574077\t Accuracy: 0.7360197368421053\n",
      "Epoch [277/500]\t Loss: 0.7408936776612934\t Accuracy: 0.7362253289473685\n",
      "Epoch [278/500]\t Loss: 0.7404784842541343\t Accuracy: 0.7368421052631579\n",
      "Epoch [279/500]\t Loss: 0.7400647746889215\t Accuracy: 0.737047697368421\n",
      "Epoch [280/500]\t Loss: 0.7396524674014041\t Accuracy: 0.7374588815789473\n",
      "Epoch [281/500]\t Loss: 0.7392415278836301\t Accuracy: 0.7374588815789473\n",
      "Epoch [282/500]\t Loss: 0.7388320031918978\t Accuracy: 0.7378700657894737\n",
      "Epoch [283/500]\t Loss: 0.7384238180361296\t Accuracy: 0.7378700657894737\n",
      "Epoch [284/500]\t Loss: 0.7380170665289226\t Accuracy: 0.7378700657894737\n",
      "Epoch [285/500]\t Loss: 0.7376116545576799\t Accuracy: 0.7380756578947368\n",
      "Epoch [286/500]\t Loss: 0.7372075695740549\t Accuracy: 0.73828125\n",
      "Epoch [287/500]\t Loss: 0.736804839811827\t Accuracy: 0.7384868421052632\n",
      "Epoch [288/500]\t Loss: 0.7364034495855633\t Accuracy: 0.7388980263157895\n",
      "Epoch [289/500]\t Loss: 0.7360033988952637\t Accuracy: 0.7388980263157895\n",
      "Epoch [290/500]\t Loss: 0.7356046312733701\t Accuracy: 0.739514802631579\n",
      "Epoch [291/500]\t Loss: 0.7352072282841331\t Accuracy: 0.7399259868421053\n",
      "Epoch [292/500]\t Loss: 0.7348110424844843\t Accuracy: 0.7399259868421053\n",
      "Epoch [293/500]\t Loss: 0.7344161962207995\t Accuracy: 0.7401315789473685\n",
      "Epoch [294/500]\t Loss: 0.7340226330255207\t Accuracy: 0.7403371710526315\n",
      "Epoch [295/500]\t Loss: 0.7336303340761285\t Accuracy: 0.7403371710526315\n",
      "Epoch [296/500]\t Loss: 0.7332392868242765\t Accuracy: 0.7401315789473685\n",
      "Epoch [297/500]\t Loss: 0.7328495132295709\t Accuracy: 0.7405427631578947\n",
      "Epoch [298/500]\t Loss: 0.7324609693727995\t Accuracy: 0.7405427631578947\n",
      "Epoch [299/500]\t Loss: 0.7320736427056161\t Accuracy: 0.7403371710526315\n",
      "Epoch [300/500]\t Loss: 0.7316875834214059\t Accuracy: 0.7403371710526315\n",
      "Epoch [301/500]\t Loss: 0.7313027381896973\t Accuracy: 0.7401315789473685\n",
      "Epoch [302/500]\t Loss: 0.7309190756396243\t Accuracy: 0.7401315789473685\n",
      "Epoch [303/500]\t Loss: 0.7305366302791395\t Accuracy: 0.7403371710526315\n",
      "Epoch [304/500]\t Loss: 0.7301554177936754\t Accuracy: 0.7405427631578947\n",
      "Epoch [305/500]\t Loss: 0.7297753283852025\t Accuracy: 0.7405427631578947\n",
      "Epoch [306/500]\t Loss: 0.7293964906742698\t Accuracy: 0.740953947368421\n",
      "Epoch [307/500]\t Loss: 0.7290187697661551\t Accuracy: 0.740953947368421\n",
      "Epoch [308/500]\t Loss: 0.7286422817330611\t Accuracy: 0.7407483552631579\n",
      "Epoch [309/500]\t Loss: 0.7282668634464866\t Accuracy: 0.7407483552631579\n",
      "Epoch [310/500]\t Loss: 0.727892699994539\t Accuracy: 0.7411595394736842\n",
      "Epoch [311/500]\t Loss: 0.7275196282487166\t Accuracy: 0.7411595394736842\n",
      "Epoch [312/500]\t Loss: 0.7271476325235868\t Accuracy: 0.740953947368421\n",
      "Epoch [313/500]\t Loss: 0.7267768633993048\t Accuracy: 0.7413651315789473\n",
      "Epoch [314/500]\t Loss: 0.7264071922553214\t Accuracy: 0.7415707236842105\n",
      "Epoch [315/500]\t Loss: 0.7260385751724243\t Accuracy: 0.7413651315789473\n",
      "Epoch [316/500]\t Loss: 0.725671112537384\t Accuracy: 0.7417763157894737\n",
      "Epoch [317/500]\t Loss: 0.7253047510197288\t Accuracy: 0.7417763157894737\n",
      "Epoch [318/500]\t Loss: 0.7249394968936318\t Accuracy: 0.7417763157894737\n",
      "Epoch [319/500]\t Loss: 0.7245752999657079\t Accuracy: 0.7415707236842105\n",
      "Epoch [320/500]\t Loss: 0.724212226114775\t Accuracy: 0.7417763157894737\n",
      "Epoch [321/500]\t Loss: 0.7238501875024093\t Accuracy: 0.7419819078947368\n",
      "Epoch [322/500]\t Loss: 0.7234892531445152\t Accuracy: 0.7421875\n",
      "Epoch [323/500]\t Loss: 0.7231293477510151\t Accuracy: 0.7428042763157895\n",
      "Epoch [324/500]\t Loss: 0.7227705183782076\t Accuracy: 0.7430098684210527\n",
      "Epoch [325/500]\t Loss: 0.7224127273810538\t Accuracy: 0.7428042763157895\n",
      "Epoch [326/500]\t Loss: 0.7220559339774283\t Accuracy: 0.7428042763157895\n",
      "Epoch [327/500]\t Loss: 0.7217002479653609\t Accuracy: 0.7430098684210527\n",
      "Epoch [328/500]\t Loss: 0.7213455626839086\t Accuracy: 0.7430098684210527\n",
      "Epoch [329/500]\t Loss: 0.7209918373509457\t Accuracy: 0.7430098684210527\n",
      "Epoch [330/500]\t Loss: 0.7206392131353679\t Accuracy: 0.7430098684210527\n",
      "Epoch [331/500]\t Loss: 0.7202875708278856\t Accuracy: 0.7432154605263158\n",
      "Epoch [332/500]\t Loss: 0.7199368978801527\t Accuracy: 0.7432154605263158\n",
      "Epoch [333/500]\t Loss: 0.7195872350742942\t Accuracy: 0.7432154605263158\n",
      "Epoch [334/500]\t Loss: 0.7192386326036955\t Accuracy: 0.7432154605263158\n",
      "Epoch [335/500]\t Loss: 0.7188909618478072\t Accuracy: 0.7430098684210527\n",
      "Epoch [336/500]\t Loss: 0.7185442698629279\t Accuracy: 0.7430098684210527\n",
      "Epoch [337/500]\t Loss: 0.7181985660603172\t Accuracy: 0.743421052631579\n",
      "Epoch [338/500]\t Loss: 0.7178538378916288\t Accuracy: 0.7436266447368421\n",
      "Epoch [339/500]\t Loss: 0.7175100006555256\t Accuracy: 0.7436266447368421\n",
      "Epoch [340/500]\t Loss: 0.7171672112063358\t Accuracy: 0.7438322368421053\n",
      "Epoch [341/500]\t Loss: 0.7168253064155579\t Accuracy: 0.7438322368421053\n",
      "Epoch [342/500]\t Loss: 0.7164843835328755\t Accuracy: 0.7438322368421053\n",
      "Epoch [343/500]\t Loss: 0.7161444017761632\t Accuracy: 0.7438322368421053\n",
      "Epoch [344/500]\t Loss: 0.7158053768308539\t Accuracy: 0.7440378289473685\n",
      "Epoch [345/500]\t Loss: 0.7154672145843506\t Accuracy: 0.7444490131578947\n",
      "Epoch [346/500]\t Loss: 0.7151300499313756\t Accuracy: 0.7444490131578947\n",
      "Epoch [347/500]\t Loss: 0.7147937699368125\t Accuracy: 0.7444490131578947\n",
      "Epoch [348/500]\t Loss: 0.714458377737748\t Accuracy: 0.7444490131578947\n",
      "Epoch [349/500]\t Loss: 0.7141239298017401\t Accuracy: 0.7446546052631579\n",
      "Epoch [350/500]\t Loss: 0.7137903414274517\t Accuracy: 0.7446546052631579\n",
      "Epoch [351/500]\t Loss: 0.7134576879049602\t Accuracy: 0.744860197368421\n",
      "Epoch [352/500]\t Loss: 0.7131259692342657\t Accuracy: 0.7450657894736842\n",
      "Epoch [353/500]\t Loss: 0.7127950818915116\t Accuracy: 0.7450657894736842\n",
      "Epoch [354/500]\t Loss: 0.712465082344256\t Accuracy: 0.7452713815789473\n",
      "Epoch [355/500]\t Loss: 0.7121359549070659\t Accuracy: 0.7450657894736842\n",
      "Epoch [356/500]\t Loss: 0.7118077152653745\t Accuracy: 0.7450657894736842\n",
      "Epoch [357/500]\t Loss: 0.7114803257741427\t Accuracy: 0.7450657894736842\n",
      "Epoch [358/500]\t Loss: 0.7111538178042361\t Accuracy: 0.7450657894736842\n",
      "Epoch [359/500]\t Loss: 0.7108281631218759\t Accuracy: 0.7450657894736842\n",
      "Epoch [360/500]\t Loss: 0.7105033491787157\t Accuracy: 0.7452713815789473\n",
      "Epoch [361/500]\t Loss: 0.7101793853860152\t Accuracy: 0.7452713815789473\n",
      "Epoch [362/500]\t Loss: 0.7098562842921207\t Accuracy: 0.7452713815789473\n",
      "Epoch [363/500]\t Loss: 0.7095340239374262\t Accuracy: 0.7454769736842105\n",
      "Epoch [364/500]\t Loss: 0.7092125949106718\t Accuracy: 0.7456825657894737\n",
      "Epoch [365/500]\t Loss: 0.7088919909376847\t Accuracy: 0.7458881578947368\n",
      "Epoch [366/500]\t Loss: 0.7085721900588587\t Accuracy: 0.74609375\n",
      "Epoch [367/500]\t Loss: 0.7082532393304926\t Accuracy: 0.74609375\n",
      "Epoch [368/500]\t Loss: 0.7079350854221144\t Accuracy: 0.7465049342105263\n",
      "Epoch [369/500]\t Loss: 0.7076177628416764\t Accuracy: 0.7465049342105263\n",
      "Epoch [370/500]\t Loss: 0.7073012527666593\t Accuracy: 0.7467105263157895\n",
      "Epoch [371/500]\t Loss: 0.7069855332374573\t Accuracy: 0.7469161184210527\n",
      "Epoch [372/500]\t Loss: 0.7066705885686373\t Accuracy: 0.7469161184210527\n",
      "Epoch [373/500]\t Loss: 0.7063564815019306\t Accuracy: 0.7471217105263158\n",
      "Epoch [374/500]\t Loss: 0.7060431116505673\t Accuracy: 0.7471217105263158\n",
      "Epoch [375/500]\t Loss: 0.7057305950867502\t Accuracy: 0.7475328947368421\n",
      "Epoch [376/500]\t Loss: 0.7054187780932376\t Accuracy: 0.7479440789473685\n",
      "Epoch [377/500]\t Loss: 0.7051078081130981\t Accuracy: 0.7479440789473685\n",
      "Epoch [378/500]\t Loss: 0.7047976004449945\t Accuracy: 0.7479440789473685\n",
      "Epoch [379/500]\t Loss: 0.7044881456776669\t Accuracy: 0.7479440789473685\n",
      "Epoch [380/500]\t Loss: 0.7041794720448946\t Accuracy: 0.7481496710526315\n",
      "Epoch [381/500]\t Loss: 0.7038715575870714\t Accuracy: 0.7483552631578947\n",
      "Epoch [382/500]\t Loss: 0.7035644085783708\t Accuracy: 0.7485608552631579\n",
      "Epoch [383/500]\t Loss: 0.7032579967850133\t Accuracy: 0.748766447368421\n",
      "Epoch [384/500]\t Loss: 0.7029523190699125\t Accuracy: 0.748766447368421\n",
      "Epoch [385/500]\t Loss: 0.7026474162151939\t Accuracy: 0.7491776315789473\n",
      "Epoch [386/500]\t Loss: 0.7023432129307797\t Accuracy: 0.7493832236842105\n",
      "Epoch [387/500]\t Loss: 0.7020398096034401\t Accuracy: 0.7495888157894737\n",
      "Epoch [388/500]\t Loss: 0.7017370870238856\t Accuracy: 0.7495888157894737\n",
      "Epoch [389/500]\t Loss: 0.7014351455788863\t Accuracy: 0.7495888157894737\n",
      "Epoch [390/500]\t Loss: 0.7011339193896243\t Accuracy: 0.7493832236842105\n",
      "Epoch [391/500]\t Loss: 0.7008333582627145\t Accuracy: 0.7493832236842105\n",
      "Epoch [392/500]\t Loss: 0.7005335876816198\t Accuracy: 0.7495888157894737\n",
      "Epoch [393/500]\t Loss: 0.7002345166708294\t Accuracy: 0.7497944078947368\n",
      "Epoch [394/500]\t Loss: 0.6999361389561704\t Accuracy: 0.75\n",
      "Epoch [395/500]\t Loss: 0.6996384859085083\t Accuracy: 0.75\n",
      "Epoch [396/500]\t Loss: 0.6993414916490254\t Accuracy: 0.75\n",
      "Epoch [397/500]\t Loss: 0.6990452753870111\t Accuracy: 0.7502055921052632\n",
      "Epoch [398/500]\t Loss: 0.6987496896793968\t Accuracy: 0.7502055921052632\n",
      "Epoch [399/500]\t Loss: 0.6984548443242123\t Accuracy: 0.7502055921052632\n",
      "Epoch [400/500]\t Loss: 0.6981606420717741\t Accuracy: 0.7504111842105263\n",
      "Epoch [401/500]\t Loss: 0.6978671582121598\t Accuracy: 0.7504111842105263\n",
      "Epoch [402/500]\t Loss: 0.6975743645115903\t Accuracy: 0.7504111842105263\n",
      "Epoch [403/500]\t Loss: 0.6972822735184118\t Accuracy: 0.7508223684210527\n",
      "Epoch [404/500]\t Loss: 0.6969908099425467\t Accuracy: 0.7508223684210527\n",
      "Epoch [405/500]\t Loss: 0.6967000427998995\t Accuracy: 0.7508223684210527\n",
      "Epoch [406/500]\t Loss: 0.6964099469937777\t Accuracy: 0.7510279605263158\n",
      "Epoch [407/500]\t Loss: 0.6961204974274886\t Accuracy: 0.751233552631579\n",
      "Epoch [408/500]\t Loss: 0.6958317411573309\t Accuracy: 0.7516447368421053\n",
      "Epoch [409/500]\t Loss: 0.6955436436753524\t Accuracy: 0.7518503289473685\n",
      "Epoch [410/500]\t Loss: 0.6952561579252544\t Accuracy: 0.7516447368421053\n",
      "Epoch [411/500]\t Loss: 0.6949693811567206\t Accuracy: 0.7516447368421053\n",
      "Epoch [412/500]\t Loss: 0.6946832067088077\t Accuracy: 0.7518503289473685\n",
      "Epoch [413/500]\t Loss: 0.6943977067345067\t Accuracy: 0.7518503289473685\n",
      "Epoch [414/500]\t Loss: 0.6941128843709042\t Accuracy: 0.7518503289473685\n",
      "Epoch [415/500]\t Loss: 0.6938286392312301\t Accuracy: 0.7518503289473685\n",
      "Epoch [416/500]\t Loss: 0.6935450654280814\t Accuracy: 0.7522615131578947\n",
      "Epoch [417/500]\t Loss: 0.6932621441389385\t Accuracy: 0.7522615131578947\n",
      "Epoch [418/500]\t Loss: 0.6929798188962435\t Accuracy: 0.7524671052631579\n",
      "Epoch [419/500]\t Loss: 0.6926981744013334\t Accuracy: 0.752672697368421\n",
      "Epoch [420/500]\t Loss: 0.6924171008561787\t Accuracy: 0.752672697368421\n",
      "Epoch [421/500]\t Loss: 0.692136686099203\t Accuracy: 0.7528782894736842\n",
      "Epoch [422/500]\t Loss: 0.6918568862111945\t Accuracy: 0.7528782894736842\n",
      "Epoch [423/500]\t Loss: 0.6915776792325472\t Accuracy: 0.7530838815789473\n",
      "Epoch [424/500]\t Loss: 0.6912991216308192\t Accuracy: 0.7534950657894737\n",
      "Epoch [425/500]\t Loss: 0.6910211506642794\t Accuracy: 0.7537006578947368\n",
      "Epoch [426/500]\t Loss: 0.6907437914296201\t Accuracy: 0.75390625\n",
      "Epoch [427/500]\t Loss: 0.6904670345155817\t Accuracy: 0.7541118421052632\n",
      "Epoch [428/500]\t Loss: 0.6901908987446835\t Accuracy: 0.7541118421052632\n",
      "Epoch [429/500]\t Loss: 0.6899153182381078\t Accuracy: 0.7543174342105263\n",
      "Epoch [430/500]\t Loss: 0.6896403871084514\t Accuracy: 0.7543174342105263\n",
      "Epoch [431/500]\t Loss: 0.689366058299416\t Accuracy: 0.7543174342105263\n",
      "Epoch [432/500]\t Loss: 0.6890922753434432\t Accuracy: 0.7543174342105263\n",
      "Epoch [433/500]\t Loss: 0.6888191480385629\t Accuracy: 0.7545230263157895\n",
      "Epoch [434/500]\t Loss: 0.6885465414900529\t Accuracy: 0.7545230263157895\n",
      "Epoch [435/500]\t Loss: 0.6882745215767309\t Accuracy: 0.7547286184210527\n",
      "Epoch [436/500]\t Loss: 0.6880031071211162\t Accuracy: 0.7549342105263158\n",
      "Epoch [437/500]\t Loss: 0.6877322636152569\t Accuracy: 0.7549342105263158\n",
      "Epoch [438/500]\t Loss: 0.6874619690995467\t Accuracy: 0.755139802631579\n",
      "Epoch [439/500]\t Loss: 0.6871922988640634\t Accuracy: 0.7553453947368421\n",
      "Epoch [440/500]\t Loss: 0.6869231556591234\t Accuracy: 0.7553453947368421\n",
      "Epoch [441/500]\t Loss: 0.6866545834039387\t Accuracy: 0.7553453947368421\n",
      "Epoch [442/500]\t Loss: 0.686386626017721\t Accuracy: 0.7553453947368421\n",
      "Epoch [443/500]\t Loss: 0.6861192207587393\t Accuracy: 0.7555509868421053\n",
      "Epoch [444/500]\t Loss: 0.685852333119041\t Accuracy: 0.7557565789473685\n",
      "Epoch [445/500]\t Loss: 0.6855860258403578\t Accuracy: 0.7557565789473685\n",
      "Epoch [446/500]\t Loss: 0.6853202738259968\t Accuracy: 0.7559621710526315\n",
      "Epoch [447/500]\t Loss: 0.6850550488421792\t Accuracy: 0.7559621710526315\n",
      "Epoch [448/500]\t Loss: 0.6847904230418959\t Accuracy: 0.7557565789473685\n",
      "Epoch [449/500]\t Loss: 0.6845262960383767\t Accuracy: 0.7559621710526315\n",
      "Epoch [450/500]\t Loss: 0.6842627368475261\t Accuracy: 0.7559621710526315\n",
      "Epoch [451/500]\t Loss: 0.6839997705660368\t Accuracy: 0.7559621710526315\n",
      "Epoch [452/500]\t Loss: 0.6837372622991863\t Accuracy: 0.7561677631578947\n",
      "Epoch [453/500]\t Loss: 0.6834753375304373\t Accuracy: 0.7567845394736842\n",
      "Epoch [454/500]\t Loss: 0.6832139272438852\t Accuracy: 0.7569901315789473\n",
      "Epoch [455/500]\t Loss: 0.6829530659474825\t Accuracy: 0.7569901315789473\n",
      "Epoch [456/500]\t Loss: 0.6826927316816229\t Accuracy: 0.7569901315789473\n",
      "Epoch [457/500]\t Loss: 0.6824329338575664\t Accuracy: 0.7571957236842105\n",
      "Epoch [458/500]\t Loss: 0.6821736411044472\t Accuracy: 0.7574013157894737\n",
      "Epoch [459/500]\t Loss: 0.6819149004785638\t Accuracy: 0.7574013157894737\n",
      "Epoch [460/500]\t Loss: 0.6816566711977908\t Accuracy: 0.7571957236842105\n",
      "Epoch [461/500]\t Loss: 0.6813989501250418\t Accuracy: 0.7571957236842105\n",
      "Epoch [462/500]\t Loss: 0.6811417435344896\t Accuracy: 0.7574013157894737\n",
      "Epoch [463/500]\t Loss: 0.6808850608373943\t Accuracy: 0.7574013157894737\n",
      "Epoch [464/500]\t Loss: 0.6806289020337557\t Accuracy: 0.7578125\n",
      "Epoch [465/500]\t Loss: 0.6803732420268812\t Accuracy: 0.7578125\n",
      "Epoch [466/500]\t Loss: 0.6801180745425978\t Accuracy: 0.7578125\n",
      "Epoch [467/500]\t Loss: 0.6798634560484635\t Accuracy: 0.7578125\n",
      "Epoch [468/500]\t Loss: 0.6796093238027472\t Accuracy: 0.7578125\n",
      "Epoch [469/500]\t Loss: 0.6793556527087563\t Accuracy: 0.7580180921052632\n",
      "Epoch [470/500]\t Loss: 0.6791025368790877\t Accuracy: 0.7582236842105263\n",
      "Epoch [471/500]\t Loss: 0.6788498884753177\t Accuracy: 0.7582236842105263\n",
      "Epoch [472/500]\t Loss: 0.6785977420053984\t Accuracy: 0.7582236842105263\n",
      "Epoch [473/500]\t Loss: 0.6783460911951567\t Accuracy: 0.7584292763157895\n",
      "Epoch [474/500]\t Loss: 0.6780949423187658\t Accuracy: 0.7584292763157895\n",
      "Epoch [475/500]\t Loss: 0.6778442985133121\t Accuracy: 0.7586348684210527\n",
      "Epoch [476/500]\t Loss: 0.6775941095854107\t Accuracy: 0.7588404605263158\n",
      "Epoch [477/500]\t Loss: 0.6773444100430137\t Accuracy: 0.7588404605263158\n",
      "Epoch [478/500]\t Loss: 0.6770951779265153\t Accuracy: 0.7588404605263158\n",
      "Epoch [479/500]\t Loss: 0.6768464508809542\t Accuracy: 0.7588404605263158\n",
      "Epoch [480/500]\t Loss: 0.6765981975354647\t Accuracy: 0.759046052631579\n",
      "Epoch [481/500]\t Loss: 0.6763504210271334\t Accuracy: 0.7594572368421053\n",
      "Epoch [482/500]\t Loss: 0.6761031182188737\t Accuracy: 0.7594572368421053\n",
      "Epoch [483/500]\t Loss: 0.6758563079332051\t Accuracy: 0.7594572368421053\n",
      "Epoch [484/500]\t Loss: 0.6756099431138289\t Accuracy: 0.7594572368421053\n",
      "Epoch [485/500]\t Loss: 0.6753640802283036\t Accuracy: 0.7594572368421053\n",
      "Epoch [486/500]\t Loss: 0.6751186220269454\t Accuracy: 0.7594572368421053\n",
      "Epoch [487/500]\t Loss: 0.6748736971303037\t Accuracy: 0.7594572368421053\n",
      "Epoch [488/500]\t Loss: 0.6746291894661752\t Accuracy: 0.7594572368421053\n",
      "Epoch [489/500]\t Loss: 0.674385174324638\t Accuracy: 0.7594572368421053\n",
      "Epoch [490/500]\t Loss: 0.674141642294432\t Accuracy: 0.7594572368421053\n",
      "Epoch [491/500]\t Loss: 0.6738985086742201\t Accuracy: 0.7594572368421053\n",
      "Epoch [492/500]\t Loss: 0.6736558801249454\t Accuracy: 0.7594572368421053\n",
      "Epoch [493/500]\t Loss: 0.673413662534011\t Accuracy: 0.7596628289473685\n",
      "Epoch [494/500]\t Loss: 0.6731719280544081\t Accuracy: 0.7598684210526315\n",
      "Epoch [495/500]\t Loss: 0.6729306453152707\t Accuracy: 0.7598684210526315\n",
      "Epoch [496/500]\t Loss: 0.6726897829457333\t Accuracy: 0.7598684210526315\n",
      "Epoch [497/500]\t Loss: 0.6724494036875273\t Accuracy: 0.7600740131578947\n",
      "Epoch [498/500]\t Loss: 0.6722094667585272\t Accuracy: 0.7600740131578947\n",
      "Epoch [499/500]\t Loss: 0.6719699407878675\t Accuracy: 0.7600740131578947\n",
      "[FINAL]\t Loss: 0.8234476620151151\t Accuracy: 0.6983366935483871\n"
     ]
    }
   ],
   "source": [
    "main(0,args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cec801-15fb-445a-9fa3-4f3338280898",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
